{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhBlg/Others/blob/main/sweeps_with_blocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pceY6sGNaTvE"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2tZmmCFaLLz",
        "outputId": "6bea9d47-b910-42c5-d443-35d64a7c35c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 34.0 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.4 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 80.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 99.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 83.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=010d4f6954e401976344777ac626172f057c9a4710ba2675fe4eb1100bd327d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Using matplotlib backend: agg\n",
            "Mounted at /content/drive/\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting braindecode\n",
            "  Downloading Braindecode-0.6-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 27.6 MB/s \n",
            "\u001b[?25hCollecting skorch\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.3.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.2.2)\n",
            "Collecting mne\n",
            "  Downloading mne-1.1.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 83.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.7.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->braindecode) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->braindecode) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->braindecode) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne->braindecode) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne->braindecode) (4.64.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne->braindecode) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne->braindecode) (21.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne->braindecode) (4.4.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne->braindecode) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne->braindecode) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne->braindecode) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->braindecode) (2022.2.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (0.8.10)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (3.1.0)\n",
            "Installing collected packages: skorch, mne, braindecode\n",
            "Successfully installed braindecode-0.6 mne-1.1.0 skorch-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting moabb\n",
            "  Downloading moabb-0.4.6-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 32.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML<6.0,>=5.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 89.7 MB/s \n",
            "\u001b[?25hCollecting coverage<6.0,>=5.5\n",
            "  Downloading coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 79.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.7.3)\n",
            "Requirement already satisfied: matplotlib<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from moabb) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.21.6)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.3.5)\n",
            "Requirement already satisfied: pooch<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.6.0)\n",
            "Collecting pyriemann>=0.2.6\n",
            "  Downloading pyriemann-0.3.tar.gz (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 80.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.15.1 in /usr/local/lib/python3.7/dist-packages (from moabb) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.62 in /usr/local/lib/python3.7/dist-packages (from moabb) (4.64.0)\n",
            "Requirement already satisfied: h5py<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from moabb) (3.1.0)\n",
            "Requirement already satisfied: mne>=0.19 in /usr/local/lib/python3.7/dist-packages (from moabb) (1.1.0)\n",
            "Requirement already satisfied: seaborn>=0.9 in /usr/local/lib/python3.7/dist-packages (from moabb) (0.11.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<4.0,>=3.0->moabb) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->moabb) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->moabb) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->moabb) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->moabb) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4.0,>=3.0->moabb) (4.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->moabb) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->moabb) (2.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->moabb) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0->moabb) (2022.2.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch<2.0,>=1.6->moabb) (1.4.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyriemann>=0.2.6->moabb) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0,>=3.0->moabb) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->moabb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->moabb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->moabb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->moabb) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0,>=1.0->moabb) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne>=0.19->moabb) (2.0.1)\n",
            "Building wheels for collected packages: pyriemann\n",
            "  Building wheel for pyriemann (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyriemann: filename=pyriemann-0.3-py2.py3-none-any.whl size=78033 sha256=77b60d6a74d25b11de8dfea2ec5842d48ff92c184423bef26aa0b2fab97703f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/1b/bf/a537f9e17e6c3490004ede419c72f863af1d0d765d25e532ef\n",
            "Successfully built pyriemann\n",
            "Installing collected packages: PyYAML, pyriemann, coverage, moabb\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1 coverage-5.5 moabb-0.4.6 pyriemann-0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will use device cuda\n",
            "Will save checkpoints to /content/resultdir\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!pip install scipy -U\n",
        "!wandb login acf4cf1e91a5b92ebf1613195d6d05c09db63b4e\n",
        "import math\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import wandb\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn.utils import weight_norm\n",
        "%matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/mne_data')\n",
        "sys.path.append(os.path.abspath('/content/drive/MyDrive/Colab Notebooks/mne_data'))\n",
        "!mkdir /content/resultdir\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "resultdir='/content/resultdir'\n",
        "!pip install braindecode\n",
        "!pip install tqdm\n",
        "!pip install mne\n",
        "!pip install moabb\n",
        "\n",
        "###########     REPRODUCIBILITY      #######################################\n",
        "random_seed=42\n",
        "#torch.use_deterministic_algorithms(True)\n",
        "torch.manual_seed(random_seed)\n",
        "############################################################################\n",
        "\n",
        "############################################################################\n",
        "\n",
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it (will take the gpu specified by the argument args.device)\n",
        "device = 'cuda' if cuda else 'cpu'\n",
        "os.makedirs(resultdir,exist_ok=True)\n",
        "print(f\"Will use device {device}\")\n",
        "print(f\"Will save checkpoints to {resultdir}\")\n",
        "################################################################################################################################# \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsHADplayNq"
      },
      "source": [
        "###Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2K62OZWaxy9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "# Import necessary library\n",
        "from scipy.linalg import sqrtm, inv \n",
        "import numpy as np\n",
        "from braindecode.datasets.moabb import MOABBDataset\n",
        "from braindecode.datautil.windowers import create_windows_from_events\n",
        "\n",
        "\n",
        "def resample(eeg):\n",
        "    secs = eeg.shape[-1]/250.0 # from 250 Hz\n",
        "    samps = int(secs*125)     # to 125 Hz\n",
        "    eeg2 = torch.nn.functional.interpolate(eeg, size=samps)\n",
        "    return eeg2\n",
        "\n",
        "\n",
        "## Dataloader ###\n",
        "def loaders(removed_subject,T_x,T_y,V_x,V_y,Test_x,Test_y,batch_size):\n",
        "    train_data = list(zip(T_x, T_y))\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "    valid_data = list(zip(V_x, V_y))\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "    test_loader = torch.utils.data.DataLoader(list(zip(Test_x, Test_y)), batch_size = 10000)\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "\n",
        "# Apply Euclidean Alignment\n",
        "def apply_EA(data, device='cuda'):\n",
        "    '''\n",
        "    Apply Euclidean aligment on array-like objects for 1 subject\n",
        "    \n",
        "    PARAMETER:\n",
        "    data: \n",
        "        Data of one subject.\n",
        "    \n",
        "    \n",
        "    OUTPUT:\n",
        "        Aligned data with Euclidean Alignment\n",
        "    '''\n",
        "    \n",
        "    # So that this function can handles separated or combined left and right trials\n",
        "    # If they are separated\n",
        "    # If they are not separated\n",
        "\n",
        "    #if input is a torch tensor\n",
        "    if torch.is_tensor(data):\n",
        "        data=data.cpu().detach().numpy() \n",
        "\n",
        "    print('Found %d trial(s) in which EEG data is stored' %len(data))\n",
        "    all_trials = data\n",
        "    \n",
        "    # Calculate reference matrix\n",
        "    RefEA = 0\n",
        "    print('Computing reference matrix RefEA')\n",
        "\n",
        "    # Iterate over all trials, compute reference EA\n",
        "    for trial in all_trials:\n",
        "        cov = np.cov(trial, rowvar=True)\n",
        "        RefEA += cov\n",
        "\n",
        "    # Average over all trials\n",
        "    RefEA = RefEA/all_trials.shape[0]\n",
        "    \n",
        "    # Adding reference EA as a new key in data\n",
        "    data_dict={}\n",
        "    print('Add RefEA as a new key in data')\n",
        "    data_dict['RefEA'] = RefEA \n",
        "    \n",
        "    # Compute R^(-0.5)\n",
        "    R_inv = sqrtm(inv(RefEA))\n",
        "    data_dict['R_inv'] = R_inv\n",
        "    \n",
        "        \n",
        "    # Perform EA on each trial\n",
        "    all_trials_EA = []\n",
        "        \n",
        "    for t in all_trials:\n",
        "        all_trials_EA.append(R_inv@t)\n",
        "        \n",
        "    # Return all_trials_EA\n",
        "    return torch.tensor(np.array(all_trials_EA)).float()\n",
        "        \n",
        "\n",
        "def standardize(X, mean=None, std=None):\n",
        "  mean = X.mean(dim=-1, keepdim=True)\n",
        "  std = X.std(dim=-1, keepdim=True)\n",
        "  return (X - mean) / std , mean, std\n",
        "\n",
        "\n",
        "\n",
        "################### Load Physionet data as done in the TIDNet paper ###################################################################\n",
        "################## calling load_eeg_bci will return an object having data[subjects][records][0/1] 0 for Xs and 1 for Ys ###############\n",
        "from torch.utils.data import Dataset\n",
        "from mne.datasets import eegbci\n",
        "import mne \n",
        "import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "BAD_SUBJECTS_EEGBCI = [87, 89, 91, 99]\n",
        "SUBJECTS_EEGBCI = list(i for i in range(109) if i not in BAD_SUBJECTS_EEGBCI)\n",
        "EVENTS_EEGBCI = dict(hands=2, feet=3)\n",
        "BASELINE_EYES_OPEN = [1]\n",
        "BASELINE_EYES_CLOSED = [2]\n",
        "\n",
        "MOTOR_FISTS = (3, 7, 11)\n",
        "IMAGERY_FISTS = (4, 8, 12)\n",
        "MOTOR_FEET = (5, 9, 13)\n",
        "IMAGERY_FEET_V_FISTS = (6, 10, 14)\n",
        "\n",
        "def zscore(data: np.ndarray, axis=-1):\n",
        "    return (data - data.mean(axis, keepdims=True)) / (data.std(axis, keepdims=True) + 1e-12)\n",
        "\n",
        "\n",
        "def one_hot(y: torch.Tensor, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor to another similarly stored tensor\"\"\"\n",
        "    if len(y.shape) > 0 and y.shape[-1] == 1:\n",
        "        y = y.squeeze(-1)\n",
        "    out = torch.zeros(y.size()+torch.Size([num_classes]), device=y.device)\n",
        "    return out.scatter_(-1, y.view((*y.size(), 1)), 1)\n",
        "\n",
        "class EpochsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, epochs: mne.Epochs, force_label=None, picks=None, preproccesors=None, normalizer=zscore,\n",
        "                 runs=None, train_mode=False):\n",
        "        self.mode = train_mode\n",
        "        self.epochs = epochs\n",
        "        self._t_len = epochs.tmax - epochs.tmin\n",
        "        self.loaded_x = [None for _ in range(len(epochs.events))]\n",
        "        self.runs = runs\n",
        "        self.picks = picks\n",
        "        self.force_label = force_label if force_label is None else torch.tensor(force_label)\n",
        "        self.normalizer = normalizer\n",
        "        self.preprocessors = preproccesors if isinstance(preproccesors, (list, tuple)) else [preproccesors]\n",
        "        for i, p in enumerate(self.preprocessors):\n",
        "            self.preprocessors[i] = p(self.epochs)\n",
        "\n",
        "    @property\n",
        "    def channels(self):\n",
        "        if self.picks is None:\n",
        "            return len(self.epochs.ch_names)\n",
        "        else:\n",
        "            return len(self.picks)\n",
        "\n",
        "    @property\n",
        "    def sfreq(self):\n",
        "        return self.epochs.info['sfreq']\n",
        "\n",
        "    def train_mode(self, mode=False):\n",
        "        self.mode = mode\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ep = self.epochs[index]\n",
        "        if self.loaded_x[index] is None:\n",
        "            x = ep.get_data()\n",
        "            if len(x.shape) != 3 or 0 in x.shape:\n",
        "                print(\"I don't know why: {} index{}/{}\".format(self.epochs, index, len(self)))\n",
        "                print(self.epochs.info['description'])\n",
        "                # raise AttributeError()\n",
        "                return self.__getitem__(index - 1)\n",
        "            x = x[0, self.picks, :]\n",
        "            for p in self.preprocessors:\n",
        "                x = p(x)\n",
        "            x = torch.from_numpy(self.normalizer(x).astype('float32')).squeeze(0)\n",
        "            self.loaded_x[index] = x\n",
        "        else:\n",
        "            x = self.loaded_x[index]\n",
        "\n",
        "        y = torch.from_numpy(ep.events[..., -1]).long() if self.force_label is None else self.force_label\n",
        "\n",
        "        if self.runs is not None:\n",
        "            return x, y, one_hot(torch.tensor(self.runs * index / len(self)).long(), self.runs)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        events = self.epochs.events[:, 0].tolist()\n",
        "        return len(events)\n",
        "\n",
        "def same(x):\n",
        "    return x\n",
        "\n",
        "def load_eeg_bci(targets=4, tmin=0, tlen=3, t_ev=0, t_sub=None, normalizer=same, low_f=None, high_f=None, #zscore\n",
        "                 alignment=False, path_mne=None):\n",
        "\n",
        "    paths = [eegbci.load_data(s+1, IMAGERY_FISTS, path=path_mne, update_path=False) for s in SUBJECTS_EEGBCI]\n",
        "    raws = [mne.io.concatenate_raws([mne.io.read_raw_edf(p, preload=True) for p in path])\n",
        "            for path in tqdm.tqdm(paths, unit='subj', desc='Loading')]\n",
        "    datasets = OrderedDict()\n",
        "    for i, raw in tqdm.tqdm(list(zip(SUBJECTS_EEGBCI, raws)), desc='Preprocessing'):\n",
        "        if raw.info['sfreq'] != 160:\n",
        "            tqdm.tqdm.write('Skipping..., sampling frequency: {}'.format(raw.info['sfreq']))\n",
        "            continue\n",
        "        raw.rename_channels(lambda x: x.strip('.'))\n",
        "        if low_f or high_f:\n",
        "            raw.filter(low_f, high_f, fir_design='firwin', skip_by_annotation='edge')\n",
        "        events, _ = mne.events_from_annotations(raw, event_id=dict(T1=0, T2=1))\n",
        "        picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
        "        epochs = mne.Epochs(raw, events[:41, ...], tmin=tmin, tmax=tmin + tlen - 1 / raw.info['sfreq'], picks=picks,\n",
        "                            baseline=None, reject_by_annotation=False)#.drop_bad()\n",
        "        if targets > 2:\n",
        "            paths = eegbci.load_data(i + 1, BASELINE_EYES_OPEN, path=path_mne, update_path=False)\n",
        "            raw = mne.io.concatenate_raws([mne.io.read_raw_edf(p, preload=True) for p in paths])\n",
        "            raw.rename_channels(lambda x: x.strip('.'))\n",
        "            if low_f or high_f:\n",
        "                raw.filter(low_f, high_f, fir_design='firwin', skip_by_annotation='edge')\n",
        "            events = np.zeros((events.shape[0] // 2, 3)).astype('int')\n",
        "            events[:, -1] = 2\n",
        "            events[:, 0] = np.linspace(0, raw.info['sfreq'] * (60 - 2 * tlen), num=events.shape[0]).astype(np.int)\n",
        "            picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
        "            eyes_epochs = mne.Epochs(raw, events, tmin=tmin, tmax=tmin + tlen - 1 / raw.info['sfreq'], picks=picks,\n",
        "                                     baseline=None, reject_by_annotation=False)#.drop_bad()\n",
        "            epochs = mne.concatenate_epochs([eyes_epochs, epochs])\n",
        "        if targets > 3:\n",
        "            paths = eegbci.load_data(i+1, IMAGERY_FEET_V_FISTS, path=path_mne, update_path=False)\n",
        "            raw = mne.io.concatenate_raws([mne.io.read_raw_edf(p, preload=True) for p in paths])\n",
        "            raw.rename_channels(lambda x: x.strip('.'))\n",
        "            if low_f or high_f:\n",
        "                raw.filter(low_f, high_f, fir_design='firwin', skip_by_annotation='edge')\n",
        "            events, _ = mne.events_from_annotations(raw, event_id=dict(T2=3))\n",
        "            picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
        "            feet_epochs = mne.Epochs(raw, events[:20, ...], tmin=tmin, tmax=tmin + tlen - 1 / raw.info['sfreq'],\n",
        "                                     picks=picks, baseline=None, reject_by_annotation=False)#.drop_bad()\n",
        "            epochs = mne.concatenate_epochs([epochs, feet_epochs])\n",
        "\n",
        "        datasets[i] = EpochsDataset(epochs, preproccesors=EuclideanAlignment if alignment else [],\n",
        "                                    normalizer=normalizer, runs=3)\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "####################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "def load_subjects(path, number_of_subjects, device, bad_subjects=[], apply_euclidean=True, with_eog=True):\n",
        "    l= number_of_subjects+1\n",
        "    sbj_x=[]\n",
        "    sbj_y=[]\n",
        "    if number_of_subjects==9:\n",
        "        for subject_id in [e for e in range(1,l) if e not in bad_subjects]:\n",
        "            dataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])\n",
        "\n",
        "\n",
        "            trial_start_offset_seconds = 0#-0.5  #####################\n",
        "            # Extract sampling frequency, check that they are same in all datasets\n",
        "            sfreq = dataset.datasets[0].raw.info['sfreq']            \n",
        "            trial_stop_offset_samples= int(-1 * sfreq)  #######################\n",
        "\n",
        "            assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
        "            # Calculate the trial start offset in samples.\n",
        "            trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
        "\n",
        "            # Create windows using braindecode function for this. It needs parameters to define how\n",
        "            # trials should be used.\n",
        "            windows_dataset = create_windows_from_events(\n",
        "                dataset,\n",
        "                trial_start_offset_samples=trial_start_offset_samples,\n",
        "                trial_stop_offset_samples=trial_stop_offset_samples, \n",
        "                preload=True,\n",
        "            )\n",
        "\n",
        "\n",
        "            splitted = windows_dataset.split('session')\n",
        "            train_set = splitted['session_T']\n",
        "            valid_set = splitted['session_E']\n",
        "\n",
        "            # delete stim channel and eog channels if wanted\n",
        "            if with_eog==False: \n",
        "              dlt=-4\n",
        "            else:\n",
        "              dlt=-1\n",
        "\n",
        "            train_x=np.array([ele[0][:dlt] for ele in train_set])\n",
        "            train_y=np.array([ele[1] for ele in train_set])\n",
        "\n",
        "            valid_x=np.array([ele[0][:dlt] for ele in valid_set])\n",
        "            valid_y=np.array([ele[1] for ele in valid_set])\n",
        "\n",
        "            T_x = torch.tensor( np.append(np.array(train_x), np.array(valid_x), axis=0) )\n",
        "            T_y = torch.tensor( np.append(np.array(train_y), np.array(valid_y), axis=0) )\n",
        "\n",
        "            T_x=resample(T_x)############################# added to do downsampling\n",
        "\n",
        "            if apply_euclidean==True:\n",
        "                x=apply_EA(T_x)\n",
        "            else : \n",
        "                x=T_x\n",
        "\n",
        "            sbj_x.append(x)\n",
        "            sbj_y.append(T_y)\n",
        "            del T_x, T_y\n",
        "\n",
        "\n",
        "    if number_of_subjects==52:\n",
        "        for subject_id in [e for e in range(1,l) if e not in bad_subjects]:\n",
        "            dataset = MOABBDataset(dataset_name=\"Cho2017\", subject_ids=[subject_id])\n",
        "\n",
        "\n",
        "            trial_start_offset_seconds = 0#-0.5  #####################\n",
        "            # Extract sampling frequency, check that they are same in all datasets\n",
        "            sfreq = dataset.datasets[0].raw.info['sfreq']            \n",
        "            trial_stop_offset_samples= int(-1 * sfreq)  #######################\n",
        "\n",
        "            assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
        "            # Calculate the trial start offset in samples.\n",
        "            trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
        "\n",
        "            # Create windows using braindecode function for this. It needs parameters to define how\n",
        "            # trials should be used.\n",
        "            windows_dataset = create_windows_from_events(\n",
        "                dataset,\n",
        "                trial_start_offset_samples=trial_start_offset_samples,\n",
        "                trial_stop_offset_samples=trial_stop_offset_samples, \n",
        "                preload=True,\n",
        "            )\n",
        "\n",
        "\n",
        "            splitted = windows_dataset.split('session')\n",
        "            splits = splitted['session_0']\n",
        "\n",
        "            # delete stim channel and EMG channels and EOG if wanted \n",
        "            if with_eog==False: \n",
        "              ch=dataset.datasets[0].raw.ch_names\n",
        "              no_eog=[e for e in range(len(ch)) if e not in [ch.index('Fp1'),ch.index('Fp2'),ch.index('Fpz'),64, 65, 66, 67, 68]]\n",
        "              T_x=np.array([ele[0][no_eog] for ele in splits])\n",
        "              T_y=np.array([ele[1] for ele in splits])\n",
        "            else:\n",
        "              dlt=-5\n",
        "              T_x=np.array([ele[0][:dlt] for ele in splits])\n",
        "              T_y=np.array([ele[1] for ele in splits])\n",
        "\n",
        "            T_x = torch.tensor(T_x)\n",
        "            T_y = torch.tensor(T_y)\n",
        "\n",
        "            if apply_euclidean==True:\n",
        "                x=apply_EA(T_x)\n",
        "            else : \n",
        "                x=T_x\n",
        "\n",
        "            sbj_x.append(x)\n",
        "            sbj_y.append(T_y)\n",
        "            del T_x, T_y\n",
        "\n",
        "\n",
        "    elif number_of_subjects==109:\n",
        "        bad_subjects=[s-1 for s in bad_subjects]\n",
        "        data=load_eeg_bci(path_mne=path)\n",
        "        for subject_id in [e for e in range(number_of_subjects) if e not in bad_subjects]:   \n",
        "            xx=[]\n",
        "            yy=[]\n",
        "            for records in range(len(data[subject_id])):\n",
        "                xx.append(data[subject_id][records][0])\n",
        "                yy.append(data[subject_id][records][1])\n",
        "            xx=torch.stack(xx)\n",
        "            yy=torch.tensor(yy)\n",
        "            if apply_euclidean==True:\n",
        "                sbj_x.append(apply_EA(xx))\n",
        "            else:\n",
        "                sbj_x.append(xx)\n",
        "            sbj_y.append(yy)\n",
        "\n",
        "    return sbj_x, sbj_y\n",
        "\n",
        "\n",
        "\n",
        "#################### Leave One Subject Out ############################\n",
        "def loso(x, y, number_of_subjects, loso, device, bad_subjects=[], with_validation=True): \n",
        "    l= number_of_subjects\n",
        "    [s-1 for s in bad_subjects]\n",
        "    T_x=torch.tensor([])\n",
        "    T_y=torch.tensor([])\n",
        "\n",
        "    loso=loso-1 # because lists start from 0\n",
        "\n",
        "    for subject_id in [e for e in range(l) if e not in [loso]+bad_subjects]:\n",
        "        T_x=torch.cat((T_x,x[subject_id]), 0)\n",
        "        T_y=torch.cat((T_y,y[subject_id]), 0)\n",
        "\n",
        "    T_x=torch.tensor(T_x).reshape([-1, T_x.shape[1], T_x.shape[2]])\n",
        "    T_y=torch.tensor(T_y).reshape([-1])\n",
        "\n",
        "    k_f=int(0.9*T_x.shape[0])\n",
        "\n",
        "    if with_validation==True:\n",
        "        data_perm = torch.randperm(T_x.shape[0])\n",
        "        temp_x, temp_y = T_x[data_perm[:]], T_y[data_perm[:]]\n",
        "        T_x, T_y = temp_x[:k_f], temp_y[:k_f]\n",
        "        V_x, V_y = temp_x[k_f:], temp_y[k_f:]\n",
        "    else :\n",
        "        V_x, V_y = torch.tensor([]), torch.tensor([])\n",
        "\n",
        "\n",
        "    Test_x=x[loso]\n",
        "    Test_y=y[loso]\n",
        "\n",
        "    \n",
        "    T_x, mean, std=standardize(T_x)\n",
        "    if with_validation==True:\n",
        "        V_x, _ , _=standardize(V_x,mean, std)\n",
        "    Test_x, _ , _=standardize(Test_x, mean, std)\n",
        "\n",
        "    ############################################################################\n",
        "    return(T_x.to(device),T_y.to(device).to(torch.int64),V_x.to(device),V_y.to(device).to(torch.int64),Test_x.to(device),Test_y.to(device).to(torch.int64))\n",
        "\n",
        "\n",
        "#################### Leave Multiple Subjects Out ############################\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def lmso(x, y, number_of_subjects, kfold, device, bad_subjects=[], with_validation=True, random_seed=42): \n",
        "    c = list(zip(x, y))\n",
        "    random.Random(random_seed).shuffle(c)\n",
        "    x, y = zip(*c)\n",
        "    \n",
        "    # 10-fold crossvalidation\n",
        "    kf = KFold(n_splits=10)\n",
        "\n",
        "    x=np.array([t.numpy() for t in x])\n",
        "    y=np.array([t.numpy() for t in y])\n",
        "\n",
        "\n",
        "    i=1\n",
        "    for train_index, test_index in kf.split(x):\n",
        "        X_train, X_test = x[train_index], x[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        if i==kfold:\n",
        "            break\n",
        "        else:\n",
        "            i+=1\n",
        "    \n",
        "\n",
        "    del c, kf\n",
        "\n",
        "    l= number_of_subjects\n",
        "    [s-1 for s in bad_subjects]\n",
        "\n",
        "    T_x=torch.tensor([])\n",
        "    T_y=torch.tensor([])\n",
        "    Test_x=torch.tensor([])\n",
        "    Test_y=torch.tensor([])\n",
        "\n",
        "    for subject_id in [e for e in range(X_train.shape[0])]:\n",
        "        T_x=torch.cat((T_x,torch.tensor(X_train[subject_id])), 0)\n",
        "        T_y=torch.cat((T_y,torch.tensor(y_train[subject_id])), 0)\n",
        "\n",
        "    T_x=torch.tensor(T_x).reshape([-1, T_x.shape[1], T_x.shape[2]])\n",
        "    T_y=torch.tensor(T_y).reshape([-1])\n",
        "\n",
        "    k_f=int(0.9*T_x.shape[0])\n",
        "\n",
        "    if with_validation==True:\n",
        "        data_perm = torch.randperm(T_x.shape[0])\n",
        "        temp_x, temp_y = T_x[data_perm[:]], T_y[data_perm[:]]\n",
        "        T_x, T_y = temp_x[:k_f], temp_y[:k_f]\n",
        "        V_x, V_y = temp_x[k_f:], temp_y[k_f:]\n",
        "    else :\n",
        "        V_x, V_y = torch.tensor([]), torch.tensor([])\n",
        "\n",
        "    for lms in range(len(X_test)):\n",
        "        Test_x=torch.cat((Test_x,torch.tensor(X_test[lms])), 0)\n",
        "        Test_y=torch.cat((Test_y,torch.tensor(y_test[lms])), 0)\n",
        "\n",
        "    Test_x=torch.tensor(Test_x).reshape([-1, Test_x.shape[1], Test_x.shape[2]])\n",
        "    Test_y=torch.tensor(Test_y).reshape([-1])\n",
        "    \n",
        "    T_x, mean, std=standardize(T_x)\n",
        "    if with_validation==True:\n",
        "        V_x, _ , _=standardize(V_x,mean, std)\n",
        "    Test_x, _ , _=standardize(Test_x, mean, std)\n",
        "    \n",
        "    ############################################################################\n",
        "    return(T_x.to(device),T_y.to(device).to(torch.int64),V_x.to(device),V_y.to(device).to(torch.int64),Test_x.to(device),Test_y.to(device).to(torch.int64))\n",
        "\n",
        "\n",
        "#############Data Augmentation ###########################################################\n",
        "from scipy.signal import butter, lfilter\n",
        "from random import gauss\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#add noise\n",
        "def chua(n):\n",
        "    alpha  = 15.6\n",
        "    beta   = 31\n",
        "    m0     = -1.143\n",
        "    m1     = -0.714\n",
        "\n",
        "    x=0.7\n",
        "    y=0\n",
        "    z=0\n",
        "\n",
        "    dt=0.01\n",
        "\n",
        "    sig=[]\n",
        "    sig1=[]\n",
        "\n",
        "    for i in range(n):\n",
        "        \n",
        "        phi=m1*x+0.5*(m0-m1)*(abs(x+1)-abs(x-1))\n",
        "        x1=alpha*(y-x-phi)\n",
        "        y1=x-y+z\n",
        "        z1=-beta*y\n",
        "\n",
        "        \n",
        "        x=x1*dt+x\n",
        "        y=y1*dt+y\n",
        "        z=z1*dt+z\n",
        "\n",
        "        sig.append(x)\n",
        "        sig1.append(y)\n",
        "\n",
        "    return sig\n",
        "\n",
        "def SNR_Set(Signal, Desired_SNR_dB):\n",
        "    Npts = len(Signal)\n",
        "    #Gaussian Noise\n",
        "##    Noise = [gauss(0.0, 1.0) for i in range(Npts)] # Generate initial noise;\n",
        "##                                                #mean zero, variance one\n",
        "    #Poisson noise\n",
        "    Noise = np.random.poisson(5, Npts)\n",
        "\n",
        "\n",
        "    #Chaotic noise (chua model)\n",
        "    #Noise = chua(Npts)\n",
        "\n",
        "\n",
        "    \n",
        "    Signal_Power = sum(abs(Signal)*abs(Signal))/Npts\n",
        "    absN=[abs(i) for i in Noise]\n",
        "    absnsqrd=[i*i for i in absN]\n",
        "    Noise_Power = sum(absnsqrd)/Npts\n",
        "            \n",
        "\n",
        "    K = (Signal_Power/Noise_Power)*10**(-Desired_SNR_dB/10)  \n",
        "\n",
        "    New_Noise = [math.sqrt(K)*i for i in Noise]\n",
        "\n",
        "    Noisy_Signal = Signal + New_Noise\n",
        "    return Noisy_Signal\n",
        "\n",
        "#flip channels\n",
        "def flip_channels(data):\n",
        "  r=torch.randperm(data.shape[1])\n",
        "  data=data[:,r,:]\n",
        "  return data\n",
        "\n",
        "#time inverse\n",
        "def time_inverse(data):\n",
        "  return torch.flip(data, [2])\n",
        "\n",
        "#Masking in %\n",
        "def masking(data,p):\n",
        "  x=data\n",
        "  mask=torch.FloatTensor(x.shape).uniform_() > p\n",
        "  masked_output = data * mask.int().float().to(device)\n",
        "  return masked_output\n",
        "\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "selection=['fc','ti','mask','filter']\n",
        "def apply_da(data,selection):\n",
        "  s=random.choice(selection)\n",
        "  if s=='fc':\n",
        "    data=flip_channels(data)\n",
        "  elif s=='ti':\n",
        "    data=time_inverse(data)\n",
        "  elif s=='mask':\n",
        "    data=masking(data,0.2)\n",
        "  elif s=='filter':\n",
        "    data=torch.tensor(butter_bandpass_filter(data.detach().cpu().numpy(),0.1, 40, 250)).float().to(device)\n",
        "  return data\n",
        "\n",
        "#####################################################################################\n",
        "\n",
        "def weight_attack(model, p=0.1):\n",
        "  ii=0\n",
        "  for i in model:\n",
        "    try:\n",
        "      r1=torch.max(model[ii].weight)\n",
        "      r2=torch.min(model[ii].weight)\n",
        "      M1=(r1 - r2) * torch.rand(model[ii].weight.shape)+ r2\n",
        "      M2=(torch.abs(M1)< p*(r1 - r2)).float()\n",
        "      with torch.no_grad():\n",
        "        M1=torch.flatten(M1)\n",
        "        M2=torch.flatten(M2)\n",
        "        mw=torch.flatten(model[2].weight)\n",
        "        shp=model[ii].weight.shape\n",
        "        for i in range(len(M1)):\n",
        "          if M2[i]==1:\n",
        "            mw[i]=M1[i]\n",
        "        mw=mw.double()\n",
        "\n",
        "        model[ii].weight=torch.nn.Parameter(mw.reshape(shp))\n",
        "    except:\n",
        "      pass\n",
        "    ii+=1\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egbHk-mvxavP"
      },
      "source": [
        "###coatnets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJS7JUooxdMO"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils import weight_norm\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "##############  EEG_CoatNet models #############################################################\n",
        "\n",
        "class PrintLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintLayer, self).__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Do your print / debug stuff here\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "class Ensure4d(nn.Module):\n",
        "    def forward(self, x):\n",
        "        while(len(x.shape) < 4):\n",
        "            x = x.unsqueeze(-1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Expression(nn.Module):\n",
        "    \"\"\"Compute given expression on forward pass.\n",
        "    Parameters\n",
        "    ----------\n",
        "    expression_fn : callable\n",
        "        Should accept variable number of objects of type\n",
        "        `torch.autograd.Variable` to compute its output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, expression_fn):\n",
        "        super(Expression, self).__init__()\n",
        "        self.expression_fn = expression_fn\n",
        "\n",
        "    def forward(self, *x):\n",
        "        return self.expression_fn(*x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if hasattr(self.expression_fn, \"func\") and hasattr(\n",
        "            self.expression_fn, \"kwargs\"\n",
        "        ):\n",
        "            expression_str = \"{:s} {:s}\".format(\n",
        "                self.expression_fn.func.__name__, str(self.expression_fn.kwargs)\n",
        "            )\n",
        "        elif hasattr(self.expression_fn, \"__name__\"):\n",
        "            expression_str = self.expression_fn.__name__\n",
        "        else:\n",
        "            expression_str = repr(self.expression_fn)\n",
        "        return (\n",
        "            self.__class__.__name__ +\n",
        "            \"(expression=%s) \" % expression_str\n",
        "        )\n",
        "\n",
        "############## Multi-head Attention Mechanism #################################################\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
        "    attn_logits = attn_logits / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
        "    attention = F.softmax(attn_logits, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Stack all weight matrices 1...h together for efficiency\n",
        "        # Note that in many implementations you see \"bias=False\" which is optional\n",
        "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
        "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        # Original Transformer initialization, see PyTorch documentation\n",
        "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
        "        self.qkv_proj.bias.data.fill_(0)\n",
        "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
        "        self.o_proj.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None, return_attention=False):\n",
        "        batch_size, seq_length, embed_dim = x.size()\n",
        "        qkv = self.qkv_proj(x)\n",
        "\n",
        "        # Separate Q, K, V from linear output\n",
        "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        # Determine value outputs\n",
        "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
        "        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n",
        "        values = values.reshape(batch_size, seq_length, self.embed_dim)\n",
        "        o = self.o_proj(values)\n",
        "\n",
        "        if return_attention:\n",
        "            return o, attention\n",
        "        else:\n",
        "            return o\n",
        "\n",
        "\n",
        "\n",
        "############## stem_stage (reducing temporal dimension) #################################################\n",
        "class stem_stage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, k ):\n",
        "        super().__init__()\n",
        "        def _permute(x):\n",
        "            '''\n",
        "            Permutes data:\n",
        "            from dim:\n",
        "            batch, chans, time, 1\n",
        "            to dim:\n",
        "            batch, chans, 1, time'''\n",
        "            return x.permute([0, 1, 3, 2])\n",
        "\n",
        "        prnt=PrintLayer()\n",
        "      \n",
        "        layers = [Ensure4d(),\n",
        "                Expression(_permute),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=(1,k)),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.GELU()\n",
        "                ]\n",
        "\n",
        "        self.model= nn.Sequential(*layers)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "############## conv_stage #################################################\n",
        "class conv_stage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_ch, conv_kernel, pool_kernel):\n",
        "        super().__init__()\n",
        "\n",
        "        prnt=PrintLayer()\n",
        "        self.pool=nn.AvgPool2d(kernel_size=(1, pool_kernel))\n",
        "        self.res=nn.Conv2d(in_channels, out_channels, kernel_size=(1,1), padding='same')\n",
        "        layers = [nn.BatchNorm2d(in_channels),\n",
        "                  nn.Conv2d(in_channels, out_channels, kernel_size=(1,1), padding='same'),\n",
        "                  nn.Conv2d(in_channels=n_ch, out_channels=n_ch, kernel_size=(1,conv_kernel),groups=n_ch, padding='same'),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=(1,1), padding='same'),\n",
        "                nn.ReLU()\n",
        "                ]\n",
        "\n",
        "        self.model= nn.Sequential(*layers)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return self.pool(self.res(x))+self.pool(self.model(x))\n",
        "\n",
        "############## InceptionBlock #################################################\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_ch, kernel_list, pool_kernel):        \n",
        "        super().__init__()\n",
        "\n",
        "        self.branch1 = conv_stage(in_channels, out_channels, n_ch, conv_kernel=kernel_list[0], pool_kernel=2)\n",
        "        self.branch2 = conv_stage(in_channels, out_channels, n_ch, conv_kernel=kernel_list[1], pool_kernel=2)\n",
        "        self.branch3 = conv_stage(in_channels, out_channels, n_ch, conv_kernel=kernel_list[2], pool_kernel=2)\n",
        "        self.branch4 = conv_stage(in_channels, out_channels, n_ch, conv_kernel=kernel_list[3], pool_kernel=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branches = (self.branch1, self.branch2, self.branch3, self.branch4)\n",
        "        return torch.cat([branch(x) for branch in branches], 1)\n",
        "\n",
        "\n",
        "############## att_stage #################################################\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x): \n",
        "        return self.net(x)\n",
        "        \n",
        "class att_stage(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, in_channels, temp_dim, pool_kernel, incep=1, masking_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        prnt=PrintLayer()\n",
        "        self.mr=masking_rate\n",
        "        self.incep=incep\n",
        "        self.ed=embed_dim\n",
        "        self.ic= in_channels\n",
        "        self.ln=nn.LayerNorm(temp_dim)\n",
        "        self.mha=MultiheadAttention(temp_dim ,embed_dim, num_heads)\n",
        "        self.ffn=FeedForward(temp_dim, temp_dim, embed_dim)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x=torch.squeeze(x)\n",
        "      #x1=self.pool(x)\n",
        "      x1=self.ffn(x)\n",
        "      x=self.ln(x)\n",
        "      #x=self.pool(x)\n",
        "      mask=(torch.cuda.FloatTensor(self.ic*self.incep, self.ic*self.incep).uniform_() > self.mr).type(torch.uint8)\n",
        "      x,s=self.mha(x, mask, return_attention=True)\n",
        "      return x+x1.reshape([-1,self.ic*self.incep,self.ed]),  s\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#residual block\n",
        "class residual_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, k, p,stride=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          in_channels (int):  Number of input channels.\n",
        "          out_channels (int): Number of output channels.\n",
        "          stride (int):       Controls the stride.\n",
        "        \"\"\"\n",
        "        super(residual_block, self).__init__()\n",
        "\n",
        "        self.skip = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "          self.skip = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, padding='same', bias=False),\n",
        "            nn.AvgPool2d(kernel_size=(1,p)),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "        else:\n",
        "          self.skip = None\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1,k), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,p)),\n",
        "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(1,k), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.block(x)\n",
        "      out += (x if self.skip is None else self.skip(x))\n",
        "      out = F.relu(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "############## CoatNet #################################################\n",
        "class coatnet(nn.Module):\n",
        "    def __init__(self, n_classes, n_channels, embed_dim, num_heads, conv_kernel, pool_kernel, incep=4):\n",
        "        super().__init__()\n",
        "\n",
        "        n_ch=n_channels\n",
        "        self.s0=stem_stage(n_ch, n_ch, pool_kernel)\n",
        "        self.s11= InceptionBlock(n_ch, n_ch, n_ch, [8, 12 ,16 ,24], pool_kernel)\n",
        "        self.s12= InceptionBlock(n_ch*4, n_ch*4, n_ch*4, [4, 8 ,16 ,32], pool_kernel)\n",
        "        temp_dim=281\n",
        "        self.s2=att_stage(128, num_heads, 14, temp_dim, pool_kernel, incep)\n",
        "        self.res1=residual_block(4, 1, 3, 1,stride=2)\n",
        "\n",
        "        self.classifier=nn.Linear(n_ch*embed_dim*incep, n_classes)\n",
        "        self.classifier=nn.Linear(3934, n_classes)\n",
        "\n",
        "\n",
        "\n",
        "        #================================\n",
        "        num_heads=1\n",
        "        in_channels=n_channels\n",
        "        drop_rate=0.4\n",
        "        self.block11= nn.Sequential(* [nn.Conv2d(num_heads, 2, kernel_size = (1, 16), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(2),\n",
        "                        DepthwiseConv2d(2,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(2),\n",
        "                        nn.ELU()] )\n",
        "        self.block12= nn.Sequential(* [torch.nn.Conv2d(num_heads, 4, kernel_size = (1, 32), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(4),\n",
        "                        DepthwiseConv2d(4,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(4),\n",
        "                        nn.ELU()] )\n",
        "        self.block13= nn.Sequential(* [torch.nn.Conv2d(num_heads, 8, kernel_size = (1, 64), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(8),\n",
        "                        DepthwiseConv2d(8,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(8),\n",
        "                        nn.ELU()] )\n",
        "\n",
        "        self.pool1 = nn.Sequential(* [nn.AvgPool2d(kernel_size=(1,4)), \n",
        "                      nn.Dropout(drop_rate)] )\n",
        "\n",
        "\n",
        "        #================================\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x=x.reshape([-1,1,25,1125])\n",
        "      branches = (self.block11, self.block12, self.block13)\n",
        "      x = torch.cat([branch(x) for branch in branches], 1)\n",
        "      x = self.pool1(x)\n",
        "      #print(x.shape)\n",
        "      x=torch.flatten(x, 1)\n",
        "      x=self.classifier(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRVTk7t38lYW",
        "outputId": "8db8e9e9-00fb-4fa9-fdab-e6c18acb9b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396868\n"
          ]
        }
      ],
      "source": [
        "eeg = torch.randn(60,25,1125).to(device)\n",
        "network=coatnet(n_classes=4, n_channels=25, embed_dim=64, num_heads=8, conv_kernel=10, pool_kernel=2, incep=1).to(device)\n",
        "print(sum(p.numel() for p in network.parameters() if p.requires_grad))\n",
        "out=network(eeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFD8PaKX3zd8"
      },
      "source": [
        "### Yassine's cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yn8AKgj37ed"
      },
      "outputs": [],
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, n_chan, fm, n_convs, init_pool, kernel_size):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.pool = torch.nn.AvgPool1d(init_pool)\n",
        "        self.conv = torch.nn.Conv1d(n_chan, fm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)\n",
        "        self.bn = torch.nn.BatchNorm1d(fm)\n",
        "        self.blocks = []\n",
        "        newfm = fm\n",
        "        oldfm = fm\n",
        "        for i in range(n_convs):\n",
        "            if i > 0:\n",
        "                newfm = int(1.414 * newfm)\n",
        "            self.blocks.append(torch.nn.Sequential(\n",
        "                (torch.nn.Conv1d(oldfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.MaxPool1d(2) if i > 0 - 1 else torch.nn.MaxPool1d(1)),\n",
        "                (torch.nn.ReLU()),\n",
        "                (torch.nn.Conv1d(newfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.ReLU())\n",
        "            ))\n",
        "            oldfm = newfm\n",
        "        self.blocks = torch.nn.ModuleList(self.blocks)\n",
        "        self.fc = torch.nn.Linear(oldfm, 4)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        y = torch.relu(self.bn(self.conv(self.pool(x))))\n",
        "        for seq in self.blocks:\n",
        "            y = seq(y)\n",
        "        y = y.mean(dim = 2)\n",
        "        return self.fc(y)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg = torch.randn(60,25,1125).to(device)\n",
        "params = [64, 4, 4, 7]\n",
        "network=ConvNet(eeg.shape[1], params[0], params[1], params[2], params[3]).to(device)\n",
        "print(sum(p.numel() for p in network.parameters() if p.requires_grad))\n",
        "out=network(eeg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay7z6kBosjIs",
        "outputId": "96b76760-bf47-4884-bf60-8a3c885e80a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EEG-ITNET"
      ],
      "metadata": {
        "id": "twDHAI6bG11k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseConv2d(torch.nn.Conv2d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 depth_multiplier=2,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 bias=True,\n",
        "                 padding_mode='zeros'\n",
        "                 ):\n",
        "        out_channels = in_channels * depth_multiplier\n",
        "        super().__init__(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "            dilation=dilation,\n",
        "            groups=in_channels,\n",
        "            bias=bias,\n",
        "            padding_mode=padding_mode\n",
        "        )\n",
        "\n",
        "\n",
        "#===================     EEG-ITNet       =====================================================================   \n",
        "   \n",
        "class EEG_ITNET(nn.Module):\n",
        "    def __init__(self, n_classes, in_channels):\n",
        "        super().__init__()\n",
        "        drop_rate=0.4\n",
        "        self.block11= nn.Sequential(* [nn.Conv2d(1, 2, kernel_size = (1, 16), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(2),\n",
        "                        DepthwiseConv2d(2,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(2),\n",
        "                        nn.ELU()] )\n",
        "        self.block12= nn.Sequential(* [torch.nn.Conv2d(1, 4, kernel_size = (1, 32), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(4),\n",
        "                        DepthwiseConv2d(4,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(4),\n",
        "                        nn.ELU()] )\n",
        "        self.block13= nn.Sequential(* [torch.nn.Conv2d(1, 8, kernel_size = (1, 64), padding = 'same', bias=False),\n",
        "                        nn.BatchNorm2d(8),\n",
        "                        DepthwiseConv2d(8,kernel_size=(in_channels, 1),depth_multiplier=1, bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(8),\n",
        "                        nn.ELU()] )\n",
        "\n",
        "        self.pool1 = nn.Sequential(* [nn.AvgPool2d(kernel_size=(1,4)), \n",
        "                      nn.Dropout(drop_rate)] )\n",
        "\n",
        "        #================================\n",
        "\n",
        "        self.block2= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 1), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "\n",
        "        self.block3= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 1), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate) ] )\n",
        "\n",
        "        #================================\n",
        "\n",
        "\n",
        "        self.block4= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 2), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "        self.block5= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 2), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "        #================================\n",
        "\n",
        "        self.block6= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 4), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "        self.block7= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 4), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate) ] )\n",
        "                        \n",
        "        #================================\n",
        "\n",
        "        self.block8= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 8), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "        self.block9= nn.Sequential(* [DepthwiseConv2d(14,kernel_size=(1,4),depth_multiplier=1, dilation=(1, 8), bias=False, padding='valid'),\n",
        "                        nn.BatchNorm2d(14),\n",
        "                        nn.ELU(),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "        #================================\n",
        "\n",
        "        self.block_reduce= nn.Sequential(* [nn.Conv2d(14, 28, kernel_size = (1, 1)),\n",
        "                        nn.BatchNorm2d(28),\n",
        "                        nn.ELU(),\n",
        "                        nn.AvgPool2d((1,4)),\n",
        "                        nn.Dropout(drop_rate)] )\n",
        "\n",
        "\n",
        "      \n",
        "        self.classifier=nn.Linear(644, n_classes)\n",
        "        self.m = nn.Softmax(dim=1)\n",
        "          \n",
        "\n",
        "    def forward(self, x):\n",
        "      x=x.reshape([-1,1,x.shape[1],x.shape[2]])\n",
        "      branches = (self.block11, self.block12, self.block13)\n",
        "      x = torch.cat([branch(x) for branch in branches], 1)\n",
        "      x = self.pool1(x)\n",
        "      x1=x\n",
        "      #================================\n",
        "      paddings = (3,0, 0,0, 0,0, 0,0)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block2(x)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block3(x)+x1\n",
        "      x1=x\n",
        "      #================================\n",
        "      paddings = (6,0, 0,0, 0,0, 0,0)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block4(x)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block5(x)+x1\n",
        "      x1=x\n",
        "      #================================\n",
        "      paddings = (12,0, 0,0, 0,0, 0,0)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block6(x)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block7(x)+x1\n",
        "      x1=x\n",
        "      #================================\n",
        "      paddings = (24,0, 0,0, 0,0, 0,0)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block8(x)\n",
        "      x = nn.functional.pad(x, paddings)\n",
        "      x=self.block9(x)+x1\n",
        "      #================================\n",
        "      x=self.block_reduce(x)\n",
        "      #================================\n",
        "      x=torch.flatten(x, 1)\n",
        "      x=self.classifier(x)\n",
        "\n",
        "      return self.m(x)\n"
      ],
      "metadata": {
        "id": "1XdCr8caG2K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg = torch.randn(60,22,375).to(device)\n",
        "network=EEG_ITNET(n_classes=4, in_channels=22).to(device)\n",
        "print(sum(p.numel() for p in network.parameters() if p.requires_grad))\n",
        "out=network(eeg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RuAHzz5HVFh",
        "outputId": "e65d1ee8-4d2c-40da-c53c-f5cfbf784c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHgle-E9cYTo"
      },
      "source": [
        "###Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWBlu9QAcYEw"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils import weight_norm\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "##############  Attention mechanism (still on testing phase) #############################################################\n",
        "\n",
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "    \n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "        \n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "        \n",
        "    output = torch.matmul(scores, v)\n",
        "    return output\n",
        "###############################################################\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // heads\n",
        "        self.h = heads\n",
        "        \n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        \n",
        "        bs = q.size(0)\n",
        "        \n",
        "        # perform linear operation and split into h heads\n",
        "        \n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "        \n",
        "        # transpose to get dimensions bs * h * sl * d_model\n",
        "       \n",
        "        k = k.transpose(1,2)\n",
        "        q = q.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "        # calculate attention using function we will define next\n",
        "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
        "        \n",
        "        # concatenate heads and put through final linear layer\n",
        "        concat = scores.transpose(1,2).contiguous()\\\n",
        "        .view(bs, -1, self.d_model)\n",
        "        \n",
        "        output = self.out(concat)\n",
        "    \n",
        "        return output\n",
        "\n",
        "\n",
        "##############  TIDNet modules #############################################################\n",
        "\n",
        "class PrintLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintLayer, self).__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Do your print / debug stuff here\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "class Ensure4d(nn.Module):\n",
        "    def forward(self, x):\n",
        "        while(len(x.shape) < 4):\n",
        "            x = x.unsqueeze(-1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Expression(nn.Module):\n",
        "    \"\"\"Compute given expression on forward pass.\n",
        "    Parameters\n",
        "    ----------\n",
        "    expression_fn : callable\n",
        "        Should accept variable number of objects of type\n",
        "        `torch.autograd.Variable` to compute its output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, expression_fn):\n",
        "        super(Expression, self).__init__()\n",
        "        self.expression_fn = expression_fn\n",
        "\n",
        "    def forward(self, *x):\n",
        "        return self.expression_fn(*x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if hasattr(self.expression_fn, \"func\") and hasattr(\n",
        "            self.expression_fn, \"kwargs\"\n",
        "        ):\n",
        "            expression_str = \"{:s} {:s}\".format(\n",
        "                self.expression_fn.func.__name__, str(self.expression_fn.kwargs)\n",
        "            )\n",
        "        elif hasattr(self.expression_fn, \"__name__\"):\n",
        "            expression_str = self.expression_fn.__name__\n",
        "        else:\n",
        "            expression_str = repr(self.expression_fn)\n",
        "        return (\n",
        "            self.__class__.__name__ +\n",
        "            \"(expression=%s) \" % expression_str\n",
        "        )\n",
        "\n",
        "\n",
        "class _TemporalFilter(nn.Module):\n",
        "    def __init__(self, in_chans, filters, depth, temp_len, drop_prob=0., activation=nn.LeakyReLU,\n",
        "                 residual='netwise'):\n",
        "        super().__init__()\n",
        "        temp_len = temp_len + 1 - temp_len % 2\n",
        "        self.residual_style = str(residual)\n",
        "        net = list()\n",
        "\n",
        "        for i in range(depth):\n",
        "            dil = depth - i\n",
        "            conv = weight_norm(nn.Conv2d(in_chans if i == 0 else filters, filters,\n",
        "                                         kernel_size=(1, temp_len), dilation=dil,\n",
        "                                         padding=(0, dil * (temp_len - 1) // 2)))\n",
        "            net.append(nn.Sequential(\n",
        "                conv,\n",
        "                activation(),\n",
        "                nn.Dropout2d(drop_prob)\n",
        "            ))\n",
        "        if self.residual_style.lower() == 'netwise':\n",
        "            self.net = nn.Sequential(*net)\n",
        "            self.residual = nn.Conv2d(in_chans, filters, (1, 1))\n",
        "        elif residual.lower() == 'dense':\n",
        "            self.net = net\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.residual_style.lower() == 'netwise':\n",
        "            return self.net(x) + self.residual(x)\n",
        "        elif self.residual_style.lower() == 'dense':\n",
        "            for layer in self.net:\n",
        "                x = torch.cat((x, layer(x)), dim=1)\n",
        "            return x\n",
        "\n",
        "\n",
        "############## MLP blocks #################################################\n",
        "class MLP_blocks(nn.Module):\n",
        "    def __init__(self, arch, in_channels):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prnt=PrintLayer()\n",
        "        for x in arch:\n",
        "            layers += [nn.Linear(in_channels, x),\n",
        "                        nn.BatchNorm1d(x),\n",
        "                        nn.ReLU()]\n",
        "            in_channels = x\n",
        "\n",
        "        self.model= nn.Sequential(*layers)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "############## spatial convs(electrodes,1) (electrode aggregator)  (still on testing phase) #################################################\n",
        "class spatial_aggregator(nn.Module):\n",
        "    def __init__(self, out, in_channels, k ):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "            \n",
        "        layers += [nn.Conv2d(in_channels, out, (k,1)),\n",
        "                    nn.BatchNorm2d(out),\n",
        "                    nn.ReLU(),\n",
        "                    nn.AvgPool2d(kernel_size=(7,1), stride=(1,2))]\n",
        "\n",
        "        self.model= nn.Sequential(*layers)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "############## electrode weight-sharing convs(1,1) (a.k.a 1x1encoders) #################################################\n",
        "class SharedSpaceTimeConv1x1(nn.Module):\n",
        "    def __init__(self, mode, arch, in_channels):\n",
        "        super().__init__()\n",
        "        def _permute(x):\n",
        "            \"\"\"\n",
        "            Permutes data:\n",
        "            from dim:\n",
        "            batch, chans, time, 1\n",
        "            to dim:\n",
        "            batch, 1, chans, time\n",
        "            \"\"\"\n",
        "            return x.permute([0, 3, 1, 2])\n",
        "        prnt=PrintLayer()\n",
        "        if mode=='1x1':\n",
        "            layers = [Ensure4d(),\n",
        "                Expression(_permute),]\n",
        "            in_channels = 1\n",
        "        else:\n",
        "            layers = []\n",
        "        for x in arch:\n",
        "            s=str(x)\n",
        "            if s[0] == 'A':\n",
        "                layers += [nn.AvgPool2d(kernel_size=(1, int(s[1:])), stride=(1,2))]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU()]\n",
        "                in_channels = x\n",
        "\n",
        "        self.model= nn.Sequential(*layers)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "\n",
        "############## TIDNet temporal block #################################################\n",
        "class TemporalTIDNet(nn.Module):\n",
        "    def __init__(self, t_filters, input_window_samples, drop_prob, pooling,\n",
        "                 temp_layers,  temp_span):\n",
        "        super().__init__()\n",
        "        self.temp_len = ceil(temp_span * input_window_samples)\n",
        "\n",
        "        def _permute(x):\n",
        "            \"\"\"\n",
        "            Permutes data:\n",
        "            from dim:\n",
        "            batch, chans, time, 1\n",
        "            to dim:\n",
        "            batch, 1, chans, time\n",
        "            \"\"\"\n",
        "            return x.permute([0, 3, 1, 2])\n",
        "\n",
        "        self.temporal = nn.Sequential(\n",
        "            Ensure4d(),\n",
        "            Expression(_permute),\n",
        "            _TemporalFilter(1, t_filters, depth=temp_layers, temp_len=self.temp_len),\n",
        "            nn.MaxPool2d((1, pooling)),\n",
        "            nn.Dropout2d(drop_prob),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.temporal(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "###################################################################################### \n",
        "\n",
        "class TemporalShareSpaceTime(nn.Module):\n",
        "\n",
        "    def __init__(self, mode, arch, n_classes, in_chans, input_window_samples, t_filters,\n",
        "                 drop_prob, pooling, temp_layers, temp_span):\n",
        "        super().__init__()\n",
        "        def compute_params(arch,h,w):\n",
        "            ### height and width of the input convolutions of each feature map\n",
        "            #### compute the number of inputs after flatten ######\n",
        "            for i in arch:\n",
        "                s=str(i)\n",
        "                if s[0] == 'A':\n",
        "                    w=int((w-int(s[1:]))/2 +1 )     #for average pooling we apply:  [(Output width + padding width right + padding width left - kernel width) / (stride width)] + 1\n",
        "            s=str(i)\n",
        "            if s[0] == 'A':\n",
        "                last_filter=arch[-2]\n",
        "            else:\n",
        "                last_filter=arch[-1]\n",
        "            return int(last_filter*h*w)\n",
        "\n",
        "        self.mode=mode\n",
        "        self.n_classes = n_classes\n",
        "        self.in_chans = in_chans\n",
        "        self.input_window_samples = input_window_samples\n",
        "        self.temp_len = ceil(temp_span * input_window_samples)\n",
        "        self.params=compute_params(arch,in_chans,ceil((input_window_samples/pooling)-1))   \n",
        "        \n",
        "        ######################################################\n",
        "        \n",
        "        if self.mode!='1x1':\n",
        "            self.tidnet_temp = TemporalTIDNet(t_filters=t_filters,\n",
        "                                     input_window_samples=input_window_samples,\n",
        "                                     drop_prob=drop_prob, pooling=pooling, temp_layers=temp_layers,\n",
        "                                     temp_span=temp_span)     \n",
        "\n",
        "        if self.mode=='1x1' or self.mode=='t+1x1':\n",
        "            self.model = SharedSpaceTimeConv1x1(self.mode, arch, t_filters) \n",
        "            if self.mode=='1x1':\n",
        "                self.params=compute_params(arch,in_chans,input_window_samples)\n",
        "            self.fc_block = nn.Linear(self.params, self.n_classes)\n",
        "        elif self.mode=='mlp':\n",
        "            self.model = MLP_blocks(arch, in_chans*ceil((input_window_samples/pooling))*t_filters)\n",
        "            self.fc_block = nn.Linear(arch[-1], self.n_classes)\n",
        "\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: torch.Tensor\n",
        "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
        "        \"\"\"\n",
        "        if self.mode!='1x1':\n",
        "            x = self.tidnet_temp(x)\n",
        "        \n",
        "        if self.mode!='mlp':\n",
        "            x = self.model(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            out = self.fc_block(x)\n",
        "\n",
        "        else :\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.model(x)\n",
        "            out = self.fc_block(x)\n",
        "        return out\n",
        "    \n",
        "    def get_emb(self, x):\n",
        "        return self.tidnet_temp(x)\n",
        "\n",
        "############################################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFbiJbUcchBA"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LppaUdf-chNA"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import os\n",
        "import torch \n",
        "from torch import optim\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchinfo import summary\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "from braindecode.models import EEGNetv4,TIDNet, EEGResNet\n",
        "def build_network(mode, arch, n_classes=4, in_chans=25, input_window_samples=1125, t_filters=32,\n",
        "                 drop_prob=0.4, pooling=15, temp_layers=2, temp_span=0.05):\n",
        "    #model=coatnet(n_classes=4, n_channels=25, embed_dim=64, num_heads=8, conv_kernel=10, pool_kernel=2, incep=1).to(device)\n",
        "    #model=RNN(input_size=1125, hidden_size=128 , num_layers=4, num_classes=4).to('cuda')\n",
        "    #model=TemporalShareSpaceTime(mode, arch, n_classes, in_chans, input_window_samples, t_filters,\n",
        "    #             drop_prob, pooling, temp_layers, temp_span)\n",
        "    model=EEGNetv4(in_chans,n_classes,input_window_samples)\n",
        "\n",
        "    #params = [64, 4, 4, 7]\n",
        "    #model=ConvNet(in_chans, params[0], params[1], params[2], params[3])\n",
        "    #model=EEG_ITNET(n_classes=4, in_channels=22).to(device)\n",
        "  \n",
        "    return model\n",
        "\n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9, weight_decay=0.5*0.001)\n",
        "    elif optimizer == \"adamw\":\n",
        "        optimizer = optim.AdamW(network.parameters(),\n",
        "                               lr=learning_rate,  weight_decay=0.01, amsgrad=True)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "\n",
        "####### Training using mixup #####################################################################\n",
        "def mixup_data(x, y, alpha=5.0, beta=5.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, beta)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "def train_mixup(network, optimizer, train_loader):\n",
        "    cumu_loss = 0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    criterion = torch.nn.CrossEntropyLoss()   \n",
        "    \n",
        "    network.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):    \n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass :\n",
        "        ## implement mixup with alpha preset to 2\n",
        "        inputs, targets_a, targets_b, lam = mixup_data(data, target, use_cuda=True)\n",
        "        inputs, targets_a, targets_b = map(Variable, (inputs,\n",
        "                                                    targets_a, targets_b))\n",
        "\n",
        "\n",
        "        outputs = network(inputs)\n",
        "\n",
        "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "        \n",
        "        cumu_loss += loss.item()\n",
        "    \n",
        "        # ⬅ Backward pass + weight update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # compute accuracy\n",
        "        # Get predictions from the maximum value\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Total number of labels\n",
        "        total += target.size(0)\n",
        "        correct += (lam * predicted.eq(targets_a.data).cpu().sum().float()\n",
        "                    + (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float())\n",
        "\n",
        "\n",
        "\n",
        "    return cumu_loss / batch_idx*data.shape[0], correct/total\n",
        "############################################################################\n",
        "\n",
        "def train_epoch(network, optimizer, train_loader):\n",
        "    cumu_loss = 0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    network.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):        \n",
        "\n",
        "        r=random.uniform(0, 1)\n",
        "        #if r<0.52:\n",
        "          #data=apply_da(data,selection)\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass \n",
        "\n",
        "        outputs = network(data)\n",
        "        loss = F.cross_entropy(outputs, target)\n",
        "        cumu_loss += loss.item()\n",
        "    \n",
        "        # ⬅ Backward pass + weight update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        # compute accuracy\n",
        "        # Get predictions from the maximum value\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Total number of labels\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum()\n",
        "\n",
        "\n",
        "    return cumu_loss / batch_idx*data.shape[0], correct/total\n",
        "\n",
        "\n",
        "def validate_epoch(network, valid_loader):\n",
        "    cumu_loss = 0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    network.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):  \n",
        "\n",
        "            loss = F.cross_entropy(network(data), target)\n",
        "            cumu_loss += loss.item()     \n",
        "\n",
        "            # compute accuracy\n",
        "            outputs = network(data)\n",
        "\n",
        "            # Get predictions from the maximum value\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Total number of labels\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum()   \n",
        "\n",
        "    \n",
        "    return cumu_loss / batch_idx*data.shape[0], correct/total\n",
        "\n",
        "\n",
        "def test(network, test_loader , classes):\n",
        "    n_classes=len(classes)\n",
        "    # Calculate Accuracy\n",
        "    correct = 0.0\n",
        "    correct_arr = [0.0] * n_classes\n",
        "    total = 0.0\n",
        "    total_arr = [0.0] * n_classes\n",
        "    y_true=[]\n",
        "    y_pred=[]\n",
        "    pred_probs=[]\n",
        "    # Iterate through test dataset\n",
        "    network.eval()   #network.train()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):  \n",
        "\n",
        "            outputs = network(data)\n",
        "            \n",
        "            # Get predictions from the maximum value\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # Total number of labels\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum()\n",
        "            y_true.append(target.cpu().detach().numpy())\n",
        "            y_pred.append(predicted.cpu().detach().numpy())\n",
        "            pred_probs.append(outputs.data.cpu().detach().numpy())\n",
        "            \n",
        "            for label in range(n_classes):\n",
        "                correct_arr[label] += (((predicted == target) & (target==label)).sum())\n",
        "                total_arr[label] += (target == label).sum()\n",
        "    \n",
        "    \n",
        "    y_true=np.array(y_true[:-1]).reshape([-1])\n",
        "    y_pred=np.array(y_pred[:-1]).reshape([-1])\n",
        "    pred_probs=np.array(pred_probs[:-1]).reshape([-1,n_classes])\n",
        "\n",
        "\n",
        "    '''# Confusion Matrices\n",
        "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                        y_true=y_true , preds=y_pred ,\n",
        "                        class_names=classes)})\n",
        "\n",
        "\n",
        "    # ROC\n",
        "    wandb.log({\"roc\" : wandb.plot.roc_curve(  y_true , pred_probs ,\n",
        "                            labels=classes)})\n",
        "\n",
        "\n",
        "    # Precision Recall Curve\n",
        "    wandb.log({\"pr\" : wandb.plot.pr_curve( y_true , pred_probs ,\n",
        "                        labels=classes, classes_to_plot=None)})'''\n",
        "\n",
        "    \n",
        "    f1=f1_score( y_true, y_pred, average='macro')\n",
        "    wandb.log({'Test macro F1-Score': f1})\n",
        "    print(f1)\n",
        "    accuracy = correct / total\n",
        "    print('TEST ACCURACY {} '.format(accuracy))\n",
        "                          \n",
        "    return accuracy, f1\n",
        "\n",
        "\n",
        "\n",
        "def train_sweep(x, y, number_of_subjects, device, bad_subjects, config, run, resultdir):\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    run_name = run.name\n",
        "    batch_size= 128 #config.batch_size\n",
        "    patience = 15 #config.patience\n",
        "    LR=1e-3 #config.learning_rate\n",
        "    optim='adamw' #config.optimizer\n",
        "    \n",
        "    '''mode=config.mode\n",
        "    design=config.design\n",
        "    p= config.power_2_of_filters\n",
        "    v=1\n",
        "    if mode!='mlp':\n",
        "        v=config.power_2_of_Avg_pooling\n",
        "\n",
        "\n",
        "    \n",
        "    if design=='inverse_bottleneck':\n",
        "        p=p-2\n",
        "        v=1\n",
        "    elif design=='bottleneck':\n",
        "        p=p+3\n",
        "    elif design=='fixed':\n",
        "        v=1\n",
        "    arch=[]\n",
        "\n",
        "    # Building the design\n",
        "    for i in range(config.number_of_layers):\n",
        "        arch.append(2**p)\n",
        "        if mode!='mlp':\n",
        "            arch.append('A'+str(2**v))\n",
        "        if design=='bottleneck':\n",
        "            p-=1\n",
        "            v-=1\n",
        "            if v<1:\n",
        "                v=1\n",
        "        elif design=='inverse_bottleneck':\n",
        "            p+=1\n",
        "            if p>6:\n",
        "                p=6\n",
        "    print(arch)'''\n",
        "\n",
        "\n",
        "    mode='mlp'\n",
        "    arch=[16,16,16,16,16]\n",
        "    network = build_network(mode, arch, n_classes=2, in_chans=61, input_window_samples=1024).to(device)\n",
        "    pytorch_total_params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
        "    wandb.log({\"total number of parameters\": pytorch_total_params})\n",
        "    optimizer=build_optimizer(network, optim, LR)\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 40, gamma = 0.1)\n",
        "    \n",
        "    classes=['left fist', 'right fist']#, 'eyes_open', 'MI O/C feet']\n",
        "\n",
        "    kfold= config.subject\n",
        "\n",
        "    T_x,T_y,V_x,V_y,Test_x,Test_y=lmso(x, y, number_of_subjects, kfold, device, bad_subjects, with_validation=False)\n",
        "    train_loader, valid_loader, test_loader=loaders(kfold, T_x, T_y, V_x, V_y, Test_x, Test_y, batch_size)\n",
        "\n",
        "    Train_acc=[]\n",
        "    Val_acc=[]\n",
        "    Train_loss=[]\n",
        "    Val_loss=[]\n",
        "    Test_acc=[]\n",
        "    ## Tensorboard iterators\n",
        "    tr_iter=0\n",
        "    v_itr=0\n",
        "    maxv=0\n",
        "    cpt_early = 0\n",
        "\n",
        "    for epoch in range(100): #config.epochs):\n",
        "        train_loss,train_acc = train_epoch(network, optimizer, train_loader)\n",
        "        print('train loss {} accuracy {} epoch {} done'.format(train_loss,train_acc,epoch))\n",
        "        #scheduler.step()\n",
        "      \n",
        "        wandb.log({'Training accuracy': train_acc,'Training loss': train_loss});   ## use this when no validation set is used\n",
        "\n",
        "        '''val_loss,val_acc = validate_epoch(network, valid_loader)\n",
        "        #print('val loss {} epoch {} done'.format(val_loss,epoch))\n",
        "\n",
        "        Train_acc.append(train_acc)\n",
        "        Val_acc.append(val_acc)\n",
        "        Train_loss.append(train_loss)\n",
        "        #Val_loss.append(val_loss)\n",
        "        #wandb.log({'Training accuracy': train_acc,'Training loss': train_loss,'Validation accuracy': val_acc,'Validation loss': val_loss});\n",
        "\n",
        "        \n",
        "        if maxv<val_acc:\n",
        "            print(f\"Epoch {epoch}, new best val accuracy {val_acc} and loss {val_loss}\")\n",
        "            maxv=val_acc\n",
        "\n",
        "            ckpt_dict = {\n",
        "            'weights': network.state_dict(),\n",
        "            'train_acc': Train_acc,\n",
        "            'val_acc': Val_acc,\n",
        "            'train_loss': Train_loss,\n",
        "            'val_acc': Val_loss,\n",
        "            'epoch': epoch\n",
        "            }\n",
        "            torch.save(ckpt_dict,os.path.join(resultdir,f\"{run_name}_bestval.pth\") )\n",
        "            cpt_early = 0\n",
        "        else:\n",
        "            cpt_early +=1\n",
        "        \n",
        "        if cpt_early == patience:\n",
        "            print(\"Early Stopping\")\n",
        "            wandb.log({'Maximum validation accuracy': maxv})\n",
        "            break\n",
        "    \n",
        "    print(\"Reloading best validation model\")\n",
        "    ckpt_dict = torch.load(os.path.join(resultdir,f\"{run_name}_bestval.pth\") )\n",
        "\n",
        "    print(f\"Reloading best model at epoch {ckpt_dict['epoch']}\")\n",
        "    network.load_state_dict(ckpt_dict['weights'])'''\n",
        "\n",
        "    test_acc,f1=test(network, test_loader , classes)\n",
        "    wandb.log({'Test accuracy': test_acc})\n",
        "\n",
        "    return test_acc, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drQY84MFcrnA"
      },
      "source": [
        "###Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03cab3541cb04439b3362b96200dcf37",
            "cb9ed64239b64d35966e8f4d41bb32cf",
            "e418c5a4c7c54f24970f79f05cfff91f",
            "f8b4dd8ab2034e178ae850ac4295d6f4",
            "288a2c4763e84cc48c4c25e1fadcad3b",
            "1a9d4ea9b40c4df3bbdc614e1bf6f6c8",
            "08179b7245ee40a7b3f7897c5585b509",
            "20a8122fc07f4872b6afc3430cbed97b",
            "47fe43c337304b6183effcea4e2e1865",
            "ccae02666afa48b291c24ef3855c0322",
            "bf1fd50d10f74875a6c3eb726a5c27a7",
            "d2801b9d662549bbbc569212a833c2ee",
            "31a73fb963d84de29239d82fc39baed6",
            "fddf81180ece452ea7919c51692dddaf",
            "6927dab3291d413281972677015a8906",
            "b9ec4243c18e47879138eb25a697f840",
            "efae0bdfb0174b68807c6a7be60c61ca",
            "abaf7414d7ab4b50ab342901d2e78ad5",
            "4972e5c198bc443b93e85aa1fe973bb8",
            "ef6f32201aeb4e85a2f5ccf4d7b601df",
            "f65fbb2829314717b6f814fd55b40185",
            "f277e759da64444e8511ea32a19880c6",
            "94fe8319e2ae4eddab8c8e579cc6860e",
            "d905d7b73a6c40b99b46354c32d04567",
            "334e3262222b485a95155629430f4b62",
            "b9a5ba806ed3404a8f87fd18997ac1a7",
            "8432f22a392e4106bc768ad095f3f0ce",
            "9fd74b710abd45eca86885a9d61a54bf",
            "05ce09b945e84ad09fa06a0db468615d",
            "4c99aafb15414634911bfdb9ed6ffa47",
            "4d7f6f6a46f249b0894147311fa00425",
            "9d5939b2463b4971b9163c9d23f42ffb",
            "289f5b3abae84283a45f4f30aaff6288",
            "74613d28fcd141368ab02efc0ea7d607",
            "0b54bc47cc12444aa1be4b9ba5a15a03",
            "c7482d1cb283400a87b6fe2fdcb855a8",
            "27733464122c46e18f29cf78da4f8965",
            "f22f7b63d37b4c22aed1c4af416c0149",
            "03c135673c1a4c37a43b1254ff83ff27",
            "e7e02333ef3447cb944686019ba888a8",
            "a56b3b0c45444a21b4469833805e4953",
            "a90d91dae42a45f4aeee045a128829e0",
            "5f373a8eadd64fd082da1b37a205228c",
            "70a367c259e3460283600a83428acfdd",
            "a357741d2e0b4960a2f89feaaec1c962",
            "917e24435a7948878b3a6ab447d547e2",
            "cf38dbff3ee946e989c2c151dd351fe1",
            "2331c3ad58da4cb29cab7e6ade6483a2",
            "1dc21647dce9419db91ee003bfc2d344",
            "818759a2fe5f4f5cb143a8f327ecc5f7",
            "92a19973816b484a9e096111b32903b0",
            "3e50921403484760b38a35157d863a48",
            "9e86a2a5f94d499eadb27a53945753ac",
            "f6d5f135b0214d7f9d100a6da1d09d7c",
            "9c50af8b21154fdaa734e178f3af6ff4",
            "97b523370df54aaab4951ca9d8660925",
            "361e56aac99b439499bd97668070201c",
            "a6cdc2882f8c4c5cb9fcb90cf42dd4d6",
            "4723e6574e4f4e7e864d98844b955708",
            "408f12ec735649858a3f17091aafa0d4",
            "c7de7380d6854c3c8c5555dfb514cc80",
            "2c1573624592439b80516f8b2f15f731",
            "2d51ad5fe5b148d5928c6384cbddffad",
            "b58ecbf4a71f49a0aebb93922ff109c9",
            "a8929d163b4746fa9ae88945b62a62d8",
            "e9f3101e6062416bbce1ec6277b0e157",
            "c7d9cc437c574130bb30a6c9799554d2",
            "f9a52294c6a44f4493ac1efda7b7d444",
            "09c9b2f336844145b46360720aa86327",
            "5e5e340b4afe4a4eb0fcf25d78125bcd",
            "749c9ebc01814b1d8b5be9a642dfaca0",
            "7dc74e18a6514dbab302915518575f86",
            "a3fa003cbff9433abea719141d9b550e",
            "789f242beea7462c9329ab164bd546b7",
            "879e169d5410471c8400ccdab17c560c",
            "bb9d0e501f0e4230b35d20760600e245",
            "cd342f5d4b4b495595a838a86f77bebd",
            "51761d12c6d34855900d0c7cfd93244c",
            "36508616fb62424e9d3b85448381f9b9",
            "6bb9f3033d5b48d29ea27867af68ae2f"
          ]
        },
        "id": "5g4HZxoccrVx",
        "outputId": "f4498e49-5761-4c7e-98cf-565f349417f2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: j09ylk92\n",
            "Sweep URL: https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "240 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "240 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 240 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "240 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "240 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 240 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:moabb.datasets.gigadb:Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 events found\n",
            "Event IDs: [1 2]\n",
            "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
            "Adding metadata with 4 columns\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 200 events and 1024 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4aehu1j0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_111257-4aehu1j0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/4aehu1j0\" target=\"_blank\">pleasant-sweep-1</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 31.13577813687532 accuracy 0.6161035895347595 epoch 0 done\n",
            "train loss 28.02446417186571 accuracy 0.6731982231140137 epoch 1 done\n",
            "train loss 26.70374354072239 accuracy 0.6972973346710205 epoch 2 done\n",
            "train loss 26.026610872019894 accuracy 0.7182432413101196 epoch 3 done\n",
            "train loss 25.724472605663795 accuracy 0.7159910202026367 epoch 4 done\n",
            "train loss 25.48301107987114 accuracy 0.718693733215332 epoch 5 done\n",
            "train loss 25.30910989512568 accuracy 0.728378415107727 epoch 6 done\n",
            "train loss 24.8648795666902 accuracy 0.7331081032752991 epoch 7 done\n",
            "train loss 24.773213199947193 accuracy 0.7319819927215576 epoch 8 done\n",
            "train loss 24.430958001509957 accuracy 0.7391892075538635 epoch 9 done\n",
            "train loss 24.312580108642578 accuracy 0.7425675988197327 epoch 10 done\n",
            "train loss 24.012443583944574 accuracy 0.748085618019104 epoch 11 done\n",
            "train loss 23.783791790837828 accuracy 0.7495495676994324 epoch 12 done\n",
            "train loss 23.591963166775912 accuracy 0.7524774670600891 epoch 13 done\n",
            "train loss 23.186599275340203 accuracy 0.7582207322120667 epoch 14 done\n",
            "train loss 23.31179421880971 accuracy 0.7566441893577576 epoch 15 done\n",
            "train loss 22.924964365751848 accuracy 0.7578828930854797 epoch 16 done\n",
            "train loss 22.755268470100734 accuracy 0.767792820930481 epoch 17 done\n",
            "train loss 22.89685595553854 accuracy 0.7617117166519165 epoch 18 done\n",
            "train loss 22.47795341325843 accuracy 0.7639639973640442 epoch 19 done\n",
            "train loss 22.3843645842179 accuracy 0.7657657861709595 epoch 20 done\n",
            "train loss 22.22038625634235 accuracy 0.7730855941772461 epoch 21 done\n",
            "train loss 21.9285597179247 accuracy 0.7771396636962891 epoch 22 done\n",
            "train loss 21.90031093099843 accuracy 0.776238739490509 epoch 23 done\n",
            "train loss 21.910216393678084 accuracy 0.781193733215332 epoch 24 done\n",
            "train loss 22.04608096247134 accuracy 0.7736486792564392 epoch 25 done\n",
            "train loss 21.63238220629485 accuracy 0.776238739490509 epoch 26 done\n",
            "train loss 21.72935268153315 accuracy 0.7795045375823975 epoch 27 done\n",
            "train loss 21.56322777789572 accuracy 0.7751126289367676 epoch 28 done\n",
            "train loss 21.47254423473192 accuracy 0.776238739490509 epoch 29 done\n",
            "train loss 21.44949324234672 accuracy 0.7840090394020081 epoch 30 done\n",
            "train loss 21.573627803636633 accuracy 0.7813063263893127 epoch 31 done\n",
            "train loss 21.317862075308096 accuracy 0.7873874306678772 epoch 32 done\n",
            "train loss 20.95940280997235 accuracy 0.7881757020950317 epoch 33 done\n",
            "train loss 21.04136732350225 accuracy 0.781193733215332 epoch 34 done\n",
            "train loss 21.052949781003207 accuracy 0.7885135412216187 epoch 35 done\n",
            "train loss 21.28210409827854 accuracy 0.7813063263893127 epoch 36 done\n",
            "train loss 20.890051530755088 accuracy 0.7878378629684448 epoch 37 done\n",
            "train loss 20.83690873436306 accuracy 0.7932432889938354 epoch 38 done\n",
            "train loss 20.751445438550867 accuracy 0.7924549579620361 epoch 39 done\n",
            "train loss 20.779218051744543 accuracy 0.7888513803482056 epoch 40 done\n",
            "train loss 20.813685935476553 accuracy 0.7882882952690125 epoch 41 done\n",
            "train loss 20.926619716312572 accuracy 0.7925676107406616 epoch 42 done\n",
            "train loss 20.86312217297761 accuracy 0.7896396517753601 epoch 43 done\n",
            "train loss 20.47701661483101 accuracy 0.7947072386741638 epoch 44 done\n",
            "train loss 20.707827174145244 accuracy 0.7926802039146423 epoch 45 done\n",
            "train loss 20.61164491072945 accuracy 0.7942567467689514 epoch 46 done\n",
            "train loss 20.3743810861007 accuracy 0.7933558821678162 epoch 47 done\n",
            "train loss 20.705161550770633 accuracy 0.7907657623291016 epoch 48 done\n",
            "train loss 20.375062631524127 accuracy 0.7976351380348206 epoch 49 done\n",
            "train loss 20.64816360888274 accuracy 0.7930180430412292 epoch 50 done\n",
            "train loss 20.489830597587254 accuracy 0.7948198318481445 epoch 51 done\n",
            "train loss 20.08247240729954 accuracy 0.7997747659683228 epoch 52 done\n",
            "train loss 20.45923125225565 accuracy 0.7939189672470093 epoch 53 done\n",
            "train loss 20.40265081239783 accuracy 0.7950450778007507 epoch 54 done\n",
            "train loss 20.313307243844736 accuracy 0.7966216206550598 epoch 55 done\n",
            "train loss 20.389398222384244 accuracy 0.7981982231140137 epoch 56 done\n",
            "train loss 20.421353402345076 accuracy 0.7951576709747314 epoch 57 done\n",
            "train loss 20.180357891580336 accuracy 0.800900936126709 epoch 58 done\n",
            "train loss 20.091941252998684 accuracy 0.8012387752532959 epoch 59 done\n",
            "train loss 19.994901926621147 accuracy 0.8011261224746704 epoch 60 done\n",
            "train loss 20.186998636826225 accuracy 0.8025901317596436 epoch 61 done\n",
            "train loss 20.0377923094708 accuracy 0.8007882833480835 epoch 62 done\n",
            "train loss 19.89724930472996 accuracy 0.8051801919937134 epoch 63 done\n",
            "train loss 19.978396146193795 accuracy 0.7998874187469482 epoch 64 done\n",
            "train loss 20.27874411707339 accuracy 0.7981982231140137 epoch 65 done\n",
            "train loss 19.85354415230129 accuracy 0.8012387752532959 epoch 66 done\n",
            "train loss 19.885462760925293 accuracy 0.8010135293006897 epoch 67 done\n",
            "train loss 19.901666827823803 accuracy 0.8031531572341919 epoch 68 done\n",
            "train loss 19.803449734397557 accuracy 0.8046171069145203 epoch 69 done\n",
            "train loss 20.09303397717683 accuracy 0.8004504442214966 epoch 70 done\n",
            "train loss 19.752577802409295 accuracy 0.8033784031867981 epoch 71 done\n",
            "train loss 19.94899444994719 accuracy 0.8006756901741028 epoch 72 done\n",
            "train loss 19.839111535445504 accuracy 0.8043919205665588 epoch 73 done\n",
            "train loss 19.7265420789304 accuracy 0.8021396398544312 epoch 74 done\n",
            "train loss 19.773102884707242 accuracy 0.8025901317596436 epoch 75 done\n",
            "train loss 19.748905306277067 accuracy 0.8072072267532349 epoch 76 done\n",
            "train loss 19.625843317612357 accuracy 0.8072072267532349 epoch 77 done\n",
            "train loss 19.943709642990775 accuracy 0.8074324727058411 epoch 78 done\n",
            "train loss 19.561563056448232 accuracy 0.8073198199272156 epoch 79 done\n",
            "train loss 19.82799426369045 accuracy 0.8027027249336243 epoch 80 done\n",
            "train loss 19.445320979408596 accuracy 0.8100225329399109 epoch 81 done\n",
            "train loss 19.815823513528578 accuracy 0.8041666746139526 epoch 82 done\n",
            "train loss 19.96139030871184 accuracy 0.8074324727058411 epoch 83 done\n",
            "train loss 19.882771906645402 accuracy 0.8021396398544312 epoch 84 done\n",
            "train loss 19.48030486314193 accuracy 0.8081081509590149 epoch 85 done\n",
            "train loss 19.411592898161516 accuracy 0.8047297596931458 epoch 86 done\n",
            "train loss 19.837861952574357 accuracy 0.8084459900856018 epoch 87 done\n",
            "train loss 19.43558431708294 accuracy 0.8084459900856018 epoch 88 done\n",
            "train loss 19.540250778198242 accuracy 0.8069819808006287 epoch 89 done\n",
            "train loss 19.64934187350066 accuracy 0.8048423528671265 epoch 90 done\n",
            "train loss 19.48251966808153 accuracy 0.8050675988197327 epoch 91 done\n",
            "train loss 19.48496248411096 accuracy 0.8111486434936523 epoch 92 done\n",
            "train loss 19.57498722491057 accuracy 0.8092342615127563 epoch 93 done\n",
            "train loss 19.47946189797443 accuracy 0.8073198199272156 epoch 94 done\n",
            "train loss 19.350127033565357 accuracy 0.807770311832428 epoch 95 done\n",
            "train loss 19.41745500979216 accuracy 0.8104729652404785 epoch 96 done\n",
            "train loss 19.096456113068953 accuracy 0.8128378391265869 epoch 97 done\n",
            "train loss 19.40011911806853 accuracy 0.8108108043670654 epoch 98 done\n",
            "train loss 19.286856361057445 accuracy 0.8117117285728455 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.7930000424385071 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03cab3541cb04439b3362b96200dcf37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.793</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.81171</td></tr><tr><td>Training loss</td><td>19.28686</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">pleasant-sweep-1</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/4aehu1j0\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/4aehu1j0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_111257-4aehu1j0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ljh55he5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_112848-ljh55he5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/ljh55he5\" target=\"_blank\">scarlet-sweep-2</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.35101376409116 accuracy 0.6298423409461975 epoch 0 done\n",
            "train loss 27.048768209374472 accuracy 0.68840092420578 epoch 1 done\n",
            "train loss 25.825302559396494 accuracy 0.713738739490509 epoch 2 done\n",
            "train loss 25.376026319420852 accuracy 0.7198198437690735 epoch 3 done\n",
            "train loss 24.97093032753986 accuracy 0.7277027368545532 epoch 4 done\n",
            "train loss 24.722265989884086 accuracy 0.735247790813446 epoch 5 done\n",
            "train loss 24.402558160864785 accuracy 0.7365990877151489 epoch 6 done\n",
            "train loss 24.38740632845008 accuracy 0.7393018007278442 epoch 7 done\n",
            "train loss 24.159968127375066 accuracy 0.7413288354873657 epoch 8 done\n",
            "train loss 23.845868753350302 accuracy 0.7445946335792542 epoch 9 done\n",
            "train loss 23.569176901941717 accuracy 0.7461711764335632 epoch 10 done\n",
            "train loss 23.332626093988836 accuracy 0.7510135173797607 epoch 11 done\n",
            "train loss 23.118610796721086 accuracy 0.7514640092849731 epoch 12 done\n",
            "train loss 22.93440700613934 accuracy 0.7594594955444336 epoch 13 done\n",
            "train loss 22.775086983390477 accuracy 0.7644144296646118 epoch 14 done\n",
            "train loss 22.38601060535597 accuracy 0.7702702879905701 epoch 15 done\n",
            "train loss 22.3524576270062 accuracy 0.7700450420379639 epoch 16 done\n",
            "train loss 22.09897399985272 accuracy 0.7699324488639832 epoch 17 done\n",
            "train loss 21.961909169736117 accuracy 0.7724099159240723 epoch 18 done\n",
            "train loss 22.033176069674283 accuracy 0.7694820165634155 epoch 19 done\n",
            "train loss 21.944469410440195 accuracy 0.7688063383102417 epoch 20 done\n",
            "train loss 21.647540403449014 accuracy 0.7784910202026367 epoch 21 done\n",
            "train loss 21.499542464380678 accuracy 0.7798423767089844 epoch 22 done\n",
            "train loss 21.425192750018574 accuracy 0.7798423767089844 epoch 23 done\n",
            "train loss 21.320055360379428 accuracy 0.7810810804367065 epoch 24 done\n",
            "train loss 21.167728320412014 accuracy 0.7832207679748535 epoch 25 done\n",
            "train loss 21.166260615639064 accuracy 0.7841216325759888 epoch 26 done\n",
            "train loss 21.2260074822799 accuracy 0.7868243455886841 epoch 27 done\n",
            "train loss 21.086628499238387 accuracy 0.7824324369430542 epoch 28 done\n",
            "train loss 21.086266102998152 accuracy 0.7840090394020081 epoch 29 done\n",
            "train loss 20.89205374925033 accuracy 0.7916666865348816 epoch 30 done\n",
            "train loss 20.945295292398207 accuracy 0.7876126170158386 epoch 31 done\n",
            "train loss 20.72571785553642 accuracy 0.7904279232025146 epoch 32 done\n",
            "train loss 20.70517691321995 accuracy 0.7861486673355103 epoch 33 done\n",
            "train loss 20.41425327632738 accuracy 0.7925676107406616 epoch 34 done\n",
            "train loss 20.499803646751072 accuracy 0.7915540933609009 epoch 35 done\n",
            "train loss 20.67255855643231 accuracy 0.7841216325759888 epoch 36 done\n",
            "train loss 20.53146938655687 accuracy 0.7911036014556885 epoch 37 done\n",
            "train loss 20.514676446500033 accuracy 0.7893018126487732 epoch 38 done\n",
            "train loss 20.487926877063256 accuracy 0.7907657623291016 epoch 39 done\n",
            "train loss 20.26880071474158 accuracy 0.7969594597816467 epoch 40 done\n",
            "train loss 20.144130312878154 accuracy 0.7934684753417969 epoch 41 done\n",
            "train loss 20.320778515027918 accuracy 0.79403156042099 epoch 42 done\n",
            "train loss 20.064490048781686 accuracy 0.800900936126709 epoch 43 done\n",
            "train loss 19.927608033885125 accuracy 0.7998874187469482 epoch 44 done\n",
            "train loss 20.175391508185346 accuracy 0.7976351380348206 epoch 45 done\n",
            "train loss 20.15677968315456 accuracy 0.7998874187469482 epoch 46 done\n",
            "train loss 19.702949959298838 accuracy 0.8034909963607788 epoch 47 done\n",
            "train loss 19.917599781699803 accuracy 0.8015766143798828 epoch 48 done\n",
            "train loss 20.062695316646412 accuracy 0.7971847057342529 epoch 49 done\n",
            "train loss 19.811030926911727 accuracy 0.8004504442214966 epoch 50 done\n",
            "train loss 20.01590419852215 accuracy 0.7958333492279053 epoch 51 done\n",
            "train loss 19.86604058224222 accuracy 0.7990991473197937 epoch 52 done\n",
            "train loss 19.788028592648715 accuracy 0.7992117404937744 epoch 53 done\n",
            "train loss 19.501935233240545 accuracy 0.8049549460411072 epoch 54 done\n",
            "train loss 19.62474031033723 accuracy 0.8023648858070374 epoch 55 done\n",
            "train loss 19.318267905193824 accuracy 0.8082207441329956 epoch 56 done\n",
            "train loss 19.793439699255902 accuracy 0.8021396398544312 epoch 57 done\n",
            "train loss 19.658512333165042 accuracy 0.8042793273925781 epoch 58 done\n",
            "train loss 19.43850687275762 accuracy 0.806869387626648 epoch 59 done\n",
            "train loss 19.595517552417256 accuracy 0.8030405640602112 epoch 60 done\n",
            "train loss 19.276049738344938 accuracy 0.8041666746139526 epoch 61 done\n",
            "train loss 19.417103083237357 accuracy 0.8059684634208679 epoch 62 done\n",
            "train loss 19.333645260852315 accuracy 0.8055180311203003 epoch 63 done\n",
            "train loss 19.249109516973082 accuracy 0.8078829050064087 epoch 64 done\n",
            "train loss 19.172520969225012 accuracy 0.8097973465919495 epoch 65 done\n",
            "train loss 19.45795144205508 accuracy 0.8087838292121887 epoch 66 done\n",
            "train loss 19.473927290543266 accuracy 0.805630624294281 epoch 67 done\n",
            "train loss 19.253254351408586 accuracy 0.8060811161994934 epoch 68 done\n",
            "train loss 19.289475648299508 accuracy 0.8117117285728455 epoch 69 done\n",
            "train loss 19.484860171442445 accuracy 0.803716242313385 epoch 70 done\n",
            "train loss 19.066288761470627 accuracy 0.8123874068260193 epoch 71 done\n",
            "train loss 18.978552071944527 accuracy 0.8092342615127563 epoch 72 done\n",
            "train loss 19.046543432318646 accuracy 0.8087838292121887 epoch 73 done\n",
            "train loss 19.11681670727937 accuracy 0.8108108043670654 epoch 74 done\n",
            "train loss 18.850935127424158 accuracy 0.8127252459526062 epoch 75 done\n",
            "train loss 18.879738517429516 accuracy 0.8103603720664978 epoch 76 done\n",
            "train loss 18.974495224330738 accuracy 0.8144144415855408 epoch 77 done\n",
            "train loss 18.789756982222848 accuracy 0.8135135173797607 epoch 78 done\n",
            "train loss 18.8898372857467 accuracy 0.814639687538147 epoch 79 done\n",
            "train loss 19.267427817634914 accuracy 0.8101351261138916 epoch 80 done\n",
            "train loss 19.124179010805875 accuracy 0.8082207441329956 epoch 81 done\n",
            "train loss 19.11210408418075 accuracy 0.806531548500061 epoch 82 done\n",
            "train loss 18.778858060422152 accuracy 0.8157657980918884 epoch 83 done\n",
            "train loss 18.780240121095076 accuracy 0.8127252459526062 epoch 84 done\n",
            "train loss 18.749427111252494 accuracy 0.8148648738861084 epoch 85 done\n",
            "train loss 18.92538705079452 accuracy 0.8086711764335632 epoch 86 done\n",
            "train loss 18.986779295879863 accuracy 0.8145270347595215 epoch 87 done\n",
            "train loss 18.618741719619088 accuracy 0.8149775266647339 epoch 88 done\n",
            "train loss 18.746254485586416 accuracy 0.8138513565063477 epoch 89 done\n",
            "train loss 18.84197011201278 accuracy 0.8097973465919495 epoch 90 done\n",
            "train loss 18.879926059557043 accuracy 0.8130630850791931 epoch 91 done\n",
            "train loss 18.708879636681598 accuracy 0.8149775266647339 epoch 92 done\n",
            "train loss 18.58078204030576 accuracy 0.8157657980918884 epoch 93 done\n",
            "train loss 18.48271714086118 accuracy 0.8242117166519165 epoch 94 done\n",
            "train loss 18.67821158533511 accuracy 0.816554069519043 epoch 95 done\n",
            "train loss 18.4769867192144 accuracy 0.8168919086456299 epoch 96 done\n",
            "train loss 18.39555188883906 accuracy 0.8182432651519775 epoch 97 done\n",
            "train loss 18.732000019239344 accuracy 0.8149775266647339 epoch 98 done\n",
            "train loss 18.195521758950274 accuracy 0.8212838172912598 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.7170000076293945 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47fe43c337304b6183effcea4e2e1865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>Training loss</td><td>█▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.717</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.82128</td></tr><tr><td>Training loss</td><td>18.19552</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-2</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/ljh55he5\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/ljh55he5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_112848-ljh55he5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mitm7mtd with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_114438-mitm7mtd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/mitm7mtd\" target=\"_blank\">exalted-sweep-3</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.412210277889088 accuracy 0.6373873949050903 epoch 0 done\n",
            "train loss 27.475532718326736 accuracy 0.6849099397659302 epoch 1 done\n",
            "train loss 26.19307644470878 accuracy 0.7087838053703308 epoch 2 done\n",
            "train loss 25.54390235569166 accuracy 0.7211712002754211 epoch 3 done\n",
            "train loss 25.13020152631013 accuracy 0.7257882952690125 epoch 4 done\n",
            "train loss 24.76834139616593 accuracy 0.7301802039146423 epoch 5 done\n",
            "train loss 24.661256292591926 accuracy 0.7381756901741028 epoch 6 done\n",
            "train loss 24.024023698723834 accuracy 0.7438063025474548 epoch 7 done\n",
            "train loss 23.7020931865858 accuracy 0.7497748136520386 epoch 8 done\n",
            "train loss 23.480392310930334 accuracy 0.7522522807121277 epoch 9 done\n",
            "train loss 23.192387601603635 accuracy 0.756869375705719 epoch 10 done\n",
            "train loss 22.99893337747325 accuracy 0.757770299911499 epoch 11 done\n",
            "train loss 22.807035777879797 accuracy 0.7621622085571289 epoch 12 done\n",
            "train loss 22.81820023578146 accuracy 0.759684681892395 epoch 13 done\n",
            "train loss 22.518361464790676 accuracy 0.7684684991836548 epoch 14 done\n",
            "train loss 22.52397926993992 accuracy 0.7670045495033264 epoch 15 done\n",
            "train loss 22.222454444221828 accuracy 0.7704955339431763 epoch 16 done\n",
            "train loss 22.242992795032006 accuracy 0.7720720767974854 epoch 17 done\n",
            "train loss 22.175007737201195 accuracy 0.7724099159240723 epoch 18 done\n",
            "train loss 21.897510093191396 accuracy 0.7721847295761108 epoch 19 done\n",
            "train loss 21.769149510756783 accuracy 0.7799549698829651 epoch 20 done\n",
            "train loss 21.797535647516668 accuracy 0.776576578617096 epoch 21 done\n",
            "train loss 21.55191707611084 accuracy 0.7816441655158997 epoch 22 done\n",
            "train loss 21.60835705632749 accuracy 0.7757883071899414 epoch 23 done\n",
            "train loss 21.5402890080991 accuracy 0.780292809009552 epoch 24 done\n",
            "train loss 21.465043938678242 accuracy 0.7781531810760498 epoch 25 done\n",
            "train loss 21.73750761280889 accuracy 0.7782657742500305 epoch 26 done\n",
            "train loss 21.23626953622569 accuracy 0.7808558940887451 epoch 27 done\n",
            "train loss 21.296018351679265 accuracy 0.7807432413101196 epoch 28 done\n",
            "train loss 21.190739631652832 accuracy 0.7810810804367065 epoch 29 done\n",
            "train loss 21.248852128567904 accuracy 0.786261260509491 epoch 30 done\n",
            "train loss 21.116660180299178 accuracy 0.7868243455886841 epoch 31 done\n",
            "train loss 21.234597268311873 accuracy 0.7836712002754211 epoch 32 done\n",
            "train loss 20.85624599456787 accuracy 0.7875000238418579 epoch 33 done\n",
            "train loss 20.93897137434586 accuracy 0.789076566696167 epoch 34 done\n",
            "train loss 21.041029059368633 accuracy 0.7852477431297302 epoch 35 done\n",
            "train loss 20.91774612924327 accuracy 0.7884009480476379 epoch 36 done\n",
            "train loss 20.899638466213062 accuracy 0.7865990996360779 epoch 37 done\n",
            "train loss 21.129024609275486 accuracy 0.7836712002754211 epoch 38 done\n",
            "train loss 20.649732444597326 accuracy 0.7876126170158386 epoch 39 done\n",
            "train loss 20.63277248714281 accuracy 0.7952702641487122 epoch 40 done\n",
            "train loss 20.464604709459387 accuracy 0.7917792797088623 epoch 41 done\n",
            "train loss 20.636103008104406 accuracy 0.7917792797088623 epoch 42 done\n",
            "train loss 20.595378481823463 accuracy 0.7938063144683838 epoch 43 done\n",
            "train loss 20.5439715385437 accuracy 0.791216254234314 epoch 44 done\n",
            "train loss 20.28411581205285 accuracy 0.8001126050949097 epoch 45 done\n",
            "train loss 20.494596108146336 accuracy 0.7950450778007507 epoch 46 done\n",
            "train loss 20.5987547584202 accuracy 0.789977490901947 epoch 47 done\n",
            "train loss 20.36551985533341 accuracy 0.7957207560539246 epoch 48 done\n",
            "train loss 20.203150044316832 accuracy 0.7998874187469482 epoch 49 done\n",
            "train loss 20.324410355609395 accuracy 0.795945942401886 epoch 50 done\n",
            "train loss 20.00753862961479 accuracy 0.8016892075538635 epoch 51 done\n",
            "train loss 20.388694576595142 accuracy 0.7951576709747314 epoch 52 done\n",
            "train loss 20.318997362385623 accuracy 0.7963964343070984 epoch 53 done\n",
            "train loss 20.38779580074808 accuracy 0.7949324250221252 epoch 54 done\n",
            "train loss 20.20818102878073 accuracy 0.7990991473197937 epoch 55 done\n",
            "train loss 20.17860690407131 accuracy 0.7947072386741638 epoch 56 done\n",
            "train loss 20.35217090274977 accuracy 0.7925676107406616 epoch 57 done\n",
            "train loss 20.048182135042936 accuracy 0.8032658100128174 epoch 58 done\n",
            "train loss 20.05917623768682 accuracy 0.7995495796203613 epoch 59 done\n",
            "train loss 19.881657704063084 accuracy 0.8038288354873657 epoch 60 done\n",
            "train loss 20.08417564889659 accuracy 0.7960585951805115 epoch 61 done\n",
            "train loss 19.851682020270303 accuracy 0.8005630970001221 epoch 62 done\n",
            "train loss 20.090126576630965 accuracy 0.7981982231140137 epoch 63 done\n",
            "train loss 20.0185751085696 accuracy 0.8012387752532959 epoch 64 done\n",
            "train loss 19.86848246532938 accuracy 0.8004504442214966 epoch 65 done\n",
            "train loss 19.869646611421004 accuracy 0.7993243336677551 epoch 66 done\n",
            "train loss 19.752933979034424 accuracy 0.8054054379463196 epoch 67 done\n",
            "train loss 19.769479979639467 accuracy 0.800900936126709 epoch 68 done\n",
            "train loss 19.739140572755232 accuracy 0.8016892075538635 epoch 69 done\n",
            "train loss 19.67895455982374 accuracy 0.8034909963607788 epoch 70 done\n",
            "train loss 19.68516370524531 accuracy 0.8042793273925781 epoch 71 done\n",
            "train loss 19.859854304272197 accuracy 0.8033784031867981 epoch 72 done\n",
            "train loss 19.563953047213346 accuracy 0.8050675988197327 epoch 73 done\n",
            "train loss 19.584730459296186 accuracy 0.8048423528671265 epoch 74 done\n",
            "train loss 19.603353002797 accuracy 0.800900936126709 epoch 75 done\n",
            "train loss 19.77763671460359 accuracy 0.8012387752532959 epoch 76 done\n",
            "train loss 19.68555674345597 accuracy 0.8010135293006897 epoch 77 done\n",
            "train loss 19.53624957540761 accuracy 0.8029279708862305 epoch 78 done\n",
            "train loss 19.69040719322536 accuracy 0.8027027249336243 epoch 79 done\n",
            "train loss 19.453922085140064 accuracy 0.8097973465919495 epoch 80 done\n",
            "train loss 19.696271108544394 accuracy 0.8067567944526672 epoch 81 done\n",
            "train loss 19.622522271197774 accuracy 0.8052927851676941 epoch 82 done\n",
            "train loss 19.723311610843826 accuracy 0.805630624294281 epoch 83 done\n",
            "train loss 19.196809146715246 accuracy 0.8114864826202393 epoch 84 done\n",
            "train loss 19.4503697105076 accuracy 0.8079954981803894 epoch 85 done\n",
            "train loss 19.5390276286913 accuracy 0.8088964223861694 epoch 86 done\n",
            "train loss 19.707783595375393 accuracy 0.8015766143798828 epoch 87 done\n",
            "train loss 19.494814603225045 accuracy 0.8067567944526672 epoch 88 done\n",
            "train loss 19.174995277238928 accuracy 0.8082207441329956 epoch 89 done\n",
            "train loss 19.138213758883268 accuracy 0.8126126527786255 epoch 90 done\n",
            "train loss 19.18580032431561 accuracy 0.8070946335792542 epoch 91 done\n",
            "train loss 19.508397641389266 accuracy 0.8049549460411072 epoch 92 done\n",
            "train loss 19.29561702064846 accuracy 0.8050675988197327 epoch 93 done\n",
            "train loss 19.326110311176464 accuracy 0.8081081509590149 epoch 94 done\n",
            "train loss 19.301223008529 accuracy 0.8063063025474548 epoch 95 done\n",
            "train loss 19.034136233122453 accuracy 0.81340092420578 epoch 96 done\n",
            "train loss 19.23754235972529 accuracy 0.8144144415855408 epoch 97 done\n",
            "train loss 19.434243347333826 accuracy 0.806531548500061 epoch 98 done\n",
            "train loss 19.308715986168902 accuracy 0.8088964223861694 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.7640000581741333 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efae0bdfb0174b68807c6a7be60c61ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.764</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.8089</td></tr><tr><td>Training loss</td><td>19.30872</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">exalted-sweep-3</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/mitm7mtd\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/mitm7mtd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_114438-mitm7mtd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: waf90r9b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_120032-waf90r9b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/waf90r9b\" target=\"_blank\">scarlet-sweep-4</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.446094554403558 accuracy 0.6305180191993713 epoch 0 done\n",
            "train loss 27.00018555185069 accuracy 0.680630624294281 epoch 1 done\n",
            "train loss 25.82811817915543 accuracy 0.7111486792564392 epoch 2 done\n",
            "train loss 24.968871241030488 accuracy 0.7266892194747925 epoch 3 done\n",
            "train loss 24.75003555546636 accuracy 0.7322072386741638 epoch 4 done\n",
            "train loss 24.251204158948816 accuracy 0.7405405640602112 epoch 5 done\n",
            "train loss 24.114101326983906 accuracy 0.7397522926330566 epoch 6 done\n",
            "train loss 23.928686826125436 accuracy 0.7442567944526672 epoch 7 done\n",
            "train loss 23.929958613022514 accuracy 0.7438063025474548 epoch 8 done\n",
            "train loss 23.544482625049092 accuracy 0.7548423409461975 epoch 9 done\n",
            "train loss 23.65666325195976 accuracy 0.7525901198387146 epoch 10 done\n",
            "train loss 23.417159785395082 accuracy 0.7511261701583862 epoch 11 done\n",
            "train loss 23.422689707382865 accuracy 0.7548423409461975 epoch 12 done\n",
            "train loss 23.153299829234246 accuracy 0.753716230392456 epoch 13 done\n",
            "train loss 23.12778263506682 accuracy 0.7570946216583252 epoch 14 done\n",
            "train loss 22.877509158590566 accuracy 0.7621622085571289 epoch 15 done\n",
            "train loss 22.820638988329016 accuracy 0.7611486911773682 epoch 16 done\n",
            "train loss 22.539086383322008 accuracy 0.767792820930481 epoch 17 done\n",
            "train loss 22.347172840781834 accuracy 0.7656531929969788 epoch 18 done\n",
            "train loss 22.365126029304836 accuracy 0.7657657861709595 epoch 19 done\n",
            "train loss 22.088137896164604 accuracy 0.7757883071899414 epoch 20 done\n",
            "train loss 21.940561999445375 accuracy 0.7744369506835938 epoch 21 done\n",
            "train loss 21.850207888561748 accuracy 0.7713963985443115 epoch 22 done\n",
            "train loss 21.3057861742766 accuracy 0.7832207679748535 epoch 23 done\n",
            "train loss 21.269274773805037 accuracy 0.7852477431297302 epoch 24 done\n",
            "train loss 21.308210849761963 accuracy 0.7845720648765564 epoch 25 done\n",
            "train loss 20.913678729015846 accuracy 0.7860360741615295 epoch 26 done\n",
            "train loss 21.07349978322568 accuracy 0.7820945978164673 epoch 27 done\n",
            "train loss 20.92106684394505 accuracy 0.7845720648765564 epoch 28 done\n",
            "train loss 20.67903574653294 accuracy 0.7894144058227539 epoch 29 done\n",
            "train loss 20.506173921668008 accuracy 0.7911036014556885 epoch 30 done\n",
            "train loss 20.493910851685897 accuracy 0.7888513803482056 epoch 31 done\n",
            "train loss 20.419190282407016 accuracy 0.79313063621521 epoch 32 done\n",
            "train loss 20.70792538186778 accuracy 0.7869369387626648 epoch 33 done\n",
            "train loss 20.25043877311375 accuracy 0.7965090274810791 epoch 34 done\n",
            "train loss 20.116159376890764 accuracy 0.8029279708862305 epoch 35 done\n",
            "train loss 20.225694386855416 accuracy 0.792792797088623 epoch 36 done\n",
            "train loss 20.10662317276001 accuracy 0.7945945858955383 epoch 37 done\n",
            "train loss 19.96418816110362 accuracy 0.7994369268417358 epoch 38 done\n",
            "train loss 19.925223101740297 accuracy 0.7992117404937744 epoch 39 done\n",
            "train loss 20.056263654128365 accuracy 0.7993243336677551 epoch 40 done\n",
            "train loss 19.94676921678626 accuracy 0.7951576709747314 epoch 41 done\n",
            "train loss 19.77080017587413 accuracy 0.7998874187469482 epoch 42 done\n",
            "train loss 19.713043461675227 accuracy 0.8019144535064697 epoch 43 done\n",
            "train loss 19.737038031868313 accuracy 0.8070946335792542 epoch 44 done\n",
            "train loss 19.580118262249492 accuracy 0.8021396398544312 epoch 45 done\n",
            "train loss 19.47337233501932 accuracy 0.8027027249336243 epoch 46 done\n",
            "train loss 19.552317246146824 accuracy 0.802815318107605 epoch 47 done\n",
            "train loss 19.468782341998555 accuracy 0.8036036491394043 epoch 48 done\n",
            "train loss 19.747869429380998 accuracy 0.8033784031867981 epoch 49 done\n",
            "train loss 19.392990547677744 accuracy 0.8069819808006287 epoch 50 done\n",
            "train loss 19.419332628664762 accuracy 0.8058558702468872 epoch 51 done\n",
            "train loss 19.310939809550412 accuracy 0.8059684634208679 epoch 52 done\n",
            "train loss 19.160404640695326 accuracy 0.8101351261138916 epoch 53 done\n",
            "train loss 19.442103572513744 accuracy 0.8086711764335632 epoch 54 done\n",
            "train loss 19.092292371003523 accuracy 0.8099099397659302 epoch 55 done\n",
            "train loss 19.293014982472293 accuracy 0.8099099397659302 epoch 56 done\n",
            "train loss 19.034026166667108 accuracy 0.8127252459526062 epoch 57 done\n",
            "train loss 19.10025644302368 accuracy 0.8118243217468262 epoch 58 done\n",
            "train loss 18.94502125615659 accuracy 0.8145270347595215 epoch 59 done\n",
            "train loss 18.935428702312965 accuracy 0.8117117285728455 epoch 60 done\n",
            "train loss 18.945506551991336 accuracy 0.8135135173797607 epoch 61 done\n",
            "train loss 18.76280969122182 accuracy 0.8164414763450623 epoch 62 done\n",
            "train loss 19.083916767783787 accuracy 0.8108108043670654 epoch 63 done\n",
            "train loss 18.842954469763715 accuracy 0.81340092420578 epoch 64 done\n",
            "train loss 18.580657741297845 accuracy 0.8192567825317383 epoch 65 done\n",
            "train loss 18.945498114046842 accuracy 0.8144144415855408 epoch 66 done\n",
            "train loss 18.986699684806492 accuracy 0.8132883310317993 epoch 67 done\n",
            "train loss 18.714283777319864 accuracy 0.8144144415855408 epoch 68 done\n",
            "train loss 18.687447029611338 accuracy 0.8141891956329346 epoch 69 done\n",
            "train loss 18.675274392832883 accuracy 0.8189189434051514 epoch 70 done\n",
            "train loss 18.809418284374736 accuracy 0.81340092420578 epoch 71 done\n",
            "train loss 18.681128792140797 accuracy 0.8129504919052124 epoch 72 done\n",
            "train loss 18.691820994667385 accuracy 0.8136261701583862 epoch 73 done\n",
            "train loss 18.4887231329213 accuracy 0.8181306719779968 epoch 74 done\n",
            "train loss 18.71804019679194 accuracy 0.8181306719779968 epoch 75 done\n",
            "train loss 18.59993673407513 accuracy 0.8143018484115601 epoch 76 done\n",
            "train loss 18.633660192074984 accuracy 0.8182432651519775 epoch 77 done\n",
            "train loss 18.517362200695537 accuracy 0.8161036372184753 epoch 78 done\n",
            "train loss 18.41671674147896 accuracy 0.8180180191993713 epoch 79 done\n",
            "train loss 18.5575038453807 accuracy 0.8166666626930237 epoch 80 done\n",
            "train loss 18.808010909868322 accuracy 0.8189189434051514 epoch 81 done\n",
            "train loss 18.366265794505246 accuracy 0.8179054260253906 epoch 82 done\n",
            "train loss 18.5172005114348 accuracy 0.8215090036392212 epoch 83 done\n",
            "train loss 18.56866992038229 accuracy 0.8236486911773682 epoch 84 done\n",
            "train loss 18.368767323701277 accuracy 0.8219594955444336 epoch 85 done\n",
            "train loss 18.27855734203173 accuracy 0.8235360383987427 epoch 86 done\n",
            "train loss 18.44436668313068 accuracy 0.8180180191993713 epoch 87 done\n",
            "train loss 18.005493433579154 accuracy 0.827139675617218 epoch 88 done\n",
            "train loss 18.40005526335343 accuracy 0.8203828930854797 epoch 89 done\n",
            "train loss 18.3673966034599 accuracy 0.8199324607849121 epoch 90 done\n",
            "train loss 18.346603331358537 accuracy 0.8216216564178467 epoch 91 done\n",
            "train loss 17.912464162577756 accuracy 0.8233108520507812 epoch 92 done\n",
            "train loss 18.20670047013656 accuracy 0.8222973346710205 epoch 93 done\n",
            "train loss 18.2222085206405 accuracy 0.8211711645126343 epoch 94 done\n",
            "train loss 18.07877383024796 accuracy 0.8247748017311096 epoch 95 done\n",
            "train loss 18.050348966018014 accuracy 0.8217342495918274 epoch 96 done\n",
            "train loss 18.341587730076004 accuracy 0.8186936974525452 epoch 97 done\n",
            "train loss 18.231898059015688 accuracy 0.8195946216583252 epoch 98 done\n",
            "train loss 18.126218546991762 accuracy 0.8231981992721558 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.6920000314712524 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334e3262222b485a95155629430f4b62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.692</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.8232</td></tr><tr><td>Training loss</td><td>18.12622</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-4</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/waf90r9b\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/waf90r9b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_120032-waf90r9b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9frnsa9x with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_121627-9frnsa9x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/9frnsa9x\" target=\"_blank\">clean-sweep-5</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.09120816769807 accuracy 0.6414414644241333 epoch 0 done\n",
            "train loss 27.125402761542283 accuracy 0.6842342615127563 epoch 1 done\n",
            "train loss 25.91217808101488 accuracy 0.7091216444969177 epoch 2 done\n",
            "train loss 25.344102382659912 accuracy 0.7191441655158997 epoch 3 done\n",
            "train loss 24.727963654891305 accuracy 0.7341216206550598 epoch 4 done\n",
            "train loss 24.70589380678923 accuracy 0.7314189076423645 epoch 5 done\n",
            "train loss 24.46412345637446 accuracy 0.7370495796203613 epoch 6 done\n",
            "train loss 24.189800697824225 accuracy 0.7451576590538025 epoch 7 done\n",
            "train loss 23.816924364670463 accuracy 0.7463964223861694 epoch 8 done\n",
            "train loss 23.56481572856074 accuracy 0.7525901198387146 epoch 9 done\n",
            "train loss 23.43820694218511 accuracy 0.754954993724823 epoch 10 done\n",
            "train loss 23.06514066198598 accuracy 0.7560811042785645 epoch 11 done\n",
            "train loss 22.89889018431954 accuracy 0.7617117166519165 epoch 12 done\n",
            "train loss 22.668330545010775 accuracy 0.7654279470443726 epoch 13 done\n",
            "train loss 22.548302298006803 accuracy 0.7645270228385925 epoch 14 done\n",
            "train loss 22.154270918472953 accuracy 0.7725225687026978 epoch 15 done\n",
            "train loss 22.496388228043266 accuracy 0.7681306600570679 epoch 16 done\n",
            "train loss 21.968737643697988 accuracy 0.7779279351234436 epoch 17 done\n",
            "train loss 22.050704624341883 accuracy 0.7729730010032654 epoch 18 done\n",
            "train loss 21.96286211843076 accuracy 0.7764639854431152 epoch 19 done\n",
            "train loss 21.560529169828996 accuracy 0.777477502822876 epoch 20 done\n",
            "train loss 21.67694539609163 accuracy 0.7786036133766174 epoch 21 done\n",
            "train loss 21.638819362806238 accuracy 0.7764639854431152 epoch 22 done\n",
            "train loss 21.660700030948803 accuracy 0.7750000357627869 epoch 23 done\n",
            "train loss 21.261229328487232 accuracy 0.7852477431297302 epoch 24 done\n",
            "train loss 21.235866919807766 accuracy 0.7816441655158997 epoch 25 done\n",
            "train loss 21.349938745084017 accuracy 0.7826576828956604 epoch 26 done\n",
            "train loss 21.113132207289986 accuracy 0.7838963866233826 epoch 27 done\n",
            "train loss 20.763201661731884 accuracy 0.7844594717025757 epoch 28 done\n",
            "train loss 21.06711779470029 accuracy 0.785923421382904 epoch 29 done\n",
            "train loss 20.772313947262973 accuracy 0.7918919324874878 epoch 30 done\n",
            "train loss 20.84019490946894 accuracy 0.789076566696167 epoch 31 done\n",
            "train loss 20.548447526019554 accuracy 0.7915540933609009 epoch 32 done\n",
            "train loss 20.774546478105627 accuracy 0.7909910082817078 epoch 33 done\n",
            "train loss 20.49306011199951 accuracy 0.7932432889938354 epoch 34 done\n",
            "train loss 20.55463104662688 accuracy 0.7932432889938354 epoch 35 done\n",
            "train loss 20.423591385716975 accuracy 0.7936937212944031 epoch 36 done\n",
            "train loss 20.602301784183666 accuracy 0.7911036014556885 epoch 37 done\n",
            "train loss 20.18730936879697 accuracy 0.8006756901741028 epoch 38 done\n",
            "train loss 20.297549786775008 accuracy 0.7957207560539246 epoch 39 done\n",
            "train loss 19.919660215792447 accuracy 0.8064189553260803 epoch 40 done\n",
            "train loss 20.157541772593625 accuracy 0.7983108162879944 epoch 41 done\n",
            "train loss 20.18173138991646 accuracy 0.7984234690666199 epoch 42 done\n",
            "train loss 20.287590379300326 accuracy 0.7987613081932068 epoch 43 done\n",
            "train loss 20.206905986951746 accuracy 0.7981982231140137 epoch 44 done\n",
            "train loss 20.236409332441248 accuracy 0.7961711883544922 epoch 45 done\n",
            "train loss 19.889827831931736 accuracy 0.7971847057342529 epoch 46 done\n",
            "train loss 20.117919756018598 accuracy 0.7943693995475769 epoch 47 done\n",
            "train loss 20.055223133253016 accuracy 0.8006756901741028 epoch 48 done\n",
            "train loss 19.88661229092142 accuracy 0.800900936126709 epoch 49 done\n",
            "train loss 20.021429600922957 accuracy 0.8018018007278442 epoch 50 done\n",
            "train loss 19.56332727100538 accuracy 0.8072072267532349 epoch 51 done\n",
            "train loss 19.41692364734152 accuracy 0.8046171069145203 epoch 52 done\n",
            "train loss 19.670948215152904 accuracy 0.800900936126709 epoch 53 done\n",
            "train loss 19.653397332067076 accuracy 0.8040540814399719 epoch 54 done\n",
            "train loss 19.56070839840433 accuracy 0.8033784031867981 epoch 55 done\n",
            "train loss 19.57343474678371 accuracy 0.8058558702468872 epoch 56 done\n",
            "train loss 19.525028912917428 accuracy 0.8040540814399719 epoch 57 done\n",
            "train loss 19.429804884869117 accuracy 0.8108108043670654 epoch 58 done\n",
            "train loss 19.552401667055875 accuracy 0.8005630970001221 epoch 59 done\n",
            "train loss 19.112772215967592 accuracy 0.8073198199272156 epoch 60 done\n",
            "train loss 19.454634998155676 accuracy 0.8058558702468872 epoch 61 done\n",
            "train loss 19.26972438978112 accuracy 0.8099099397659302 epoch 62 done\n",
            "train loss 19.37216563846754 accuracy 0.8099099397659302 epoch 63 done\n",
            "train loss 19.329848932183307 accuracy 0.8074324727058411 epoch 64 done\n",
            "train loss 19.392013508340586 accuracy 0.806869387626648 epoch 65 done\n",
            "train loss 18.960652040398642 accuracy 0.8108108043670654 epoch 66 done\n",
            "train loss 19.18612301867941 accuracy 0.8084459900856018 epoch 67 done\n",
            "train loss 19.26378811960635 accuracy 0.8072072267532349 epoch 68 done\n",
            "train loss 18.994519337363865 accuracy 0.8110360503196716 epoch 69 done\n",
            "train loss 18.922469968381137 accuracy 0.8130630850791931 epoch 70 done\n",
            "train loss 19.170531438744586 accuracy 0.8129504919052124 epoch 71 done\n",
            "train loss 19.217581417249598 accuracy 0.8127252459526062 epoch 72 done\n",
            "train loss 19.021046389704164 accuracy 0.8149775266647339 epoch 73 done\n",
            "train loss 18.74617684405783 accuracy 0.8172297477722168 epoch 74 done\n",
            "train loss 19.000145456065304 accuracy 0.8111486434936523 epoch 75 done\n",
            "train loss 18.912983977276344 accuracy 0.8135135173797607 epoch 76 done\n",
            "train loss 18.69539849654488 accuracy 0.8156531453132629 epoch 77 done\n",
            "train loss 19.089316782744035 accuracy 0.8102477788925171 epoch 78 done\n",
            "train loss 18.914787561997123 accuracy 0.8122748136520386 epoch 79 done\n",
            "train loss 19.131105132724926 accuracy 0.8078829050064087 epoch 80 done\n",
            "train loss 18.916004823601764 accuracy 0.8139640092849731 epoch 81 done\n",
            "train loss 18.552498174750287 accuracy 0.8200450539588928 epoch 82 done\n",
            "train loss 18.92827440344769 accuracy 0.8163288235664368 epoch 83 done\n",
            "train loss 18.72473625514818 accuracy 0.8144144415855408 epoch 84 done\n",
            "train loss 18.916272889012873 accuracy 0.8138513565063477 epoch 85 done\n",
            "train loss 18.66637146991232 accuracy 0.8095721006393433 epoch 86 done\n",
            "train loss 18.651608073193092 accuracy 0.8197072148323059 epoch 87 done\n",
            "train loss 18.617996879245926 accuracy 0.8158783912658691 epoch 88 done\n",
            "train loss 18.50977495442266 accuracy 0.8173423409461975 epoch 89 done\n",
            "train loss 18.719573290451713 accuracy 0.8176801800727844 epoch 90 done\n",
            "train loss 18.615533994591758 accuracy 0.8139640092849731 epoch 91 done\n",
            "train loss 18.63668512261432 accuracy 0.819369375705719 epoch 92 done\n",
            "train loss 18.580842702285103 accuracy 0.8155405521392822 epoch 93 done\n",
            "train loss 18.595845201741092 accuracy 0.8171171545982361 epoch 94 done\n",
            "train loss 18.785692443018377 accuracy 0.816216230392456 epoch 95 done\n",
            "train loss 18.556595180345617 accuracy 0.8176801800727844 epoch 96 done\n",
            "train loss 18.493719246076502 accuracy 0.8168919086456299 epoch 97 done\n",
            "train loss 18.30577790218851 accuracy 0.8185811042785645 epoch 98 done\n",
            "train loss 18.437001124672268 accuracy 0.8185811042785645 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.6940000057220459 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "289f5b3abae84283a45f4f30aaff6288"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇█████████████████</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.694</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.81858</td></tr><tr><td>Training loss</td><td>18.437</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">clean-sweep-5</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/9frnsa9x\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/9frnsa9x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_121627-9frnsa9x/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lr5mt1dq with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_123224-lr5mt1dq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/lr5mt1dq\" target=\"_blank\">vibrant-sweep-6</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.26246916729471 accuracy 0.6353603601455688 epoch 0 done\n",
            "train loss 27.371312473131262 accuracy 0.6922297477722168 epoch 1 done\n",
            "train loss 26.132864413054094 accuracy 0.7100225687026978 epoch 2 done\n",
            "train loss 25.42656647640726 accuracy 0.7248874306678772 epoch 3 done\n",
            "train loss 24.930038203363836 accuracy 0.7262387275695801 epoch 4 done\n",
            "train loss 24.783239447552226 accuracy 0.7386261224746704 epoch 5 done\n",
            "train loss 24.551229207412057 accuracy 0.7372747659683228 epoch 6 done\n",
            "train loss 24.09126445521479 accuracy 0.7454954981803894 epoch 7 done\n",
            "train loss 23.92397167371667 accuracy 0.7467342615127563 epoch 8 done\n",
            "train loss 23.720080251279086 accuracy 0.7550675868988037 epoch 9 done\n",
            "train loss 23.42531861429629 accuracy 0.753716230392456 epoch 10 done\n",
            "train loss 23.23101124556168 accuracy 0.7574324607849121 epoch 11 done\n",
            "train loss 23.20965511902519 accuracy 0.7620495557785034 epoch 12 done\n",
            "train loss 22.95969766119252 accuracy 0.7599099278450012 epoch 13 done\n",
            "train loss 22.5654762516851 accuracy 0.7638513445854187 epoch 14 done\n",
            "train loss 22.264106149258822 accuracy 0.774324357509613 epoch 15 done\n",
            "train loss 22.328530809153683 accuracy 0.7726351618766785 epoch 16 done\n",
            "train loss 22.159110214399256 accuracy 0.774324357509613 epoch 17 done\n",
            "train loss 21.901027513586957 accuracy 0.7778153419494629 epoch 18 done\n",
            "train loss 21.867625962132994 accuracy 0.7757883071899414 epoch 19 done\n",
            "train loss 21.655909766321596 accuracy 0.7781531810760498 epoch 20 done\n",
            "train loss 21.728519854338273 accuracy 0.7770270705223083 epoch 21 done\n",
            "train loss 21.286791241687276 accuracy 0.789076566696167 epoch 22 done\n",
            "train loss 21.444044527800187 accuracy 0.7851351499557495 epoch 23 done\n",
            "train loss 21.343581324038297 accuracy 0.7847973108291626 epoch 24 done\n",
            "train loss 21.015190974525783 accuracy 0.7873874306678772 epoch 25 done\n",
            "train loss 21.253809991090193 accuracy 0.7850225567817688 epoch 26 done\n",
            "train loss 20.884773627571438 accuracy 0.7868243455886841 epoch 27 done\n",
            "train loss 20.97314341171928 accuracy 0.79313063621521 epoch 28 done\n",
            "train loss 20.74243352724158 accuracy 0.7932432889938354 epoch 29 done\n",
            "train loss 20.86593186337015 accuracy 0.7902027368545532 epoch 30 done\n",
            "train loss 20.582967219145402 accuracy 0.7907657623291016 epoch 31 done\n",
            "train loss 20.695886010709017 accuracy 0.7932432889938354 epoch 32 done\n",
            "train loss 20.340726479240086 accuracy 0.7972972989082336 epoch 33 done\n",
            "train loss 20.31709977854853 accuracy 0.7939189672470093 epoch 34 done\n",
            "train loss 20.74497421928074 accuracy 0.7889639735221863 epoch 35 done\n",
            "train loss 20.307301811549973 accuracy 0.79313063621521 epoch 36 done\n",
            "train loss 20.343192141989004 accuracy 0.7995495796203613 epoch 37 done\n",
            "train loss 20.481654457424 accuracy 0.7929054498672485 epoch 38 done\n",
            "train loss 20.401102397752844 accuracy 0.7944819927215576 epoch 39 done\n",
            "train loss 20.25190846816353 accuracy 0.7943693995475769 epoch 40 done\n",
            "train loss 20.160680750141974 accuracy 0.7979729771614075 epoch 41 done\n",
            "train loss 20.24367029770561 accuracy 0.7970721125602722 epoch 42 done\n",
            "train loss 20.37809013283771 accuracy 0.7978603839874268 epoch 43 done\n",
            "train loss 20.127850864244543 accuracy 0.800000011920929 epoch 44 done\n",
            "train loss 19.90874474981557 accuracy 0.805630624294281 epoch 45 done\n",
            "train loss 19.97735058743021 accuracy 0.8016892075538635 epoch 46 done\n",
            "train loss 20.045640903970472 accuracy 0.7997747659683228 epoch 47 done\n",
            "train loss 20.114843575850777 accuracy 0.8029279708862305 epoch 48 done\n",
            "train loss 19.579861827518627 accuracy 0.8088964223861694 epoch 49 done\n",
            "train loss 20.058724403381348 accuracy 0.8034909963607788 epoch 50 done\n",
            "train loss 19.76257436171822 accuracy 0.8041666746139526 epoch 51 done\n",
            "train loss 19.649654554284137 accuracy 0.8036036491394043 epoch 52 done\n",
            "train loss 19.9017538609712 accuracy 0.8007882833480835 epoch 53 done\n",
            "train loss 19.739085114520527 accuracy 0.8045045137405396 epoch 54 done\n",
            "train loss 19.942810804947563 accuracy 0.8050675988197327 epoch 55 done\n",
            "train loss 20.118118866630223 accuracy 0.7983108162879944 epoch 56 done\n",
            "train loss 19.703717646391496 accuracy 0.8041666746139526 epoch 57 done\n",
            "train loss 19.797817147296406 accuracy 0.8085585832595825 epoch 58 done\n",
            "train loss 19.433884040169094 accuracy 0.8087838292121887 epoch 59 done\n",
            "train loss 19.600672701130744 accuracy 0.8054054379463196 epoch 60 done\n",
            "train loss 19.587643478227697 accuracy 0.8034909963607788 epoch 61 done\n",
            "train loss 19.63565789098325 accuracy 0.8052927851676941 epoch 62 done\n",
            "train loss 19.496867034746252 accuracy 0.8050675988197327 epoch 63 done\n",
            "train loss 19.467046882795252 accuracy 0.8114864826202393 epoch 64 done\n",
            "train loss 19.34786089606907 accuracy 0.8084459900856018 epoch 65 done\n",
            "train loss 19.456709509310514 accuracy 0.8063063025474548 epoch 66 done\n",
            "train loss 19.71941145606663 accuracy 0.8045045137405396 epoch 67 done\n",
            "train loss 19.59068312852279 accuracy 0.8041666746139526 epoch 68 done\n",
            "train loss 19.432508655216385 accuracy 0.8082207441329956 epoch 69 done\n",
            "train loss 19.271204471588135 accuracy 0.8083333373069763 epoch 70 done\n",
            "train loss 19.186497190724246 accuracy 0.8106982111930847 epoch 71 done\n",
            "train loss 19.25978359968766 accuracy 0.8069819808006287 epoch 72 done\n",
            "train loss 18.937711777894393 accuracy 0.8131756782531738 epoch 73 done\n",
            "train loss 19.73003862215125 accuracy 0.8002252578735352 epoch 74 done\n",
            "train loss 19.145070469897725 accuracy 0.8110360503196716 epoch 75 done\n",
            "train loss 19.213503091231637 accuracy 0.8072072267532349 epoch 76 done\n",
            "train loss 18.88315945086272 accuracy 0.814639687538147 epoch 77 done\n",
            "train loss 19.224244594573975 accuracy 0.8102477788925171 epoch 78 done\n",
            "train loss 19.27660204016644 accuracy 0.8085585832595825 epoch 79 done\n",
            "train loss 19.193545134171195 accuracy 0.8084459900856018 epoch 80 done\n",
            "train loss 19.490287531977113 accuracy 0.8087838292121887 epoch 81 done\n",
            "train loss 18.970272478849992 accuracy 0.8125 epoch 82 done\n",
            "train loss 19.0339851172074 accuracy 0.8143018484115601 epoch 83 done\n",
            "train loss 19.192582959714144 accuracy 0.8109234571456909 epoch 84 done\n",
            "train loss 19.047590359397557 accuracy 0.8131756782531738 epoch 85 done\n",
            "train loss 18.95105144251948 accuracy 0.8147522807121277 epoch 86 done\n",
            "train loss 19.134325815283734 accuracy 0.8101351261138916 epoch 87 done\n",
            "train loss 18.828144301538885 accuracy 0.8143018484115601 epoch 88 done\n",
            "train loss 18.955786539160687 accuracy 0.8112612962722778 epoch 89 done\n",
            "train loss 19.020830942236856 accuracy 0.8171171545982361 epoch 90 done\n",
            "train loss 18.99546546521394 accuracy 0.8154279589653015 epoch 91 done\n",
            "train loss 18.876863458882205 accuracy 0.8113738894462585 epoch 92 done\n",
            "train loss 19.089306541111156 accuracy 0.8130630850791931 epoch 93 done\n",
            "train loss 18.878267080887504 accuracy 0.81340092420578 epoch 94 done\n",
            "train loss 19.032446405161984 accuracy 0.8122748136520386 epoch 95 done\n",
            "train loss 18.690257922462795 accuracy 0.8192567825317383 epoch 96 done\n",
            "train loss 18.570605817048445 accuracy 0.8166666626930237 epoch 97 done\n",
            "train loss 19.017099546349566 accuracy 0.8122748136520386 epoch 98 done\n",
            "train loss 18.77169779072637 accuracy 0.8154279589653015 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.718000054359436 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a56b3b0c45444a21b4469833805e4953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇████████████</td></tr><tr><td>Training loss</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.718</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.81543</td></tr><tr><td>Training loss</td><td>18.7717</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vibrant-sweep-6</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/lr5mt1dq\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/lr5mt1dq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_123224-lr5mt1dq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: urx0zdda with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_124817-urx0zdda</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/urx0zdda\" target=\"_blank\">fresh-sweep-7</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 30.402361413706906 accuracy 0.6323198080062866 epoch 0 done\n",
            "train loss 27.339606430219565 accuracy 0.6751126050949097 epoch 1 done\n",
            "train loss 26.067598736804467 accuracy 0.7027027010917664 epoch 2 done\n",
            "train loss 25.391042730082635 accuracy 0.7153153419494629 epoch 3 done\n",
            "train loss 24.94503914791605 accuracy 0.7317567467689514 epoch 4 done\n",
            "train loss 24.747097284897514 accuracy 0.7307432889938354 epoch 5 done\n",
            "train loss 24.45906236897344 accuracy 0.7382882833480835 epoch 6 done\n",
            "train loss 24.288767441459328 accuracy 0.7438063025474548 epoch 7 done\n",
            "train loss 24.225655555725098 accuracy 0.7441441416740417 epoch 8 done\n",
            "train loss 23.86943767381751 accuracy 0.7462838292121887 epoch 9 done\n",
            "train loss 23.957150023916494 accuracy 0.7468468546867371 epoch 10 done\n",
            "train loss 24.115855569424834 accuracy 0.7438063025474548 epoch 11 done\n",
            "train loss 23.71028056352035 accuracy 0.7495495676994324 epoch 12 done\n",
            "train loss 23.611215819483217 accuracy 0.7493243217468262 epoch 13 done\n",
            "train loss 23.456796459529713 accuracy 0.7538288235664368 epoch 14 done\n",
            "train loss 23.2957618340202 accuracy 0.7542793154716492 epoch 15 done\n",
            "train loss 23.221020636351213 accuracy 0.7534909844398499 epoch 16 done\n",
            "train loss 23.163072233614713 accuracy 0.7599099278450012 epoch 17 done\n",
            "train loss 23.076564063196596 accuracy 0.754054069519043 epoch 18 done\n",
            "train loss 22.782551309336785 accuracy 0.7610360383987427 epoch 19 done\n",
            "train loss 22.916061940400496 accuracy 0.761824369430542 epoch 20 done\n",
            "train loss 22.764589558476988 accuracy 0.7659910321235657 epoch 21 done\n",
            "train loss 22.70643887312516 accuracy 0.7656531929969788 epoch 22 done\n",
            "train loss 22.37083323105522 accuracy 0.7688063383102417 epoch 23 done\n",
            "train loss 22.369888948357623 accuracy 0.7688063383102417 epoch 24 done\n",
            "train loss 22.34141202594923 accuracy 0.7724099159240723 epoch 25 done\n",
            "train loss 22.071412563323975 accuracy 0.7726351618766785 epoch 26 done\n",
            "train loss 22.002655713454537 accuracy 0.7730855941772461 epoch 27 done\n",
            "train loss 22.073912599812385 accuracy 0.7727477550506592 epoch 28 done\n",
            "train loss 21.75728244366853 accuracy 0.7766892313957214 epoch 29 done\n",
            "train loss 21.775532888329547 accuracy 0.7740991115570068 epoch 30 done\n",
            "train loss 21.611712476481564 accuracy 0.7826576828956604 epoch 31 done\n",
            "train loss 21.669200959412947 accuracy 0.7813063263893127 epoch 32 done\n",
            "train loss 21.225234093873397 accuracy 0.785923421382904 epoch 33 done\n",
            "train loss 21.732197699339494 accuracy 0.7828829288482666 epoch 34 done\n",
            "train loss 21.386942282966945 accuracy 0.7841216325759888 epoch 35 done\n",
            "train loss 21.44793350800224 accuracy 0.7836712002754211 epoch 36 done\n",
            "train loss 21.077125549316406 accuracy 0.7897522449493408 epoch 37 done\n",
            "train loss 21.216093768244203 accuracy 0.7888513803482056 epoch 38 done\n",
            "train loss 21.25420327808546 accuracy 0.7856982350349426 epoch 39 done\n",
            "train loss 21.003641916357953 accuracy 0.789076566696167 epoch 40 done\n",
            "train loss 21.019158384074334 accuracy 0.7900900840759277 epoch 41 done\n",
            "train loss 20.977009275685187 accuracy 0.7904279232025146 epoch 42 done\n",
            "train loss 21.08732275340868 accuracy 0.7841216325759888 epoch 43 done\n",
            "train loss 20.895845952241316 accuracy 0.7902027368545532 epoch 44 done\n",
            "train loss 21.19194623698359 accuracy 0.7853603959083557 epoch 45 done\n",
            "train loss 20.784522637077 accuracy 0.788063108921051 epoch 46 done\n",
            "train loss 20.647701864657193 accuracy 0.7951576709747314 epoch 47 done\n",
            "train loss 20.62644923251608 accuracy 0.7944819927215576 epoch 48 done\n",
            "train loss 20.576129954794176 accuracy 0.7960585951805115 epoch 49 done\n",
            "train loss 20.858313954394795 accuracy 0.7868243455886841 epoch 50 done\n",
            "train loss 20.631925002388332 accuracy 0.7920045256614685 epoch 51 done\n",
            "train loss 20.619181757387906 accuracy 0.7954955101013184 epoch 52 done\n",
            "train loss 20.438926800437596 accuracy 0.7972972989082336 epoch 53 done\n",
            "train loss 20.65988126008407 accuracy 0.7906531691551208 epoch 54 done\n",
            "train loss 20.619057696798574 accuracy 0.7917792797088623 epoch 55 done\n",
            "train loss 20.295425041862156 accuracy 0.797747790813446 epoch 56 done\n",
            "train loss 20.525633376577627 accuracy 0.795945942401886 epoch 57 done\n",
            "train loss 20.41979227895322 accuracy 0.795945942401886 epoch 58 done\n",
            "train loss 20.370844156845756 accuracy 0.799662172794342 epoch 59 done\n",
            "train loss 20.332346190576967 accuracy 0.7986486554145813 epoch 60 done\n",
            "train loss 20.57961555149244 accuracy 0.7956081032752991 epoch 61 done\n",
            "train loss 20.300425156303074 accuracy 0.8013513684272766 epoch 62 done\n",
            "train loss 20.472298311150592 accuracy 0.7945945858955383 epoch 63 done\n",
            "train loss 19.892205839571744 accuracy 0.8055180311203003 epoch 64 done\n",
            "train loss 20.150184672811758 accuracy 0.7985360622406006 epoch 65 done\n",
            "train loss 19.97937816122304 accuracy 0.796846866607666 epoch 66 done\n",
            "train loss 19.951143140378207 accuracy 0.8022522926330566 epoch 67 done\n",
            "train loss 20.300180082735807 accuracy 0.798085629940033 epoch 68 done\n",
            "train loss 19.72029173892477 accuracy 0.8025901317596436 epoch 69 done\n",
            "train loss 20.27543260740197 accuracy 0.8005630970001221 epoch 70 done\n",
            "train loss 20.13025553330131 accuracy 0.8003378510475159 epoch 71 done\n",
            "train loss 20.007657704146013 accuracy 0.8020270466804504 epoch 72 done\n",
            "train loss 20.094395243603252 accuracy 0.800000011920929 epoch 73 done\n",
            "train loss 19.880478547966998 accuracy 0.7985360622406006 epoch 74 done\n",
            "train loss 19.92129385989645 accuracy 0.8023648858070374 epoch 75 done\n",
            "train loss 20.003749930340312 accuracy 0.8023648858070374 epoch 76 done\n",
            "train loss 19.824395179748535 accuracy 0.8052927851676941 epoch 77 done\n",
            "train loss 19.82017720263937 accuracy 0.8058558702468872 epoch 78 done\n",
            "train loss 19.81300117658532 accuracy 0.8003378510475159 epoch 79 done\n",
            "train loss 19.549772946730904 accuracy 0.8078829050064087 epoch 80 done\n",
            "train loss 19.67597482515418 accuracy 0.8036036491394043 epoch 81 done\n",
            "train loss 19.65187290440435 accuracy 0.8102477788925171 epoch 82 done\n",
            "train loss 19.91841057072515 accuracy 0.8054054379463196 epoch 83 done\n",
            "train loss 19.662200326504916 accuracy 0.8075450658798218 epoch 84 done\n",
            "train loss 19.38510100737862 accuracy 0.8074324727058411 epoch 85 done\n",
            "train loss 19.672831452411156 accuracy 0.8073198199272156 epoch 86 done\n",
            "train loss 19.80062264981477 accuracy 0.8050675988197327 epoch 87 done\n",
            "train loss 19.66443333418473 accuracy 0.8029279708862305 epoch 88 done\n",
            "train loss 19.421704872794773 accuracy 0.8140766024589539 epoch 89 done\n",
            "train loss 19.636649422023606 accuracy 0.8075450658798218 epoch 90 done\n",
            "train loss 19.44150203207265 accuracy 0.8088964223861694 epoch 91 done\n",
            "train loss 19.5280820597773 accuracy 0.8047297596931458 epoch 92 done\n",
            "train loss 19.582960336104684 accuracy 0.8083333373069763 epoch 93 done\n",
            "train loss 19.171904294387154 accuracy 0.8112612962722778 epoch 94 done\n",
            "train loss 19.440921223681908 accuracy 0.8084459900856018 epoch 95 done\n",
            "train loss 19.70736733726833 accuracy 0.8061937093734741 epoch 96 done\n",
            "train loss 19.596453791079313 accuracy 0.8111486434936523 epoch 97 done\n",
            "train loss 19.511950969696045 accuracy 0.807770311832428 epoch 98 done\n",
            "train loss 19.34583211981732 accuracy 0.8122748136520386 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.7290000319480896 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dc21647dce9419db91ee003bfc2d344"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Training loss</td><td>█▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.729</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.81227</td></tr><tr><td>Training loss</td><td>19.34583</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fresh-sweep-7</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/urx0zdda\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/urx0zdda</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_124817-urx0zdda/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: emgq1aht with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_130410-emgq1aht</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/emgq1aht\" target=\"_blank\">summer-sweep-8</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 31.113447438115656 accuracy 0.610585629940033 epoch 0 done\n",
            "train loss 28.26682296006576 accuracy 0.6666666865348816 epoch 1 done\n",
            "train loss 27.092388982358187 accuracy 0.6931306719779968 epoch 2 done\n",
            "train loss 26.455907717995018 accuracy 0.7084459662437439 epoch 3 done\n",
            "train loss 25.7611925498299 accuracy 0.7248874306678772 epoch 4 done\n",
            "train loss 25.47875995221345 accuracy 0.723761260509491 epoch 5 done\n",
            "train loss 24.85911265663479 accuracy 0.7327702641487122 epoch 6 done\n",
            "train loss 24.422638976055644 accuracy 0.7434684634208679 epoch 7 done\n",
            "train loss 24.395288571067475 accuracy 0.7434684634208679 epoch 8 done\n",
            "train loss 23.95740094392196 accuracy 0.7462838292121887 epoch 9 done\n",
            "train loss 23.634822161301322 accuracy 0.7496621608734131 epoch 10 done\n",
            "train loss 23.409320789834727 accuracy 0.7551801800727844 epoch 11 done\n",
            "train loss 23.06557626309602 accuracy 0.761824369430542 epoch 12 done\n",
            "train loss 22.72225732388704 accuracy 0.7649775147438049 epoch 13 done\n",
            "train loss 22.742987508359164 accuracy 0.7655405402183533 epoch 14 done\n",
            "train loss 22.631227451822035 accuracy 0.762837827205658 epoch 15 done\n",
            "train loss 22.540335136911143 accuracy 0.763738751411438 epoch 16 done\n",
            "train loss 22.227387697800346 accuracy 0.7728604078292847 epoch 17 done\n",
            "train loss 22.166687053182848 accuracy 0.7692567706108093 epoch 18 done\n",
            "train loss 22.069332786228344 accuracy 0.7720720767974854 epoch 19 done\n",
            "train loss 21.900196365688156 accuracy 0.7745495438575745 epoch 20 done\n",
            "train loss 22.125260145767875 accuracy 0.7711712121963501 epoch 21 done\n",
            "train loss 22.025946098825205 accuracy 0.7736486792564392 epoch 22 done\n",
            "train loss 21.745180192201033 accuracy 0.7760135531425476 epoch 23 done\n",
            "train loss 21.65279548064522 accuracy 0.7814189195632935 epoch 24 done\n",
            "train loss 21.659387422644574 accuracy 0.7792792916297913 epoch 25 done\n",
            "train loss 21.51880571116572 accuracy 0.7786036133766174 epoch 26 done\n",
            "train loss 21.623660730279013 accuracy 0.7777027487754822 epoch 27 done\n",
            "train loss 21.42741170136825 accuracy 0.7832207679748535 epoch 28 done\n",
            "train loss 21.243015330770742 accuracy 0.786261260509491 epoch 29 done\n",
            "train loss 21.406865866287895 accuracy 0.7864865064620972 epoch 30 done\n",
            "train loss 21.372097326361615 accuracy 0.7841216325759888 epoch 31 done\n",
            "train loss 21.488602969957434 accuracy 0.7814189195632935 epoch 32 done\n",
            "train loss 20.99258773223214 accuracy 0.785923421382904 epoch 33 done\n",
            "train loss 21.162605575893238 accuracy 0.7838963866233826 epoch 34 done\n",
            "train loss 21.096214792002804 accuracy 0.7819820046424866 epoch 35 done\n",
            "train loss 20.859295119409975 accuracy 0.7906531691551208 epoch 36 done\n",
            "train loss 21.04853916168213 accuracy 0.7856982350349426 epoch 37 done\n",
            "train loss 20.90889431082684 accuracy 0.7875000238418579 epoch 38 done\n",
            "train loss 20.95576582784238 accuracy 0.7867117524147034 epoch 39 done\n",
            "train loss 20.913983013318934 accuracy 0.7889639735221863 epoch 40 done\n",
            "train loss 20.922833878061045 accuracy 0.7926802039146423 epoch 41 done\n",
            "train loss 20.787421205769412 accuracy 0.7902027368545532 epoch 42 done\n",
            "train loss 20.617386963056482 accuracy 0.7918919324874878 epoch 43 done\n",
            "train loss 20.568449165510096 accuracy 0.7935811281204224 epoch 44 done\n",
            "train loss 20.41601556280385 accuracy 0.792792797088623 epoch 45 done\n",
            "train loss 20.448016228883162 accuracy 0.7951576709747314 epoch 46 done\n",
            "train loss 20.41148353659588 accuracy 0.7965090274810791 epoch 47 done\n",
            "train loss 20.819082674772844 accuracy 0.7854729890823364 epoch 48 done\n",
            "train loss 20.769785963970683 accuracy 0.7918919324874878 epoch 49 done\n",
            "train loss 20.634574102318805 accuracy 0.7884009480476379 epoch 50 done\n",
            "train loss 20.433799432671588 accuracy 0.7945945858955383 epoch 51 done\n",
            "train loss 20.47900272452313 accuracy 0.79403156042099 epoch 52 done\n",
            "train loss 20.40236479303111 accuracy 0.800000011920929 epoch 53 done\n",
            "train loss 20.437374218650486 accuracy 0.7960585951805115 epoch 54 done\n",
            "train loss 20.25128350050553 accuracy 0.797747790813446 epoch 55 done\n",
            "train loss 20.128602525462277 accuracy 0.7992117404937744 epoch 56 done\n",
            "train loss 20.197026356406834 accuracy 0.7965090274810791 epoch 57 done\n",
            "train loss 20.363786593727443 accuracy 0.7994369268417358 epoch 58 done\n",
            "train loss 20.1325016229049 accuracy 0.8010135293006897 epoch 59 done\n",
            "train loss 20.099208583002504 accuracy 0.797747790813446 epoch 60 done\n",
            "train loss 20.33885255067245 accuracy 0.7985360622406006 epoch 61 done\n",
            "train loss 19.907408341117527 accuracy 0.800900936126709 epoch 62 done\n",
            "train loss 20.102411415265955 accuracy 0.7986486554145813 epoch 63 done\n",
            "train loss 19.722956325696863 accuracy 0.8057432770729065 epoch 64 done\n",
            "train loss 20.018001058827274 accuracy 0.795945942401886 epoch 65 done\n",
            "train loss 20.17475420495738 accuracy 0.798085629940033 epoch 66 done\n",
            "train loss 19.616812436476998 accuracy 0.8048423528671265 epoch 67 done\n",
            "train loss 19.99456324784652 accuracy 0.7993243336677551 epoch 68 done\n",
            "train loss 19.906494534533955 accuracy 0.8003378510475159 epoch 69 done\n",
            "train loss 20.107768556346066 accuracy 0.798085629940033 epoch 70 done\n",
            "train loss 20.06634886368461 accuracy 0.8038288354873657 epoch 71 done\n",
            "train loss 20.033607482910156 accuracy 0.8011261224746704 epoch 72 done\n",
            "train loss 19.62019920349121 accuracy 0.8052927851676941 epoch 73 done\n",
            "train loss 19.87929464423138 accuracy 0.8057432770729065 epoch 74 done\n",
            "train loss 19.801909819893215 accuracy 0.8019144535064697 epoch 75 done\n",
            "train loss 19.875185821367346 accuracy 0.8030405640602112 epoch 76 done\n",
            "train loss 19.849182564279307 accuracy 0.7994369268417358 epoch 77 done\n",
            "train loss 20.067125341166623 accuracy 0.7949324250221252 epoch 78 done\n",
            "train loss 19.83938619364863 accuracy 0.7983108162879944 epoch 79 done\n",
            "train loss 19.68306367293648 accuracy 0.803716242313385 epoch 80 done\n",
            "train loss 20.014596524445906 accuracy 0.8034909963607788 epoch 81 done\n",
            "train loss 19.556570675062098 accuracy 0.8086711764335632 epoch 82 done\n",
            "train loss 19.85959419996842 accuracy 0.8036036491394043 epoch 83 done\n",
            "train loss 19.61904075871343 accuracy 0.8085585832595825 epoch 84 done\n",
            "train loss 19.814517974853516 accuracy 0.8019144535064697 epoch 85 done\n",
            "train loss 19.79620529257733 accuracy 0.8029279708862305 epoch 86 done\n",
            "train loss 19.679728611655857 accuracy 0.8030405640602112 epoch 87 done\n",
            "train loss 19.56981140634288 accuracy 0.8091216683387756 epoch 88 done\n",
            "train loss 19.71209619356238 accuracy 0.8048423528671265 epoch 89 done\n",
            "train loss 19.635719112727955 accuracy 0.8111486434936523 epoch 90 done\n",
            "train loss 19.411181512086287 accuracy 0.810585618019104 epoch 91 done\n",
            "train loss 19.859000599902608 accuracy 0.8066441416740417 epoch 92 done\n",
            "train loss 19.76964635434358 accuracy 0.8039414882659912 epoch 93 done\n",
            "train loss 19.68579783646957 accuracy 0.8073198199272156 epoch 94 done\n",
            "train loss 19.457865300385848 accuracy 0.8076576590538025 epoch 95 done\n",
            "train loss 19.523737057395604 accuracy 0.8063063025474548 epoch 96 done\n",
            "train loss 19.75720911440642 accuracy 0.8033784031867981 epoch 97 done\n",
            "train loss 19.33815630622532 accuracy 0.8072072267532349 epoch 98 done\n",
            "train loss 19.475461835446566 accuracy 0.8076576590538025 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.8080000281333923 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "361e56aac99b439499bd97668070201c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████▇████████</td></tr><tr><td>Training loss</td><td>█▆▅▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.808</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.80766</td></tr><tr><td>Training loss</td><td>19.47546</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">summer-sweep-8</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/emgq1aht\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/emgq1aht</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_130410-emgq1aht/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n43irxoa with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_131954-n43irxoa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/n43irxoa\" target=\"_blank\">still-sweep-9</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 61.47571328107048 accuracy 0.6273863911628723 epoch 0 done\n",
            "train loss 53.80547109772178 accuracy 0.6871591210365295 epoch 1 done\n",
            "train loss 51.02374417641583 accuracy 0.7182954549789429 epoch 2 done\n",
            "train loss 49.70652900022619 accuracy 0.729204535484314 epoch 3 done\n",
            "train loss 48.65539316570057 accuracy 0.7368181943893433 epoch 4 done\n",
            "train loss 48.00342758964089 accuracy 0.7419317960739136 epoch 5 done\n",
            "train loss 47.78616352642284 accuracy 0.7438636422157288 epoch 6 done\n",
            "train loss 46.86183887369492 accuracy 0.753636360168457 epoch 7 done\n",
            "train loss 46.71508164966808 accuracy 0.7555682063102722 epoch 8 done\n",
            "train loss 46.52703182837543 accuracy 0.7561363577842712 epoch 9 done\n",
            "train loss 45.62708628878874 accuracy 0.7621591091156006 epoch 10 done\n",
            "train loss 45.431169874527875 accuracy 0.7627272605895996 epoch 11 done\n",
            "train loss 45.00708965694203 accuracy 0.7662500143051147 epoch 12 done\n",
            "train loss 44.684686702840466 accuracy 0.7681818008422852 epoch 13 done\n",
            "train loss 44.05215613982257 accuracy 0.7692045569419861 epoch 14 done\n",
            "train loss 44.291971543255976 accuracy 0.7643181681632996 epoch 15 done\n",
            "train loss 44.16351905991049 accuracy 0.7681818008422852 epoch 16 done\n",
            "train loss 43.756827634923596 accuracy 0.7740908861160278 epoch 17 done\n",
            "train loss 43.565806935815246 accuracy 0.7722727060317993 epoch 18 done\n",
            "train loss 43.21199777547051 accuracy 0.7744318246841431 epoch 19 done\n",
            "train loss 43.37702385117026 accuracy 0.7738636136054993 epoch 20 done\n",
            "train loss 42.82009758668787 accuracy 0.7796590924263 epoch 21 done\n",
            "train loss 42.43168002016404 accuracy 0.7819318175315857 epoch 22 done\n",
            "train loss 42.63041588839363 accuracy 0.7807954549789429 epoch 23 done\n",
            "train loss 41.82065463066101 accuracy 0.7888636589050293 epoch 24 done\n",
            "train loss 41.126286296283496 accuracy 0.7948863506317139 epoch 25 done\n",
            "train loss 41.6792475195492 accuracy 0.7914772629737854 epoch 26 done\n",
            "train loss 41.16943948409137 accuracy 0.7925000190734863 epoch 27 done\n",
            "train loss 40.72730852575863 accuracy 0.7943181991577148 epoch 28 done\n",
            "train loss 40.80376208529753 accuracy 0.7920454740524292 epoch 29 done\n",
            "train loss 40.64059214030995 accuracy 0.7951136231422424 epoch 30 done\n",
            "train loss 39.884574862087476 accuracy 0.7990909218788147 epoch 31 done\n",
            "train loss 40.2079426541048 accuracy 0.7943181991577148 epoch 32 done\n",
            "train loss 39.55953858880436 accuracy 0.8010227084159851 epoch 33 done\n",
            "train loss 38.94517497455372 accuracy 0.8029545545578003 epoch 34 done\n",
            "train loss 39.57711162286646 accuracy 0.8010227084159851 epoch 35 done\n",
            "train loss 38.487691093893616 accuracy 0.8111363649368286 epoch 36 done\n",
            "train loss 39.08495319590849 accuracy 0.8023863434791565 epoch 37 done\n",
            "train loss 38.715637249105114 accuracy 0.8056818246841431 epoch 38 done\n",
            "train loss 38.28805063752567 accuracy 0.8107954859733582 epoch 39 done\n",
            "train loss 38.38419173745548 accuracy 0.807272732257843 epoch 40 done\n",
            "train loss 39.02396712583654 accuracy 0.8050000071525574 epoch 41 done\n",
            "train loss 38.066121970905975 accuracy 0.8115909099578857 epoch 42 done\n",
            "train loss 37.63161576495451 accuracy 0.8142045736312866 epoch 43 done\n",
            "train loss 38.02156665044672 accuracy 0.8121591210365295 epoch 44 done\n",
            "train loss 37.98543342422037 accuracy 0.8148863911628723 epoch 45 done\n",
            "train loss 37.60407808247734 accuracy 0.8137500286102295 epoch 46 done\n",
            "train loss 37.96100706212661 accuracy 0.8135227560997009 epoch 47 done\n",
            "train loss 37.83322826553793 accuracy 0.816136360168457 epoch 48 done\n",
            "train loss 37.101019116008985 accuracy 0.8201136589050293 epoch 49 done\n",
            "train loss 36.937760689679315 accuracy 0.8202272653579712 epoch 50 done\n",
            "train loss 36.95449725319357 accuracy 0.8190909028053284 epoch 51 done\n",
            "train loss 37.19377448979546 accuracy 0.8148863911628723 epoch 52 done\n",
            "train loss 36.45028470544254 accuracy 0.8204545378684998 epoch 53 done\n",
            "train loss 36.21762591951034 accuracy 0.8279545307159424 epoch 54 done\n",
            "train loss 37.123360213111425 accuracy 0.8195454478263855 epoch 55 done\n",
            "train loss 37.259053482728845 accuracy 0.8159090876579285 epoch 56 done\n",
            "train loss 36.70731492603527 accuracy 0.824431836605072 epoch 57 done\n",
            "train loss 36.87468775580911 accuracy 0.8217045664787292 epoch 58 done\n",
            "train loss 36.90672877255608 accuracy 0.819204568862915 epoch 59 done\n",
            "train loss 36.731599541271436 accuracy 0.8228409290313721 epoch 60 done\n",
            "train loss 36.89090571683996 accuracy 0.8172727227210999 epoch 61 done\n",
            "train loss 36.33798400093527 accuracy 0.8251136541366577 epoch 62 done\n",
            "train loss 36.355156660079956 accuracy 0.8205682039260864 epoch 63 done\n",
            "train loss 36.58891212238985 accuracy 0.8204545378684998 epoch 64 done\n",
            "train loss 35.71444071040434 accuracy 0.8278409242630005 epoch 65 done\n",
            "train loss 36.20988123557147 accuracy 0.8247727155685425 epoch 66 done\n",
            "train loss 36.21571869008682 accuracy 0.8292045593261719 epoch 67 done\n",
            "train loss 35.99457200835733 accuracy 0.8271591067314148 epoch 68 done\n",
            "train loss 36.44678533778471 accuracy 0.8203409314155579 epoch 69 done\n",
            "train loss 36.27765415696537 accuracy 0.8228409290313721 epoch 70 done\n",
            "train loss 35.931366373510926 accuracy 0.8262500166893005 epoch 71 done\n",
            "train loss 36.37444067001343 accuracy 0.8198863863945007 epoch 72 done\n",
            "train loss 35.348765036639044 accuracy 0.8270454406738281 epoch 73 done\n",
            "train loss 35.73505038373611 accuracy 0.826022744178772 epoch 74 done\n",
            "train loss 35.57151376499849 accuracy 0.8287500143051147 epoch 75 done\n",
            "train loss 35.89895796775818 accuracy 0.8268181681632996 epoch 76 done\n",
            "train loss 36.311740089865296 accuracy 0.8236363530158997 epoch 77 done\n",
            "train loss 35.80513046769535 accuracy 0.824999988079071 epoch 78 done\n",
            "train loss 35.60479960020851 accuracy 0.8322727084159851 epoch 79 done\n",
            "train loss 35.93337952389437 accuracy 0.8262500166893005 epoch 80 done\n",
            "train loss 35.45828375395607 accuracy 0.8336363434791565 epoch 81 done\n",
            "train loss 35.72682422750137 accuracy 0.8286363482475281 epoch 82 done\n",
            "train loss 35.4101292666267 accuracy 0.8289772868156433 epoch 83 done\n",
            "train loss 35.589507306323334 accuracy 0.8293181657791138 epoch 84 done\n",
            "train loss 35.23196036675397 accuracy 0.8311363458633423 epoch 85 done\n",
            "train loss 35.439943734337305 accuracy 0.8247727155685425 epoch 86 done\n",
            "train loss 35.6038312701618 accuracy 0.8294318318367004 epoch 87 done\n",
            "train loss 35.65350786377402 accuracy 0.828181803226471 epoch 88 done\n",
            "train loss 35.453651778838214 accuracy 0.8294318318367004 epoch 89 done\n",
            "train loss 35.370549475445465 accuracy 0.8315908908843994 epoch 90 done\n",
            "train loss 35.4274560844197 accuracy 0.8299999833106995 epoch 91 done\n",
            "train loss 35.2147175283993 accuracy 0.8319318294525146 epoch 92 done\n",
            "train loss 35.127358085968915 accuracy 0.8331817984580994 epoch 93 done\n",
            "train loss 34.92784193684073 accuracy 0.8346590995788574 epoch 94 done\n",
            "train loss 34.70590403500725 accuracy 0.8344318270683289 epoch 95 done\n",
            "train loss 34.613128676134 accuracy 0.8347727060317993 epoch 96 done\n",
            "train loss 34.86028420223909 accuracy 0.8319318294525146 epoch 97 done\n",
            "train loss 35.114010235842535 accuracy 0.8305681943893433 epoch 98 done\n",
            "train loss 34.90602165109971 accuracy 0.8310227394104004 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.6324073672294617 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8929d163b4746fa9ae88945b62a62d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█████████████████</td></tr><tr><td>Training loss</td><td>█▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.63241</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.83102</td></tr><tr><td>Training loss</td><td>34.90602</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">still-sweep-9</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/n43irxoa\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/n43irxoa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_131954-n43irxoa/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hayr8ea9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_133535-hayr8ea9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/hayr8ea9\" target=\"_blank\">fearless-sweep-10</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 74.37151735169547 accuracy 0.6484581828117371 epoch 0 done\n",
            "train loss 66.68425282410213 accuracy 0.6959251165390015 epoch 1 done\n",
            "train loss 63.71790759904044 accuracy 0.7194933891296387 epoch 2 done\n",
            "train loss 62.63754573890141 accuracy 0.7246696352958679 epoch 3 done\n",
            "train loss 61.86646342277527 accuracy 0.7289648056030273 epoch 4 done\n",
            "train loss 61.0097497190748 accuracy 0.7379956245422363 epoch 5 done\n",
            "train loss 60.04591604641506 accuracy 0.7448238134384155 epoch 6 done\n",
            "train loss 59.87995444025312 accuracy 0.7422907948493958 epoch 7 done\n",
            "train loss 59.243744015693665 accuracy 0.7509912252426147 epoch 8 done\n",
            "train loss 58.416324734687805 accuracy 0.7546255588531494 epoch 9 done\n",
            "train loss 58.214766076632905 accuracy 0.7540749311447144 epoch 10 done\n",
            "train loss 57.12016148226601 accuracy 0.7599118947982788 epoch 11 done\n",
            "train loss 57.03033261639731 accuracy 0.7620044350624084 epoch 12 done\n",
            "train loss 56.058409452438354 accuracy 0.766740083694458 epoch 13 done\n",
            "train loss 55.93061113357544 accuracy 0.7665198445320129 epoch 14 done\n",
            "train loss 55.60656227384295 accuracy 0.7702643275260925 epoch 15 done\n",
            "train loss 54.91688515458788 accuracy 0.7729074954986572 epoch 16 done\n",
            "train loss 54.91225816522326 accuracy 0.7707048654556274 epoch 17 done\n",
            "train loss 54.30131190163748 accuracy 0.7774229049682617 epoch 18 done\n",
            "train loss 54.20771670341492 accuracy 0.7762115001678467 epoch 19 done\n",
            "train loss 53.47562655380794 accuracy 0.7784141302108765 epoch 20 done\n",
            "train loss 53.52064755984715 accuracy 0.7777533531188965 epoch 21 done\n",
            "train loss 53.027581572532654 accuracy 0.7839207053184509 epoch 22 done\n",
            "train loss 52.94148092610495 accuracy 0.783480167388916 epoch 23 done\n",
            "train loss 52.30504769938332 accuracy 0.7848017811775208 epoch 24 done\n",
            "train loss 52.67933535575867 accuracy 0.7859030961990356 epoch 25 done\n",
            "train loss 52.31221599238259 accuracy 0.7830396890640259 epoch 26 done\n",
            "train loss 52.66322754110609 accuracy 0.7827093005180359 epoch 27 done\n",
            "train loss 51.66739276477269 accuracy 0.7848017811775208 epoch 28 done\n",
            "train loss 52.133765254701885 accuracy 0.7870044112205505 epoch 29 done\n",
            "train loss 51.047610589436125 accuracy 0.7918502688407898 epoch 30 done\n",
            "train loss 51.162411434309824 accuracy 0.7918502688407898 epoch 31 done\n",
            "train loss 50.31470326014927 accuracy 0.8012114763259888 epoch 32 done\n",
            "train loss 50.89337514128004 accuracy 0.7971366047859192 epoch 33 done\n",
            "train loss 51.045775703021455 accuracy 0.7896475791931152 epoch 34 done\n",
            "train loss 50.769908973148894 accuracy 0.7962555289268494 epoch 35 done\n",
            "train loss 50.494238070079255 accuracy 0.7954846024513245 epoch 36 done\n",
            "train loss 50.63744463239397 accuracy 0.7969163060188293 epoch 37 done\n",
            "train loss 50.62889839921679 accuracy 0.7973568439483643 epoch 38 done\n",
            "train loss 50.05252397060394 accuracy 0.800330400466919 epoch 39 done\n",
            "train loss 49.6723450081689 accuracy 0.8015418648719788 epoch 40 done\n",
            "train loss 50.57699658189501 accuracy 0.7966960668563843 epoch 41 done\n",
            "train loss 49.62394385678427 accuracy 0.800330400466919 epoch 42 done\n",
            "train loss 50.191423007420134 accuracy 0.8025330305099487 epoch 43 done\n",
            "train loss 49.03056790147509 accuracy 0.8058370351791382 epoch 44 done\n",
            "train loss 49.09154677391052 accuracy 0.8030837178230286 epoch 45 done\n",
            "train loss 48.63817543642862 accuracy 0.8036344051361084 epoch 46 done\n",
            "train loss 48.84196313789913 accuracy 0.8071585893630981 epoch 47 done\n",
            "train loss 48.89499832902636 accuracy 0.8048458099365234 epoch 48 done\n",
            "train loss 49.05175602436066 accuracy 0.8017621636390686 epoch 49 done\n",
            "train loss 48.732496057237896 accuracy 0.806718111038208 epoch 50 done\n",
            "train loss 48.648204701287405 accuracy 0.8049559593200684 epoch 51 done\n",
            "train loss 48.57614835671016 accuracy 0.8092511296272278 epoch 52 done\n",
            "train loss 48.7554258278438 accuracy 0.8063876628875732 epoch 53 done\n",
            "train loss 48.000852942466736 accuracy 0.8131057620048523 epoch 54 done\n",
            "train loss 47.90343035970415 accuracy 0.8094713687896729 epoch 55 done\n",
            "train loss 49.201026575905935 accuracy 0.8042951822280884 epoch 56 done\n",
            "train loss 48.276858125414165 accuracy 0.8078194260597229 epoch 57 done\n",
            "train loss 48.48450739043099 accuracy 0.8075991272926331 epoch 58 done\n",
            "train loss 47.70772658075605 accuracy 0.8105726838111877 epoch 59 done\n",
            "train loss 48.30534430912563 accuracy 0.8081498146057129 epoch 60 done\n",
            "train loss 47.314041239874705 accuracy 0.8156387805938721 epoch 61 done\n",
            "train loss 47.88006683758327 accuracy 0.8072687387466431 epoch 62 done\n",
            "train loss 47.99429987158094 accuracy 0.808700442314148 epoch 63 done\n",
            "train loss 47.87985062599182 accuracy 0.8127753734588623 epoch 64 done\n",
            "train loss 47.201321891375954 accuracy 0.8140969276428223 epoch 65 done\n",
            "train loss 47.60145546708788 accuracy 0.8094713687896729 epoch 66 done\n",
            "train loss 47.06978947775705 accuracy 0.8138766884803772 epoch 67 done\n",
            "train loss 46.74224271093096 accuracy 0.8192731738090515 epoch 68 done\n",
            "train loss 47.77993241378239 accuracy 0.807378888130188 epoch 69 done\n",
            "train loss 47.50647124222347 accuracy 0.8140969276428223 epoch 70 done\n",
            "train loss 47.43926729474749 accuracy 0.8107929825782776 epoch 71 done\n",
            "train loss 47.21027689320701 accuracy 0.8129956126213074 epoch 72 done\n",
            "train loss 47.46227707181658 accuracy 0.8094713687896729 epoch 73 done\n",
            "train loss 47.07941620690482 accuracy 0.8131057620048523 epoch 74 done\n",
            "train loss 47.52772772312164 accuracy 0.8099119067192078 epoch 75 done\n",
            "train loss 47.75357513768332 accuracy 0.8069383502006531 epoch 76 done\n",
            "train loss 46.662340368543354 accuracy 0.8194934129714966 epoch 77 done\n",
            "train loss 46.710660338401794 accuracy 0.8176211714744568 epoch 78 done\n",
            "train loss 46.22328298432487 accuracy 0.8171806335449219 epoch 79 done\n",
            "train loss 46.55342950139727 accuracy 0.8188326358795166 epoch 80 done\n",
            "train loss 46.40134181295122 accuracy 0.8183920979499817 epoch 81 done\n",
            "train loss 47.31402734347752 accuracy 0.8153083920478821 epoch 82 done\n",
            "train loss 47.00269031524658 accuracy 0.8166300058364868 epoch 83 done\n",
            "train loss 46.481909445353914 accuracy 0.816740095615387 epoch 84 done\n",
            "train loss 47.23833315713065 accuracy 0.8107929825782776 epoch 85 done\n",
            "train loss 45.90003270762307 accuracy 0.8226872682571411 epoch 86 done\n",
            "train loss 46.451452425548005 accuracy 0.8189427256584167 epoch 87 done\n",
            "train loss 46.30173277003425 accuracy 0.8213656544685364 epoch 88 done\n",
            "train loss 46.56446359838758 accuracy 0.8158590793609619 epoch 89 done\n",
            "train loss 45.925977434430806 accuracy 0.8240088224411011 epoch 90 done\n",
            "train loss 45.88753657681602 accuracy 0.8212555050849915 epoch 91 done\n",
            "train loss 46.727532046181814 accuracy 0.8194934129714966 epoch 92 done\n",
            "train loss 46.094645619392395 accuracy 0.8198238015174866 epoch 93 done\n",
            "train loss 46.950053215026855 accuracy 0.8138766884803772 epoch 94 done\n",
            "train loss 46.36759196008955 accuracy 0.8221365809440613 epoch 95 done\n",
            "train loss 46.08048253399985 accuracy 0.8181717991828918 epoch 96 done\n",
            "train loss 46.110703468322754 accuracy 0.8174008727073669 epoch 97 done\n",
            "train loss 46.25296890735626 accuracy 0.8209251165390015 epoch 98 done\n",
            "train loss 45.36999872752599 accuracy 0.824779748916626 epoch 99 done\n",
            "nan\n",
            "TEST ACCURACY 0.6800000071525574 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3fa003cbff9433abea719141d9b550e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Training accuracy</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████████</td></tr><tr><td>Training loss</td><td>█▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total number of parameters</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.68</td></tr><tr><td>Test macro F1-Score</td><td>nan</td></tr><tr><td>Training accuracy</td><td>0.82478</td></tr><tr><td>Training loss</td><td>45.37</td></tr><tr><td>total number of parameters</td><td>3106</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fearless-sweep-10</strong>: <a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/hayr8ea9\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/runs/hayr8ea9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220822_133535-hayr8ea9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u9iuhjac with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CrossEntropyLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \truns: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubject: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220822_135147-u9iuhjac</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brain-imt/cho17_tests/runs/u9iuhjac\" target=\"_blank\">olive-sweep-11</a></strong> to <a href=\"https://wandb.ai/brain-imt/cho17_tests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92\" target=\"_blank\">https://wandb.ai/brain-imt/cho17_tests/sweeps/j09ylk92</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:419: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:446: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:447: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:463: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 32.05361163097879 accuracy 0.6217342615127563 epoch 0 done\n",
            "train loss 28.163392605988875 accuracy 0.678716242313385 epoch 1 done\n",
            "train loss 26.76347259853197 accuracy 0.7031531929969788 epoch 2 done\n",
            "train loss 26.205646805141285 accuracy 0.7131757140159607 epoch 3 done\n",
            "train loss 25.576910433561906 accuracy 0.7202702760696411 epoch 4 done\n",
            "train loss 25.36480314835258 accuracy 0.7245495915412903 epoch 5 done\n",
            "train loss 25.10478108862172 accuracy 0.7304054498672485 epoch 6 done\n",
            "train loss 24.783949209296186 accuracy 0.7382882833480835 epoch 7 done\n",
            "train loss 24.34609201680059 accuracy 0.7476351261138916 epoch 8 done\n",
            "train loss 24.329773902893066 accuracy 0.7424549460411072 epoch 9 done\n",
            "train loss 24.00716470635456 accuracy 0.7459459900856018 epoch 10 done\n",
            "train loss 23.94376777565998 accuracy 0.7497748136520386 epoch 11 done\n",
            "train loss 23.58054360099461 accuracy 0.7556306719779968 epoch 12 done\n",
            "train loss 23.391121905782946 accuracy 0.7586711645126343 epoch 13 done\n",
            "train loss 23.248721931291662 accuracy 0.7559685111045837 epoch 14 done\n",
            "train loss 23.024379999741264 accuracy 0.7639639973640442 epoch 15 done\n",
            "train loss 23.011499798816182 accuracy 0.7614865303039551 epoch 16 done\n",
            "train loss 22.801524825718094 accuracy 0.7638513445854187 epoch 17 done\n",
            "train loss 22.917866147082783 accuracy 0.7636261582374573 epoch 18 done\n",
            "train loss 22.733662252840787 accuracy 0.7683558464050293 epoch 19 done\n",
            "train loss 22.357110728388246 accuracy 0.773423433303833 epoch 20 done\n",
            "train loss 22.332104724386465 accuracy 0.7748873829841614 epoch 21 done\n",
            "train loss 22.305457467618197 accuracy 0.7648648619651794 epoch 22 done\n",
            "train loss 22.337511104086172 accuracy 0.7753378748893738 epoch 23 done\n",
            "train loss 22.26602245413739 accuracy 0.7751126289367676 epoch 24 done\n",
            "train loss 22.13810414853303 accuracy 0.7737612724304199 epoch 25 done\n",
            "train loss 21.831680442975916 accuracy 0.7761261463165283 epoch 26 done\n",
            "train loss 21.771155046380088 accuracy 0.7817567586898804 epoch 27 done\n",
            "train loss 22.202123268790867 accuracy 0.7718468904495239 epoch 28 done\n",
            "train loss 21.808994396873143 accuracy 0.7764639854431152 epoch 29 done\n",
            "train loss 21.832124005193297 accuracy 0.7742117047309875 epoch 30 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "project_name=\"cho17_tests\" #PhysioNet_tests   #bci4_tests   #cho17_tests   #sandbox\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'grid', #grid\n",
        "    'metric': {\n",
        "      'name': 'loss',\n",
        "      'goal': 'minimize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values': [3000]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64]\n",
        "        },\n",
        "        'patience': {\n",
        "            'values': [60]\n",
        "        },\n",
        "     \n",
        "        'learning_rate': {\n",
        "            'values': [1e-3]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adamw']\n",
        "        },\n",
        "         'loss': {\n",
        "            'values': ['CrossEntropyLoss'],\n",
        "        },\n",
        "        'subject': {\n",
        "            'values': [1,2,3,4,5,6,7,8,9,10]\n",
        "        },\n",
        "        'runs': {\n",
        "            'values': [1,2,3,4,5,6,7,8,9,10]\n",
        "        },\n",
        "      \n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
        "\n",
        "#number_of_subjects=9\n",
        "#bad_subjects=[] #bad subject for BCI-VI-2a\n",
        "#x, y= load_subjects('/content/drive/MyDrive/Colab Notebooks/bci4_subjects/', number_of_subjects, device, bad_subjects, apply_euclidean=False, with_eog=False)\n",
        "\n",
        "number_of_subjects=52\n",
        "bad_subjects=[32,46,49] #bad subject for Cho2017\n",
        "x, y= load_subjects('/content/drive/MyDrive/Colab Notebooks/mne_data/', number_of_subjects, device, bad_subjects, apply_euclidean=False, with_eog=False)\n",
        "\n",
        "#number_of_subjects=109\n",
        "#bad_subjects=[88,90,92,100] #bad subject for Physionet MI\n",
        "#x, y= load_subjects('/content/drive/MyDrive/Colab Notebooks/mne_data/', number_of_subjects, device, bad_subjects, apply_euclidean=True)\n",
        "\n",
        "def train_wandb():\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(project=project_name, entity=\"brain-imt\" , config=sweep_config)\n",
        "    assert run is wandb.run\n",
        "    with run:\n",
        "        config =wandb.config\n",
        "        #run=12\n",
        "        test_acc, f1=train_sweep(x, y, number_of_subjects, device, bad_subjects, config, run, resultdir)\n",
        "    ############################################################################\n",
        "\n",
        "#import os\n",
        "#os.environ[\"WANDB_MODE\"]=\"offline\"\n",
        "\n",
        "#Test_acc= train_wandb()\n",
        "wandb.agent(sweep_id, train_wandb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpq4_WZvwxzd"
      },
      "source": [
        "###Yassine's code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-xzeYvUwyCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fa3acd-6bf2-4111-95c2-499760431762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "Found 576 trial(s) in which EEG data is stored\n",
            "Computing reference matrix RefEA\n",
            "Add RefEA as a new key in data\n",
            "[64, 4, 4, 7] 744583 params\n",
            "Removed subject: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:315: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.814 \n",
            "number of the run  1\n",
            " 49 test: 0.776 \n",
            "number of the run  2\n",
            " 49 test: 0.800 \n",
            " average: 0.797\n",
            "Removed subject: 2\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.637 \n",
            "number of the run  1\n",
            " 49 test: 0.634 \n",
            "number of the run  2\n",
            " 49 test: 0.630 \n",
            " average: 0.634\n",
            "Removed subject: 3\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.766 \n",
            "number of the run  1\n",
            " 49 test: 0.783 \n",
            "number of the run  2\n",
            " 49 test: 0.780 \n",
            " average: 0.776\n",
            "Removed subject: 4\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.715 \n",
            "number of the run  1\n",
            " 49 test: 0.703 \n",
            "number of the run  2\n",
            " 49 test: 0.682 \n",
            " average: 0.700\n",
            "Removed subject: 5\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.760 \n",
            "number of the run  1\n",
            " 49 test: 0.759 \n",
            "number of the run  2\n",
            " 49 test: 0.786 \n",
            " average: 0.769\n",
            "Removed subject: 6\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.689 \n",
            "number of the run  1\n",
            " 49 test: 0.696 \n",
            "number of the run  2\n",
            " 49 test: 0.727 \n",
            " average: 0.704\n",
            "Removed subject: 7\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.887 \n",
            "number of the run  1\n",
            " 49 test: 0.868 \n",
            "number of the run  2\n",
            " 49 test: 0.875 \n",
            " average: 0.877\n",
            "Removed subject: 8\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.866 \n",
            "number of the run  1\n",
            " 49 test: 0.839 \n",
            "number of the run  2\n",
            " 49 test: 0.854 \n",
            " average: 0.853\n",
            "Removed subject: 9\n",
            "torch.Size([4608, 25, 1125])\n",
            "number of the run  0\n",
            " 49 test: 0.788 \n",
            "number of the run  1\n",
            " 49 test: 0.733 \n",
            "number of the run  2\n",
            " 49 test: 0.714 \n",
            " average: 0.745\n",
            "score is 0.762\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#hyperparameters\n",
        "batch_size = 144\n",
        "\n",
        "number_of_subjects=9\n",
        "bad_subjects=[] #bad subject for Physionet MI\n",
        "x, y= load_subjects('/content/drive/MyDrive/Colab Notebooks/bci4_subjects/', number_of_subjects, device, bad_subjects, apply_euclidean=True, with_eog=True)\n",
        "\n",
        "n_chan = x[0].shape[1]\n",
        "\n",
        "def loaders(removed_subject):\n",
        "    T_x,T_y,V_x,V_y,Test_x,Test_y=loso(x, y, number_of_subjects, removed_subject, device, bad_subjects, with_validation=False)\n",
        "    print(T_x.shape)\n",
        "    train_data = list(zip(T_x, T_y))\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, drop_last = True)\n",
        "    test_loader = torch.utils.data.DataLoader(list(zip(Test_x, Test_y)), batch_size = 1000)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, fm, n_convs, init_pool, kernel_size):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.pool = torch.nn.AvgPool1d(init_pool)\n",
        "        self.conv = torch.nn.Conv1d(n_chan, fm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)\n",
        "        self.bn = torch.nn.BatchNorm1d(fm)\n",
        "        self.blocks = []\n",
        "        newfm = fm\n",
        "        oldfm = fm\n",
        "        for i in range(n_convs):\n",
        "            if i > 0:\n",
        "                newfm = int(1.414 * newfm)\n",
        "            self.blocks.append(torch.nn.Sequential(\n",
        "                (torch.nn.Conv1d(oldfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.MaxPool1d(2) if i > 0 - 1 else torch.nn.MaxPool1d(1)),\n",
        "                (torch.nn.ReLU()),\n",
        "                (torch.nn.Conv1d(newfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.ReLU())\n",
        "            ))\n",
        "            oldfm = newfm\n",
        "        self.blocks = torch.nn.ModuleList(self.blocks)\n",
        "        self.fc = torch.nn.Linear(oldfm, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = torch.relu(self.bn(self.conv(self.pool(x))))\n",
        "        for seq in self.blocks:\n",
        "            y = seq(y)\n",
        "        y = y.mean(dim = 2)\n",
        "        return self.fc(y)\n",
        "    \n",
        "def train(epoch, model, criterion, optimizer, train_loader, mixup = False):\n",
        "    losses, scores = [], []\n",
        "    cont = True\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        if mixup:\n",
        "            mm = random.random()\n",
        "            perm = torch.randperm(data.shape[0])\n",
        "            output = model(mm * data + (1 - mm) * data[perm])\n",
        "        else:\n",
        "            output = model(data)\n",
        "        decisions = torch.argmax(output, dim = 1)\n",
        "        scores.append((decisions == target).float().mean().item())\n",
        "        if mixup:\n",
        "            loss = mm * criterion(output, target) + (1 - mm) * criterion(output, target[perm])\n",
        "        else:\n",
        "            loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(\"\\r{:3d} {:3.3f} {:3.3f} \".format(epoch + 1, np.mean(losses), np.mean(scores)), end='')\n",
        "    return np.mean(scores)\n",
        "\n",
        "def test(epoch, model, test_loader, confusions = False):\n",
        "    if confusions:\n",
        "        confs = torch.zeros((4,4))\n",
        "    score, count = 0, 0\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            decisions = torch.argmax(output, dim = 1)\n",
        "            if confusions:\n",
        "                for j in range(4):\n",
        "                    for k in range(4):\n",
        "                        confs[j][k] += (decisions[torch.where(target == j)[0]] == k).int().sum().item()\n",
        "            score += (decisions == target).int().sum().item()\n",
        "            count += target.shape[0]\n",
        "    print(\"\\r{:3d} test: {:.3f} \".format(epoch, score / count), end = '')\n",
        "    if confusions:\n",
        "        print(confs)\n",
        "    return (score / count)\n",
        "\n",
        "def train_test(params, runs = 3):\n",
        "    model = ConvNet(params[0], params[1], params[2], params[3]).to(device)\n",
        "    print(params, np.sum([m.numel() for m in model.parameters()]), \"params\")\n",
        "    scores = []\n",
        "    for removed_subject in range(1,10):\n",
        "        print(\"Removed subject:\", removed_subject)\n",
        "        train_loader, test_loader = loaders(removed_subject)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        for n_run in range(runs):\n",
        "            print(\"number of the run \",n_run)\n",
        "            model = ConvNet(params[0], params[1], params[2], params[3]).to(device)\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 40, gamma = 0.1)\n",
        "            \n",
        "            for epoch in range(50):\n",
        "                train_acc = train(epoch, model, criterion, optimizer, train_loader, mixup = True)\n",
        "                score = test(epoch, model, test_loader)\n",
        "                scheduler.step()\n",
        "            scores.append(score)\n",
        "            if n_run == runs - 1:\n",
        "                print()\n",
        "                print(\" average: {:.3f}\".format(np.mean(scores[-runs:])))\n",
        "            else:\n",
        "                print()\n",
        "    print(\"score is {:.3f}\".format(np.mean(scores)))\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "variations = [16, 1, 1, 1, 2]\n",
        "best_params = [448, 5, 1, 5, 9]\n",
        "best_params = [64, 4, 4, 7]\n",
        "#best_params = [32, 1, 2, 2, 3]\n",
        "#ending fm, n_blocks, depth_block, pool, kernel_size\n",
        "best_score = train_test(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BaUhvBAq3kt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "from  braindecode.models.eegnet import EEGNetv4\n",
        "import sys\n",
        "if len(sys.argv) > 1:\n",
        "    device = (\"cuda:\" + str(sys.argv[1])) if torch.cuda.is_available() else \"cpu\"\n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#hyperparameters\n",
        "batch_size = 144\n",
        "\n",
        "    \n",
        "X = torch.load(\"/users/local/eeg_data/bnci_X_offset_eog_EA.pt\")\n",
        "Y = torch.load(\"/users/local/eeg_data/bnci_Y_offset_eog_EA.pt\")\n",
        "\n",
        "n_chan = X[0].shape[1]\n",
        "\n",
        "mean = torch.cat(X).transpose(1,2).reshape(-1, n_chan).mean(dim = 0)\n",
        "std = torch.cat(X).transpose(1,2).reshape(-1, n_chan).std(dim = 0)\n",
        "\n",
        "def loaders(removed_subject):\n",
        "    train_X = torch.cat(X[:removed_subject] + X[removed_subject+1:])\n",
        "    train_Y = torch.cat(Y[:removed_subject] + Y[removed_subject+1:])\n",
        "    #train_X = (train_X - mean.unsqueeze(0).unsqueeze(2)) / std.unsqueeze(0).unsqueeze(2)\n",
        "    train_X = (train_X - mean.unsqueeze(0).unsqueeze(2)) / std.unsqueeze(0).unsqueeze(2)\n",
        "    train_X = torch.unbind(train_X)\n",
        "    train_Y = torch.unbind(train_Y)\n",
        "    train_data = list(zip(train_X, train_Y))\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, drop_last = True, num_workers = 8)\n",
        "    test_X = X[removed_subject]\n",
        "    test_X = (test_X - mean.unsqueeze(0).unsqueeze(2)) / std.unsqueeze(0).unsqueeze(2)\n",
        "    test_X = torch.unbind(test_X)\n",
        "    test_Y = torch.unbind(Y[removed_subject])\n",
        "    test_loader = torch.utils.data.DataLoader(list(zip(test_X, test_Y)), batch_size = 10000)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, fm, n_convs, init_pool, kernel_size):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.pool = torch.nn.AvgPool1d(init_pool)\n",
        "        self.conv = torch.nn.Conv1d(n_chan, fm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)\n",
        "        self.bn = torch.nn.BatchNorm1d(fm)\n",
        "        self.blocks = []\n",
        "        newfm = fm\n",
        "        oldfm = fm\n",
        "        for i in range(n_convs):\n",
        "            if i > 0:\n",
        "                newfm = int(1.414 * newfm)\n",
        "            self.blocks.append(torch.nn.Sequential(\n",
        "                (torch.nn.Conv1d(oldfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.MaxPool1d(2) if i > 0 - 1 else torch.nn.MaxPool1d(1)),\n",
        "                (torch.nn.ReLU()),\n",
        "                (torch.nn.Conv1d(newfm, newfm, kernel_size = kernel_size, padding = kernel_size // 2, bias = False)),\n",
        "                (torch.nn.BatchNorm1d(newfm)),\n",
        "                (torch.nn.ReLU())\n",
        "            ))\n",
        "            oldfm = newfm\n",
        "        self.blocks = torch.nn.ModuleList(self.blocks)\n",
        "        self.fc = torch.nn.Linear(oldfm, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = torch.relu(self.bn(self.conv(self.pool(x))))\n",
        "        for seq in self.blocks:\n",
        "            y = seq(y)\n",
        "        y = y.mean(dim = 2)\n",
        "        return self.fc(y)\n",
        "    \n",
        "def train(epoch, model, criterion, optimizer, train_loader, mixup = False):\n",
        "    losses, scores = [], []\n",
        "    cont = True\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # #random crop\n",
        "        # data = data[:,:,random.randint(0,300):-1-random.randint(0,300)]\n",
        "        # #resize (700 is a target to provide both dilations and contractions)\n",
        "        # data = torchvision.transforms.Resize((data.shape[1],700))(data)\n",
        "        # # drop out sensors\n",
        "        # data = data * (torch.rand(1,data.shape[1],1) > 0.1).to(device).float()\n",
        "        # add random noise\n",
        "        #data = data + 2 * torch.randn_like(data)\n",
        "        optimizer.zero_grad()\n",
        "        if mixup:\n",
        "            mm = random.random()\n",
        "            perm = torch.randperm(data.shape[0])\n",
        "            output = model(mm * data + (1 - mm) * data[perm])\n",
        "        else:\n",
        "            output = model(data)\n",
        "        decisions = torch.argmax(output, dim = 1)\n",
        "        scores.append((decisions == target).float().mean().item())\n",
        "        if mixup:\n",
        "            loss = mm * criterion(output, target) + (1 - mm) * criterion(output, target[perm])\n",
        "        else:\n",
        "            loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(\"\\r{:3d} {:3.3f} {:3.3f} \".format(epoch + 1, np.mean(losses), np.mean(scores)), end='')\n",
        "    return np.mean(scores)\n",
        "\n",
        "def test(epoch, model, test_loader, confusions = False):\n",
        "    if confusions:\n",
        "        confs = torch.zeros((4,4))\n",
        "    score, count = 0, 0\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            decisions = torch.argmax(output, dim = 1)\n",
        "            if confusions:\n",
        "                for j in range(4):\n",
        "                    for k in range(4):\n",
        "                        confs[j][k] += (decisions[torch.where(target == j)[0]] == k).int().sum().item()\n",
        "            score += (decisions == target).int().sum().item()\n",
        "            count += target.shape[0]\n",
        "    print(\"\\r{:3d} test: {:.3f} \".format(epoch, score / count), end = '')\n",
        "    if confusions:\n",
        "        print(confs)\n",
        "    return (score / count)\n",
        "\n",
        "def train_test(params, runs = 3):\n",
        "    model = ConvNet(params[0], params[1], params[2], params[3]).to(device)\n",
        "    print(params, np.sum([m.numel() for m in model.parameters()]), \"params\")\n",
        "    scores = []\n",
        "    for removed_subject in range(len(X)):\n",
        "        print(\"Removed subject:\", removed_subject)\n",
        "        train_loader, test_loader = loaders(removed_subject)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        for n_run in range(runs):\n",
        "            model = ConvNet(params[0], params[1], params[2], params[3]).to(device)\n",
        "            optimizer = torch.optim.Adam(model.parameters())\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 40, gamma = 0.1)\n",
        "            #optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9, nesterov = True, weight_decay = 1e-4)\n",
        "            #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 10)\n",
        "            for epoch in range(50):\n",
        "                train_acc = train(epoch, model, criterion, optimizer, train_loader, mixup = True)\n",
        "                scheduler.step()\n",
        "                \n",
        "            score = test(epoch, model, test_loader)\n",
        "            scores.append(score)\n",
        "            if n_run == runs - 1:\n",
        "                print(\" average: {:.3f}\".format(np.mean(scores[-runs:])))\n",
        "            else:\n",
        "                print()\n",
        "    print(\"{:.3f}\".format(np.mean(scores)))\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "variations = [16, 1, 1, 1, 2]\n",
        "best_params = [448, 5, 1, 5, 9]\n",
        "best_params = [64, 4, 4, 7]\n",
        "#best_params = [32, 1, 2, 2, 3]\n",
        "#ending fm, n_blocks, depth_block, pool, kernel_size\n",
        "best_score = train_test(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auldJ7s6f3qz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "accs_no_ea=[0.7024, 0.6289, 0.6145, 0.6795, 0.6892, 0.621, 0.6451, 0.6594, 0.6407, 0.5998]\n",
        "accs_ea=[0.7378, 0.7378, 0.8438, 0.6563, 0.6788, 0.599, 0.6059, 0.6233, 0.651]\n",
        "accs_bci=[0.73,0.72,0.84,0.65,0.67,0.599,0.6,0.62,0.65]\n",
        "mlp_bci_accs=[0.57,0.58,0.55,0.6,0.74,0.66,0.81,0.67,0.58]\n",
        "accs=mlp_bci_accs\n",
        "accs=np.array(accs)\n",
        "print('mean ',accs.mean())\n",
        "print('std ',accs.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS2mxmM4qx6f"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pceY6sGNaTvE",
        "9HsHADplayNq",
        "SYGu8lghuney",
        "iirnKmTTkpoF",
        "eHgle-E9cYTo"
      ],
      "machine_shape": "hm",
      "name": "sweeps_with_blocks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNiiTBH0dL8pG/1vVL7n3du",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03cab3541cb04439b3362b96200dcf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb9ed64239b64d35966e8f4d41bb32cf",
              "IPY_MODEL_e418c5a4c7c54f24970f79f05cfff91f"
            ],
            "layout": "IPY_MODEL_f8b4dd8ab2034e178ae850ac4295d6f4",
            "tabbable": null,
            "tooltip": null
          }
        },
        "cb9ed64239b64d35966e8f4d41bb32cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_288a2c4763e84cc48c4c25e1fadcad3b",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9d4ea9b40c4df3bbdc614e1bf6f6c8",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e418c5a4c7c54f24970f79f05cfff91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_08179b7245ee40a7b3f7897c5585b509",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a8122fc07f4872b6afc3430cbed97b",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "f8b4dd8ab2034e178ae850ac4295d6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288a2c4763e84cc48c4c25e1fadcad3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9d4ea9b40c4df3bbdc614e1bf6f6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "08179b7245ee40a7b3f7897c5585b509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a8122fc07f4872b6afc3430cbed97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47fe43c337304b6183effcea4e2e1865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccae02666afa48b291c24ef3855c0322",
              "IPY_MODEL_bf1fd50d10f74875a6c3eb726a5c27a7"
            ],
            "layout": "IPY_MODEL_d2801b9d662549bbbc569212a833c2ee",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ccae02666afa48b291c24ef3855c0322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_31a73fb963d84de29239d82fc39baed6",
            "placeholder": "​",
            "style": "IPY_MODEL_fddf81180ece452ea7919c51692dddaf",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "bf1fd50d10f74875a6c3eb726a5c27a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6927dab3291d413281972677015a8906",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9ec4243c18e47879138eb25a697f840",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "d2801b9d662549bbbc569212a833c2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a73fb963d84de29239d82fc39baed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddf81180ece452ea7919c51692dddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "6927dab3291d413281972677015a8906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ec4243c18e47879138eb25a697f840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efae0bdfb0174b68807c6a7be60c61ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abaf7414d7ab4b50ab342901d2e78ad5",
              "IPY_MODEL_4972e5c198bc443b93e85aa1fe973bb8"
            ],
            "layout": "IPY_MODEL_ef6f32201aeb4e85a2f5ccf4d7b601df",
            "tabbable": null,
            "tooltip": null
          }
        },
        "abaf7414d7ab4b50ab342901d2e78ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f65fbb2829314717b6f814fd55b40185",
            "placeholder": "​",
            "style": "IPY_MODEL_f277e759da64444e8511ea32a19880c6",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4972e5c198bc443b93e85aa1fe973bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_94fe8319e2ae4eddab8c8e579cc6860e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d905d7b73a6c40b99b46354c32d04567",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "ef6f32201aeb4e85a2f5ccf4d7b601df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65fbb2829314717b6f814fd55b40185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f277e759da64444e8511ea32a19880c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "94fe8319e2ae4eddab8c8e579cc6860e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d905d7b73a6c40b99b46354c32d04567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "334e3262222b485a95155629430f4b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9a5ba806ed3404a8f87fd18997ac1a7",
              "IPY_MODEL_8432f22a392e4106bc768ad095f3f0ce"
            ],
            "layout": "IPY_MODEL_9fd74b710abd45eca86885a9d61a54bf",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b9a5ba806ed3404a8f87fd18997ac1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_05ce09b945e84ad09fa06a0db468615d",
            "placeholder": "​",
            "style": "IPY_MODEL_4c99aafb15414634911bfdb9ed6ffa47",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8432f22a392e4106bc768ad095f3f0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4d7f6f6a46f249b0894147311fa00425",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5939b2463b4971b9163c9d23f42ffb",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "9fd74b710abd45eca86885a9d61a54bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ce09b945e84ad09fa06a0db468615d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c99aafb15414634911bfdb9ed6ffa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "4d7f6f6a46f249b0894147311fa00425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5939b2463b4971b9163c9d23f42ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "289f5b3abae84283a45f4f30aaff6288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74613d28fcd141368ab02efc0ea7d607",
              "IPY_MODEL_0b54bc47cc12444aa1be4b9ba5a15a03"
            ],
            "layout": "IPY_MODEL_c7482d1cb283400a87b6fe2fdcb855a8",
            "tabbable": null,
            "tooltip": null
          }
        },
        "74613d28fcd141368ab02efc0ea7d607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_27733464122c46e18f29cf78da4f8965",
            "placeholder": "​",
            "style": "IPY_MODEL_f22f7b63d37b4c22aed1c4af416c0149",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0b54bc47cc12444aa1be4b9ba5a15a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_03c135673c1a4c37a43b1254ff83ff27",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7e02333ef3447cb944686019ba888a8",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "c7482d1cb283400a87b6fe2fdcb855a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27733464122c46e18f29cf78da4f8965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22f7b63d37b4c22aed1c4af416c0149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "03c135673c1a4c37a43b1254ff83ff27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e02333ef3447cb944686019ba888a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a56b3b0c45444a21b4469833805e4953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a90d91dae42a45f4aeee045a128829e0",
              "IPY_MODEL_5f373a8eadd64fd082da1b37a205228c"
            ],
            "layout": "IPY_MODEL_70a367c259e3460283600a83428acfdd",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a90d91dae42a45f4aeee045a128829e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a357741d2e0b4960a2f89feaaec1c962",
            "placeholder": "​",
            "style": "IPY_MODEL_917e24435a7948878b3a6ab447d547e2",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5f373a8eadd64fd082da1b37a205228c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cf38dbff3ee946e989c2c151dd351fe1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2331c3ad58da4cb29cab7e6ade6483a2",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "70a367c259e3460283600a83428acfdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a357741d2e0b4960a2f89feaaec1c962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917e24435a7948878b3a6ab447d547e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "cf38dbff3ee946e989c2c151dd351fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2331c3ad58da4cb29cab7e6ade6483a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dc21647dce9419db91ee003bfc2d344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_818759a2fe5f4f5cb143a8f327ecc5f7",
              "IPY_MODEL_92a19973816b484a9e096111b32903b0"
            ],
            "layout": "IPY_MODEL_3e50921403484760b38a35157d863a48",
            "tabbable": null,
            "tooltip": null
          }
        },
        "818759a2fe5f4f5cb143a8f327ecc5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9e86a2a5f94d499eadb27a53945753ac",
            "placeholder": "​",
            "style": "IPY_MODEL_f6d5f135b0214d7f9d100a6da1d09d7c",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "92a19973816b484a9e096111b32903b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9c50af8b21154fdaa734e178f3af6ff4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b523370df54aaab4951ca9d8660925",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "3e50921403484760b38a35157d863a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e86a2a5f94d499eadb27a53945753ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d5f135b0214d7f9d100a6da1d09d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "9c50af8b21154fdaa734e178f3af6ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b523370df54aaab4951ca9d8660925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "361e56aac99b439499bd97668070201c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6cdc2882f8c4c5cb9fcb90cf42dd4d6",
              "IPY_MODEL_4723e6574e4f4e7e864d98844b955708"
            ],
            "layout": "IPY_MODEL_408f12ec735649858a3f17091aafa0d4",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a6cdc2882f8c4c5cb9fcb90cf42dd4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c7de7380d6854c3c8c5555dfb514cc80",
            "placeholder": "​",
            "style": "IPY_MODEL_2c1573624592439b80516f8b2f15f731",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4723e6574e4f4e7e864d98844b955708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2d51ad5fe5b148d5928c6384cbddffad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b58ecbf4a71f49a0aebb93922ff109c9",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "408f12ec735649858a3f17091aafa0d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7de7380d6854c3c8c5555dfb514cc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1573624592439b80516f8b2f15f731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "2d51ad5fe5b148d5928c6384cbddffad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58ecbf4a71f49a0aebb93922ff109c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8929d163b4746fa9ae88945b62a62d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9f3101e6062416bbce1ec6277b0e157",
              "IPY_MODEL_c7d9cc437c574130bb30a6c9799554d2"
            ],
            "layout": "IPY_MODEL_f9a52294c6a44f4493ac1efda7b7d444",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e9f3101e6062416bbce1ec6277b0e157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_09c9b2f336844145b46360720aa86327",
            "placeholder": "​",
            "style": "IPY_MODEL_5e5e340b4afe4a4eb0fcf25d78125bcd",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "c7d9cc437c574130bb30a6c9799554d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_749c9ebc01814b1d8b5be9a642dfaca0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dc74e18a6514dbab302915518575f86",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "f9a52294c6a44f4493ac1efda7b7d444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c9b2f336844145b46360720aa86327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5e340b4afe4a4eb0fcf25d78125bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "749c9ebc01814b1d8b5be9a642dfaca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc74e18a6514dbab302915518575f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3fa003cbff9433abea719141d9b550e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_789f242beea7462c9329ab164bd546b7",
              "IPY_MODEL_879e169d5410471c8400ccdab17c560c"
            ],
            "layout": "IPY_MODEL_bb9d0e501f0e4230b35d20760600e245",
            "tabbable": null,
            "tooltip": null
          }
        },
        "789f242beea7462c9329ab164bd546b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cd342f5d4b4b495595a838a86f77bebd",
            "placeholder": "​",
            "style": "IPY_MODEL_51761d12c6d34855900d0c7cfd93244c",
            "tabbable": null,
            "tooltip": null,
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "879e169d5410471c8400ccdab17c560c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_36508616fb62424e9d3b85448381f9b9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bb9f3033d5b48d29ea27867af68ae2f",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "bb9d0e501f0e4230b35d20760600e245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd342f5d4b4b495595a838a86f77bebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51761d12c6d34855900d0c7cfd93244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "36508616fb62424e9d3b85448381f9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb9f3033d5b48d29ea27867af68ae2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}